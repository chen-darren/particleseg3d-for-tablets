Starting... 
2025-04-02 13:30:46.036075: Using splits from existing split file: /home/dchen/Senior_Design/training/nnUNet_preprocessed/Task502_ParticleSeg3D/splits_final.pkl 
2025-04-02 13:30:46.037142: The split file contains 5 splits. 
2025-04-02 13:30:46.037194: Desired fold for training: 2 
2025-04-02 13:30:46.037244: This split has 12 training and 3 validation cases. 
2025-04-02 13:30:47.543775: raw_data_dir:  /home/dchen/Senior_Design/training/nnUNet_raw_data_base/nnUNet_raw_data/Task502_ParticleSeg3D 
2025-04-02 13:30:47.543885: preprocessed_data_dir:  /home/dchen/Senior_Design/training/nnUNet_preprocessed/Task502_ParticleSeg3D 
2025-04-02 13:30:47.543953: TRAINING KEYS:
 odict_keys([np.str_('2_Tablet_Aug1'), np.str_('2_Tablet_Aug2'), np.str_('2_Tablet_Aug4'), np.str_('2_Tablet_Aug5'), np.str_('4_GenericD12_Aug1'), np.str_('4_GenericD12_Aug2'), np.str_('4_GenericD12_Aug4'), np.str_('4_GenericD12_Aug5'), np.str_('5_ClaritinD12_Aug1'), np.str_('5_ClaritinD12_Aug2'), np.str_('5_ClaritinD12_Aug4'), np.str_('5_ClaritinD12_Aug5')]) 
2025-04-02 13:30:47.543985: VALIDATION KEYS:
 odict_keys([np.str_('2_Tablet_Aug3'), np.str_('4_GenericD12_Aug3'), np.str_('5_ClaritinD12_Aug3')]) 
2025-04-02 13:30:48.818624: loading checkpoint /home/dchen/Senior_Design/training/nnUNet_trained_models/nnUNet/3d_fullres/Task502_ParticleSeg3D/nnUNetTrainerV2_ParticleSeg3D_DarrenSGD_CUDAErrorSkip__nnUNetPlansv2.1/fold_2/model_latest.model train= True 
2025-04-02 13:30:49.069574: lr: 0.000809 
2025-04-02 13:30:57.875092: Unable to plot network architecture: 
2025-04-02 13:30:57.876518: No module named 'hiddenlayer' 
2025-04-02 13:30:57.876699: 
printing the network instead:
 
2025-04-02 13:30:57.876771: Generic_UNet(
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
) 
2025-04-02 13:30:57.881114: 
 
2025-04-02 13:30:57.881624: 
epoch:  210 
2025-04-02 13:32:50.659366: train loss : -0.6875 
2025-04-02 13:33:05.511822: validation loss: -0.2892 
2025-04-02 13:33:05.512769: Average global foreground Dice: [np.float32(0.7746), np.float32(0.576)] 
2025-04-02 13:33:05.513279: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 13:33:05.928819: lr: 0.000808 
2025-04-02 13:33:05.952704: saving checkpoint... 
2025-04-02 13:33:06.243452: done, saving took 0.31 seconds 
2025-04-02 13:33:06.248432: This epoch took 128.366345 s
 
2025-04-02 13:33:06.248703: 
epoch:  211 
2025-04-02 13:34:53.582116: train loss : -0.6926 
2025-04-02 13:35:07.678691: validation loss: -0.2052 
2025-04-02 13:35:07.679486: Average global foreground Dice: [np.float32(0.7258), np.float32(0.5225)] 
2025-04-02 13:35:07.680484: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 13:35:08.037480: lr: 0.000807 
2025-04-02 13:35:08.038115: This epoch took 121.789321 s
 
2025-04-02 13:35:08.038258: 
epoch:  212 
2025-04-02 13:36:59.472048: train loss : -0.7003 
2025-04-02 13:37:13.705478: validation loss: -0.2257 
2025-04-02 13:37:13.706337: Average global foreground Dice: [np.float32(0.728), np.float32(0.5346)] 
2025-04-02 13:37:13.706940: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 13:37:14.040362: lr: 0.000806 
2025-04-02 13:37:14.040564: This epoch took 126.002234 s
 
2025-04-02 13:37:14.040631: 
epoch:  213 
2025-04-02 13:39:10.397190: train loss : -0.6772 
2025-04-02 13:39:24.055864: validation loss: -0.3127 
2025-04-02 13:39:24.056638: Average global foreground Dice: [np.float32(0.7857), np.float32(0.5864)] 
2025-04-02 13:39:24.057129: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 13:39:24.404651: lr: 0.000805 
2025-04-02 13:39:24.404805: This epoch took 130.364131 s
 
2025-04-02 13:39:24.404888: 
epoch:  214 
2025-04-02 13:41:11.873297: train loss : -0.6872 
2025-04-02 13:41:28.039453: validation loss: 0.3072 
2025-04-02 13:41:28.040669: Average global foreground Dice: [np.float32(0.6734), np.float32(0.4713)] 
2025-04-02 13:41:28.041165: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 13:41:28.378949: lr: 0.000804 
2025-04-02 13:41:28.379485: saving scheduled checkpoint file... 
2025-04-02 13:41:28.414849: saving checkpoint... 
2025-04-02 13:41:28.746084: done, saving took 0.37 seconds 
2025-04-02 13:41:28.751027: done 
2025-04-02 13:41:28.751278: This epoch took 124.346321 s
 
2025-04-02 13:41:28.751442: 
epoch:  215 
2025-04-02 13:43:20.044369: train loss : -0.6824 
2025-04-02 13:43:34.773406: validation loss: -0.0773 
2025-04-02 13:43:34.774359: Average global foreground Dice: [np.float32(0.7277), np.float32(0.5195)] 
2025-04-02 13:43:34.774781: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 13:43:35.129619: lr: 0.000803 
2025-04-02 13:43:35.130146: This epoch took 126.378570 s
 
2025-04-02 13:43:35.130562: 
epoch:  216 
2025-04-02 13:45:27.143054: train loss : -0.6813 
2025-04-02 13:45:42.897057: validation loss: -0.3938 
2025-04-02 13:45:42.898113: Average global foreground Dice: [np.float32(0.8162), np.float32(0.6219)] 
2025-04-02 13:45:42.898612: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 13:45:43.315117: lr: 0.000802 
2025-04-02 13:45:43.315593: This epoch took 128.184601 s
 
2025-04-02 13:45:43.315658: 
epoch:  217 
2025-04-02 13:47:30.066043: train loss : -0.6875 
2025-04-02 13:47:45.439174: validation loss: -0.3025 
2025-04-02 13:47:45.440207: Average global foreground Dice: [np.float32(0.7888), np.float32(0.6014)] 
2025-04-02 13:47:45.440670: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 13:47:45.812642: lr: 0.000801 
2025-04-02 13:47:45.813131: This epoch took 122.497405 s
 
2025-04-02 13:47:45.813499: 
epoch:  218 
2025-04-02 13:49:37.263516: train loss : -0.6790 
2025-04-02 13:49:52.996689: validation loss: -0.1779 
2025-04-02 13:49:52.997603: Average global foreground Dice: [np.float32(0.6854), np.float32(0.4853)] 
2025-04-02 13:49:52.998186: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 13:49:53.431630: lr: 0.000801 
2025-04-02 13:49:53.431978: This epoch took 127.618179 s
 
2025-04-02 13:49:53.432402: 
epoch:  219 
2025-04-02 13:51:46.267685: train loss : -0.7030 
2025-04-02 13:52:00.922288: validation loss: -0.2628 
2025-04-02 13:52:00.923354: Average global foreground Dice: [np.float32(0.7723), np.float32(0.5867)] 
2025-04-02 13:52:00.923862: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 13:52:01.288154: lr: 0.0008 
2025-04-02 13:52:01.288798: saving scheduled checkpoint file... 
2025-04-02 13:52:01.311715: saving checkpoint... 
2025-04-02 13:52:01.631567: done, saving took 0.34 seconds 
2025-04-02 13:52:01.634999: done 
2025-04-02 13:52:01.635273: This epoch took 128.202802 s
 
2025-04-02 13:52:01.635512: 
epoch:  220 
2025-04-02 13:53:53.510718: train loss : -0.6780 
2025-04-02 13:54:08.182713: validation loss: -0.0783 
2025-04-02 13:54:08.183481: Average global foreground Dice: [np.float32(0.7381), np.float32(0.5325)] 
2025-04-02 13:54:08.183873: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 13:54:08.580833: lr: 0.000799 
2025-04-02 13:54:08.581036: This epoch took 126.945255 s
 
2025-04-02 13:54:08.581192: 
epoch:  221 
2025-04-02 13:56:00.539098: train loss : -0.6982 
2025-04-02 13:56:15.436104: validation loss: -0.1808 
2025-04-02 13:56:15.437562: Average global foreground Dice: [np.float32(0.7382), np.float32(0.53)] 
2025-04-02 13:56:15.437921: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 13:56:15.931566: lr: 0.000798 
2025-04-02 13:56:15.931934: This epoch took 127.350664 s
 
2025-04-02 13:56:15.931996: 
epoch:  222 
2025-04-02 13:58:04.314232: train loss : -0.6963 
2025-04-02 13:58:20.997566: validation loss: -0.2922 
2025-04-02 13:58:20.998738: Average global foreground Dice: [np.float32(0.769), np.float32(0.5758)] 
2025-04-02 13:58:20.999377: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 13:58:21.462111: lr: 0.000797 
2025-04-02 13:58:21.462599: This epoch took 125.530442 s
 
2025-04-02 13:58:21.463307: 
epoch:  223 
2025-04-02 14:03:25.495971: train loss : -0.6759 
2025-04-02 14:03:39.869595: validation loss: 0.0732 
2025-04-02 14:03:39.870216: Average global foreground Dice: [np.float32(0.6865), np.float32(0.4924)] 
2025-04-02 14:03:39.870879: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 14:03:40.217928: lr: 0.000796 
2025-04-02 14:03:40.218141: This epoch took 318.753894 s
 
2025-04-02 14:03:40.218272: 
epoch:  224 
2025-04-02 14:05:38.675895: train loss : -0.6979 
2025-04-02 14:05:52.634140: validation loss: -0.1275 
2025-04-02 14:05:52.635062: Average global foreground Dice: [np.float32(0.7345), np.float32(0.5222)] 
2025-04-02 14:05:52.635854: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 14:05:52.987118: lr: 0.000795 
2025-04-02 14:05:52.987479: saving scheduled checkpoint file... 
2025-04-02 14:05:53.013998: saving checkpoint... 
2025-04-02 14:05:53.362936: done, saving took 0.38 seconds 
2025-04-02 14:05:53.366306: done 
2025-04-02 14:05:53.366393: This epoch took 133.148058 s
 
2025-04-02 14:05:53.366491: 
epoch:  225 
2025-04-02 14:07:44.425862: train loss : -0.6990 
2025-04-02 14:08:01.765040: validation loss: -0.2108 
2025-04-02 14:08:01.766569: Average global foreground Dice: [np.float32(0.7503), np.float32(0.5488)] 
2025-04-02 14:08:01.767213: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 14:08:02.112236: lr: 0.000794 
2025-04-02 14:08:02.112546: This epoch took 128.745990 s
 
2025-04-02 14:08:02.112739: 
epoch:  226 
2025-04-02 14:09:59.221135: train loss : -0.6863 
2025-04-02 14:10:13.508755: validation loss: -0.4437 
2025-04-02 14:10:13.509754: Average global foreground Dice: [np.float32(0.8252), np.float32(0.6274)] 
2025-04-02 14:10:13.510154: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 14:10:13.872658: lr: 0.000793 
2025-04-02 14:10:13.873011: This epoch took 131.760191 s
 
2025-04-02 14:10:13.873143: 
epoch:  227 
2025-04-02 14:12:00.741659: train loss : -0.6860 
2025-04-02 14:12:18.313957: validation loss: -0.2584 
2025-04-02 14:12:18.315047: Average global foreground Dice: [np.float32(0.7629), np.float32(0.5674)] 
2025-04-02 14:12:18.315690: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 14:12:18.740511: lr: 0.000792 
2025-04-02 14:12:18.740671: This epoch took 124.867395 s
 
2025-04-02 14:12:18.740736: 
epoch:  228 
2025-04-02 14:14:11.715285: train loss : -0.6962 
2025-04-02 14:14:25.225974: validation loss: 0.0514 
2025-04-02 14:14:25.226731: Average global foreground Dice: [np.float32(0.7495), np.float32(0.5536)] 
2025-04-02 14:14:25.227533: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 14:14:25.583942: lr: 0.000791 
2025-04-02 14:14:25.584086: This epoch took 126.843278 s
 
2025-04-02 14:14:25.584141: 
epoch:  229 
2025-04-02 14:16:16.726972: train loss : -0.6855 
2025-04-02 14:16:32.730942: validation loss: -0.0945 
2025-04-02 14:16:32.731731: Average global foreground Dice: [np.float32(0.6954), np.float32(0.4706)] 
2025-04-02 14:16:32.732675: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 14:16:33.054334: lr: 0.00079 
2025-04-02 14:16:33.054567: saving scheduled checkpoint file... 
2025-04-02 14:16:33.078762: saving checkpoint... 
2025-04-02 14:16:33.395841: done, saving took 0.34 seconds 
2025-04-02 14:16:33.400338: done 
2025-04-02 14:16:33.400737: This epoch took 127.816539 s
 
2025-04-02 14:16:33.401264: 
epoch:  230 
2025-04-02 14:18:28.802587: train loss : -0.6865 
2025-04-02 14:18:43.134757: validation loss: -0.1019 
2025-04-02 14:18:43.135570: Average global foreground Dice: [np.float32(0.7441), np.float32(0.533)] 
2025-04-02 14:18:43.136200: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 14:18:43.798425: lr: 0.000789 
2025-04-02 14:18:43.798662: This epoch took 130.396866 s
 
2025-04-02 14:18:43.798783: 
epoch:  231 
2025-04-02 14:20:36.944025: train loss : -0.6823 
2025-04-02 14:20:51.487130: validation loss: -0.3052 
2025-04-02 14:20:51.488187: Average global foreground Dice: [np.float32(0.7981), np.float32(0.5915)] 
2025-04-02 14:20:51.488757: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 14:20:51.839543: lr: 0.000789 
2025-04-02 14:20:51.840002: This epoch took 128.041148 s
 
2025-04-02 14:20:51.840348: 
epoch:  232 
2025-04-02 14:22:48.325657: train loss : -0.6822 
2025-04-02 14:23:03.872638: validation loss: -0.1750 
2025-04-02 14:23:03.873457: Average global foreground Dice: [np.float32(0.7175), np.float32(0.474)] 
2025-04-02 14:23:03.873984: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 14:23:04.240925: lr: 0.000788 
2025-04-02 14:23:04.241098: This epoch took 132.400308 s
 
2025-04-02 14:23:04.241275: 
epoch:  233 
2025-04-02 14:24:57.083191: train loss : -0.6797 
2025-04-02 14:25:12.055754: validation loss: -0.2843 
2025-04-02 14:25:12.056418: Average global foreground Dice: [np.float32(0.7549), np.float32(0.5582)] 
2025-04-02 14:25:12.056937: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 14:25:12.380287: lr: 0.000787 
2025-04-02 14:25:12.380691: This epoch took 128.139333 s
 
2025-04-02 14:25:12.380949: 
epoch:  234 
2025-04-02 14:27:03.275191: train loss : -0.6739 
2025-04-02 14:27:18.647244: validation loss: -0.1506 
2025-04-02 14:27:18.648046: Average global foreground Dice: [np.float32(0.7417), np.float32(0.5385)] 
2025-04-02 14:27:18.648427: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 14:27:19.018738: lr: 0.000786 
2025-04-02 14:27:19.019305: saving scheduled checkpoint file... 
2025-04-02 14:27:19.047532: saving checkpoint... 
2025-04-02 14:27:19.431791: done, saving took 0.41 seconds 
2025-04-02 14:27:19.434742: done 
2025-04-02 14:27:19.435006: This epoch took 127.053556 s
 
2025-04-02 14:27:19.435322: 
epoch:  235 
2025-04-02 14:29:13.793404: train loss : -0.6777 
2025-04-02 14:29:30.449607: validation loss: -0.2628 
2025-04-02 14:29:30.451054: Average global foreground Dice: [np.float32(0.7705), np.float32(0.5841)] 
2025-04-02 14:29:30.451779: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 14:29:30.901752: lr: 0.000785 
2025-04-02 14:29:30.901896: This epoch took 131.466337 s
 
2025-04-02 14:29:30.901952: 
epoch:  236 
2025-04-02 14:31:24.780649: train loss : -0.6908 
2025-04-02 14:31:39.799302: validation loss: -0.2382 
2025-04-02 14:31:39.800348: Average global foreground Dice: [np.float32(0.7454), np.float32(0.529)] 
2025-04-02 14:31:39.800809: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 14:31:40.169934: lr: 0.000784 
2025-04-02 14:31:40.170075: This epoch took 129.268058 s
 
2025-04-02 14:31:40.170139: 
epoch:  237 
2025-04-02 14:33:30.890161: train loss : -0.6905 
2025-04-02 14:33:47.061764: validation loss: -0.3496 
2025-04-02 14:33:47.063429: Average global foreground Dice: [np.float32(0.8183), np.float32(0.6228)] 
2025-04-02 14:33:47.064221: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 14:33:47.558008: lr: 0.000783 
2025-04-02 14:33:47.558646: This epoch took 127.388447 s
 
2025-04-02 14:33:47.559120: 
epoch:  238 
2025-04-02 14:35:45.144676: train loss : -0.6591 
2025-04-02 14:35:59.274544: validation loss: -0.3604 
2025-04-02 14:35:59.275467: Average global foreground Dice: [np.float32(0.8108), np.float32(0.6178)] 
2025-04-02 14:35:59.275923: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 14:35:59.627281: lr: 0.000782 
2025-04-02 14:35:59.627617: This epoch took 132.067914 s
 
2025-04-02 14:35:59.627878: 
epoch:  239 
2025-04-02 14:37:55.514123: train loss : -0.6899 
2025-04-02 14:38:13.945001: validation loss: -0.3865 
2025-04-02 14:38:13.946364: Average global foreground Dice: [np.float32(0.7835), np.float32(0.5988)] 
2025-04-02 14:38:13.946982: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 14:38:14.408278: lr: 0.000781 
2025-04-02 14:38:14.408670: saving scheduled checkpoint file... 
2025-04-02 14:38:14.431633: saving checkpoint... 
2025-04-02 14:38:14.770386: done, saving took 0.36 seconds 
2025-04-02 14:38:14.773742: done 
2025-04-02 14:38:14.773924: This epoch took 135.145792 s
 
2025-04-02 14:38:14.774285: 
epoch:  240 
2025-04-02 14:40:06.539930: train loss : -0.6566 
2025-04-02 14:40:23.357085: validation loss: -0.2775 
2025-04-02 14:40:23.358579: Average global foreground Dice: [np.float32(0.7508), np.float32(0.543)] 
2025-04-02 14:40:23.359043: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 14:40:23.877236: lr: 0.00078 
2025-04-02 14:40:23.877854: This epoch took 129.103171 s
 
2025-04-02 14:40:23.878264: 
epoch:  241 
2025-04-02 14:42:16.250529: train loss : -0.6587 
2025-04-02 14:42:31.292835: validation loss: 0.0516 
2025-04-02 14:42:31.294250: Average global foreground Dice: [np.float32(0.7217), np.float32(0.5251)] 
2025-04-02 14:42:31.294862: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 14:42:31.955601: lr: 0.000779 
2025-04-02 14:42:31.964549: This epoch took 128.085899 s
 
2025-04-02 14:42:31.965037: 
epoch:  242 
2025-04-02 14:44:24.653512: train loss : -0.6604 
2025-04-02 14:44:40.362650: validation loss: -0.2376 
2025-04-02 14:44:40.363659: Average global foreground Dice: [np.float32(0.7964), np.float32(0.5955)] 
2025-04-02 14:44:40.364342: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 14:44:40.774325: lr: 0.000778 
2025-04-02 14:44:40.774839: This epoch took 128.809668 s
 
2025-04-02 14:44:40.775137: 
epoch:  243 
2025-04-02 14:46:35.835166: train loss : -0.6814 
2025-04-02 14:46:50.068507: validation loss: -0.2170 
2025-04-02 14:46:50.069362: Average global foreground Dice: [np.float32(0.731), np.float32(0.5331)] 
2025-04-02 14:46:50.069810: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 14:46:50.421266: lr: 0.000777 
2025-04-02 14:46:50.421480: This epoch took 129.646265 s
 
2025-04-02 14:46:50.421605: 
epoch:  244 
2025-04-02 14:48:40.880985: train loss : -0.6934 
2025-04-02 14:48:56.315428: validation loss: -0.1079 
2025-04-02 14:48:56.316506: Average global foreground Dice: [np.float32(0.7347), np.float32(0.5327)] 
2025-04-02 14:48:56.316905: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 14:48:56.676322: lr: 0.000777 
2025-04-02 14:48:56.676481: saving scheduled checkpoint file... 
2025-04-02 14:48:56.693076: saving checkpoint... 
2025-04-02 14:48:57.036749: done, saving took 0.36 seconds 
2025-04-02 14:48:57.040569: done 
2025-04-02 14:48:57.040814: This epoch took 126.619151 s
 
2025-04-02 14:48:57.041028: 
epoch:  245 
2025-04-02 14:50:50.701339: train loss : -0.6610 
2025-04-02 14:51:08.534448: validation loss: 0.0431 
2025-04-02 14:51:08.535774: Average global foreground Dice: [np.float32(0.7049), np.float32(0.4988)] 
2025-04-02 14:51:08.537728: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 14:51:08.914920: lr: 0.000776 
2025-04-02 14:51:08.915152: This epoch took 131.872612 s
 
2025-04-02 14:51:08.915216: 
epoch:  246 

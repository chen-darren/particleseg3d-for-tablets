Starting... 
2025-04-02 14:54:32.740228: Using splits from existing split file: /home/dchen/Senior_Design/training/nnUNet_preprocessed/Task502_ParticleSeg3D/splits_final.pkl 
2025-04-02 14:54:32.742366: The split file contains 5 splits. 
2025-04-02 14:54:32.742437: Desired fold for training: 2 
2025-04-02 14:54:32.742490: This split has 12 training and 3 validation cases. 
2025-04-02 14:54:34.271418: raw_data_dir:  /home/dchen/Senior_Design/training/nnUNet_raw_data_base/nnUNet_raw_data/Task502_ParticleSeg3D 
2025-04-02 14:54:34.271537: preprocessed_data_dir:  /home/dchen/Senior_Design/training/nnUNet_preprocessed/Task502_ParticleSeg3D 
2025-04-02 14:54:34.271604: TRAINING KEYS:
 odict_keys([np.str_('2_Tablet_Aug1'), np.str_('2_Tablet_Aug2'), np.str_('2_Tablet_Aug4'), np.str_('2_Tablet_Aug5'), np.str_('4_GenericD12_Aug1'), np.str_('4_GenericD12_Aug2'), np.str_('4_GenericD12_Aug4'), np.str_('4_GenericD12_Aug5'), np.str_('5_ClaritinD12_Aug1'), np.str_('5_ClaritinD12_Aug2'), np.str_('5_ClaritinD12_Aug4'), np.str_('5_ClaritinD12_Aug5')]) 
2025-04-02 14:54:34.271637: VALIDATION KEYS:
 odict_keys([np.str_('2_Tablet_Aug3'), np.str_('4_GenericD12_Aug3'), np.str_('5_ClaritinD12_Aug3')]) 
2025-04-02 14:54:35.322933: loading checkpoint /home/dchen/Senior_Design/training/nnUNet_trained_models/nnUNet/3d_fullres/Task502_ParticleSeg3D/nnUNetTrainerV2_ParticleSeg3D_DarrenSGD_CUDAErrorSkip__nnUNetPlansv2.1/fold_2/model_latest.model train= True 
2025-04-02 14:54:35.575700: lr: 0.000777 
2025-04-02 14:54:41.536753: Unable to plot network architecture: 
2025-04-02 14:54:41.536946: No module named 'hiddenlayer' 
2025-04-02 14:54:41.536978: 
printing the network instead:
 
2025-04-02 14:54:41.537008: Generic_UNet(
  (conv_blocks_localization): ModuleList(
    (0): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (1): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (2): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (3): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
    (4): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (conv_blocks_context): ModuleList(
    (0): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(1, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (1): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (2): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (3): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (4): StackedConvLayers(
      (blocks): Sequential(
        (0): ConvDropoutNormNonlin(
          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
        (1): ConvDropoutNormNonlin(
          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
        )
      )
    )
    (5): Sequential(
      (0): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 2, 2), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
      (1): StackedConvLayers(
        (blocks): Sequential(
          (0): ConvDropoutNormNonlin(
            (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))
            (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)
            (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)
          )
        )
      )
    )
  )
  (td): ModuleList()
  (tu): ModuleList(
    (0): ConvTranspose3d(320, 320, kernel_size=(1, 2, 2), stride=(1, 2, 2), bias=False)
    (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
    (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)
  )
  (seg_outputs): ModuleList(
    (0): Conv3d(320, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (1): Conv3d(256, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (2): Conv3d(128, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (3): Conv3d(64, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
    (4): Conv3d(32, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)
  )
) 
2025-04-02 14:54:41.539515: 
 
2025-04-02 14:54:41.539691: 
epoch:  245 
2025-04-02 14:56:40.307059: train loss : -0.6997 
2025-04-02 14:56:54.257283: validation loss: -0.2558 
2025-04-02 14:56:54.258201: Average global foreground Dice: [np.float32(0.7551), np.float32(0.562)] 
2025-04-02 14:56:54.258827: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 14:56:54.655039: lr: 0.000776 
2025-04-02 14:56:54.655186: This epoch took 133.115439 s
 
2025-04-02 14:56:54.655243: 
epoch:  246 
2025-04-02 14:58:44.672648: train loss : -0.7019 
2025-04-02 14:59:00.213605: validation loss: -0.2286 
2025-04-02 14:59:00.214289: Average global foreground Dice: [np.float32(0.7348), np.float32(0.5398)] 
2025-04-02 14:59:00.214792: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 14:59:00.575976: lr: 0.000775 
2025-04-02 14:59:00.576522: This epoch took 125.921220 s
 
2025-04-02 14:59:00.576929: 
epoch:  247 
2025-04-02 15:03:08.147222: train loss : -0.7036 
2025-04-02 15:03:22.224078: validation loss: -0.1786 
2025-04-02 15:03:22.224932: Average global foreground Dice: [np.float32(0.7119), np.float32(0.5117)] 
2025-04-02 15:03:22.225414: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 15:03:22.581561: lr: 0.000774 
2025-04-02 15:03:22.581710: This epoch took 262.004493 s
 
2025-04-02 15:03:22.581752: 
epoch:  248 
2025-04-02 15:05:18.351003: train loss : -0.6848 
2025-04-02 15:05:33.559629: validation loss: -0.0270 
2025-04-02 15:05:33.560721: Average global foreground Dice: [np.float32(0.737), np.float32(0.5397)] 
2025-04-02 15:05:33.561103: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 15:05:33.942713: lr: 0.000773 
2025-04-02 15:05:33.943710: This epoch took 131.361929 s
 
2025-04-02 15:05:33.943989: 
epoch:  249 
2025-04-02 15:07:27.249512: train loss : -0.6992 
2025-04-02 15:07:40.330548: validation loss: -0.1758 
2025-04-02 15:07:40.331469: Average global foreground Dice: [np.float32(0.7363), np.float32(0.5301)] 
2025-04-02 15:07:40.331992: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 15:07:40.720163: lr: 0.000772 
2025-04-02 15:07:40.720541: saving scheduled checkpoint file... 
2025-04-02 15:07:40.752656: saving checkpoint... 
2025-04-02 15:07:41.156525: done, saving took 0.44 seconds 
2025-04-02 15:07:41.164501: done 
2025-04-02 15:07:41.164788: This epoch took 127.220496 s
 
2025-04-02 15:07:41.165062: 
epoch:  250 
2025-04-02 15:09:30.308649: train loss : -0.6677 
2025-04-02 15:09:44.922955: validation loss: -0.2456 
2025-04-02 15:09:44.924163: Average global foreground Dice: [np.float32(0.8003), np.float32(0.6091)] 
2025-04-02 15:09:44.924791: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 15:09:45.314927: lr: 0.000771 
2025-04-02 15:09:45.315197: This epoch took 124.149961 s
 
2025-04-02 15:09:45.315350: 
epoch:  251 
2025-04-02 15:11:36.923697: train loss : -0.6742 
2025-04-02 15:11:49.913960: validation loss: 0.0260 
2025-04-02 15:11:49.914680: Average global foreground Dice: [np.float32(0.7199), np.float32(0.5248)] 
2025-04-02 15:11:49.915150: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 15:11:50.330830: lr: 0.00077 
2025-04-02 15:11:50.331550: This epoch took 125.016114 s
 
2025-04-02 15:11:50.331941: 
epoch:  252 
2025-04-02 15:13:48.214792: train loss : -0.6961 
2025-04-02 15:14:04.321463: validation loss: -0.0658 
2025-04-02 15:14:04.322100: Average global foreground Dice: [np.float32(0.7354), np.float32(0.5425)] 
2025-04-02 15:14:04.322507: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 15:14:04.678236: lr: 0.000769 
2025-04-02 15:14:04.678376: This epoch took 134.346327 s
 
2025-04-02 15:14:04.678433: 
epoch:  253 
2025-04-02 15:15:58.723790: train loss : -0.6698 
2025-04-02 15:16:12.139476: validation loss: -0.1402 
2025-04-02 15:16:12.140379: Average global foreground Dice: [np.float32(0.7587), np.float32(0.5583)] 
2025-04-02 15:16:12.141086: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 15:16:12.595752: lr: 0.000768 
2025-04-02 15:16:12.597568: This epoch took 127.919072 s
 
2025-04-02 15:16:12.597912: 
epoch:  254 
2025-04-02 15:18:04.353885: train loss : -0.6957 
2025-04-02 15:18:19.450181: validation loss: -0.0037 
2025-04-02 15:18:19.451395: Average global foreground Dice: [np.float32(0.6947), np.float32(0.4792)] 
2025-04-02 15:18:19.452099: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 15:18:19.948528: lr: 0.000767 
2025-04-02 15:18:19.949382: saving scheduled checkpoint file... 
2025-04-02 15:18:19.995191: saving checkpoint... 
2025-04-02 15:18:20.655627: done, saving took 0.71 seconds 
2025-04-02 15:18:20.661276: done 
2025-04-02 15:18:20.661633: This epoch took 128.063563 s
 
2025-04-02 15:18:20.662009: 
epoch:  255 
2025-04-02 15:20:15.238384: train loss : -0.6534 
2025-04-02 15:20:30.020105: validation loss: 0.0447 
2025-04-02 15:20:30.020999: Average global foreground Dice: [np.float32(0.6851), np.float32(0.4843)] 
2025-04-02 15:20:30.021792: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 15:20:30.372990: lr: 0.000766 
2025-04-02 15:20:30.373394: This epoch took 129.711126 s
 
2025-04-02 15:20:30.373538: 
epoch:  256 
2025-04-02 15:22:25.108943: train loss : -0.6689 
2025-04-02 15:22:41.413196: validation loss: -0.3262 
2025-04-02 15:22:41.414364: Average global foreground Dice: [np.float32(0.7658), np.float32(0.5678)] 
2025-04-02 15:22:41.414955: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 15:22:41.766728: lr: 0.000765 
2025-04-02 15:22:41.766917: This epoch took 131.393303 s
 
2025-04-02 15:22:41.766984: 
epoch:  257 
2025-04-02 15:24:39.889769: train loss : -0.6749 
2025-04-02 15:24:53.272361: validation loss: -0.0766 
2025-04-02 15:24:53.273069: Average global foreground Dice: [np.float32(0.7372), np.float32(0.5386)] 
2025-04-02 15:24:53.278763: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 15:24:53.611990: lr: 0.000764 
2025-04-02 15:24:53.612950: This epoch took 131.845887 s
 
2025-04-02 15:24:53.613419: 
epoch:  258 
2025-04-02 15:26:53.804606: train loss : -0.6868 
2025-04-02 15:27:07.919396: validation loss: -0.0829 
2025-04-02 15:27:07.920107: Average global foreground Dice: [np.float32(0.7217), np.float32(0.5228)] 
2025-04-02 15:27:07.920465: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 15:27:08.304365: lr: 0.000764 
2025-04-02 15:27:08.304791: This epoch took 134.690974 s
 
2025-04-02 15:27:08.305136: 
epoch:  259 
2025-04-02 15:28:59.951561: train loss : -0.6806 
2025-04-02 15:29:14.216619: validation loss: -0.1560 
2025-04-02 15:29:14.217418: Average global foreground Dice: [np.float32(0.7262), np.float32(0.5278)] 
2025-04-02 15:29:14.217806: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 15:29:14.566759: lr: 0.000763 
2025-04-02 15:29:14.567364: saving scheduled checkpoint file... 
2025-04-02 15:29:14.598100: saving checkpoint... 
2025-04-02 15:29:14.950135: done, saving took 0.38 seconds 
2025-04-02 15:29:14.954596: done 
2025-04-02 15:29:14.954919: This epoch took 126.649512 s
 
2025-04-02 15:29:14.955395: 
epoch:  260 
2025-04-02 15:31:09.997502: train loss : -0.7062 
2025-04-02 15:31:24.473094: validation loss: 0.1906 
2025-04-02 15:31:24.478055: Average global foreground Dice: [np.float32(0.7064), np.float32(0.5058)] 
2025-04-02 15:31:24.478444: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 15:31:24.813453: lr: 0.000762 
2025-04-02 15:31:24.813726: This epoch took 129.857842 s
 
2025-04-02 15:31:24.813979: 
epoch:  261 
2025-04-02 15:33:17.733694: train loss : -0.6985 
2025-04-02 15:33:31.500908: validation loss: -0.1974 
2025-04-02 15:33:31.502024: Average global foreground Dice: [np.float32(0.7685), np.float32(0.5713)] 
2025-04-02 15:33:31.502575: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 15:33:31.849346: lr: 0.000761 
2025-04-02 15:33:31.849797: This epoch took 127.035629 s
 
2025-04-02 15:33:31.850211: 
epoch:  262 
2025-04-02 15:35:21.860892: train loss : -0.6840 
2025-04-02 15:35:35.468493: validation loss: -0.3961 
2025-04-02 15:35:35.469375: Average global foreground Dice: [np.float32(0.8082), np.float32(0.626)] 
2025-04-02 15:35:35.469788: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 15:35:35.893771: lr: 0.00076 
2025-04-02 15:35:35.894397: This epoch took 124.043886 s
 
2025-04-02 15:35:35.894852: 
epoch:  263 
2025-04-02 15:37:36.397085: train loss : -0.6887 
2025-04-02 15:37:50.899067: validation loss: -0.2417 
2025-04-02 15:37:50.899762: Average global foreground Dice: [np.float32(0.7219), np.float32(0.5358)] 
2025-04-02 15:37:50.900265: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 15:37:51.389595: lr: 0.000759 
2025-04-02 15:37:51.389808: This epoch took 135.494601 s
 
2025-04-02 15:37:51.389874: 
epoch:  264 
2025-04-02 15:39:46.363662: train loss : -0.6973 
2025-04-02 15:40:01.170044: validation loss: -0.1273 
2025-04-02 15:40:01.170781: Average global foreground Dice: [np.float32(0.7424), np.float32(0.5427)] 
2025-04-02 15:40:01.171169: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 15:40:01.514531: lr: 0.000758 
2025-04-02 15:40:01.514734: saving scheduled checkpoint file... 
2025-04-02 15:40:01.535602: saving checkpoint... 
2025-04-02 15:40:01.852146: done, saving took 0.34 seconds 
2025-04-02 15:40:01.877791: done 
2025-04-02 15:40:01.877972: This epoch took 130.488034 s
 
2025-04-02 15:40:01.878237: 
epoch:  265 
2025-04-02 15:42:03.747638: train loss : -0.6448 
2025-04-02 15:42:19.053860: validation loss: -0.3901 
2025-04-02 15:42:19.054955: Average global foreground Dice: [np.float32(0.8049), np.float32(0.6181)] 
2025-04-02 15:42:19.055470: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 15:42:19.663751: lr: 0.000757 
2025-04-02 15:42:19.664140: This epoch took 137.785283 s
 
2025-04-02 15:42:19.664330: 
epoch:  266 
2025-04-02 15:44:13.181612: train loss : -0.7096 
2025-04-02 15:44:29.127850: validation loss: -0.1106 
2025-04-02 15:44:29.135287: Average global foreground Dice: [np.float32(0.7198), np.float32(0.5213)] 
2025-04-02 15:44:29.136163: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 15:44:29.553738: lr: 0.000756 
2025-04-02 15:44:29.554387: This epoch took 129.889559 s
 
2025-04-02 15:44:29.555243: 
epoch:  267 
2025-04-02 15:46:27.184277: train loss : -0.7002 
2025-04-02 15:46:42.477253: validation loss: -0.0579 
2025-04-02 15:46:42.478423: Average global foreground Dice: [np.float32(0.6839), np.float32(0.4963)] 
2025-04-02 15:46:42.479116: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 15:46:42.888885: lr: 0.000755 
2025-04-02 15:46:42.889051: This epoch took 133.333483 s
 
2025-04-02 15:46:42.889113: 
epoch:  268 
2025-04-02 15:48:38.059112: train loss : -0.6825 
2025-04-02 15:48:54.032198: validation loss: -0.2822 
2025-04-02 15:48:54.033037: Average global foreground Dice: [np.float32(0.7284), np.float32(0.5323)] 
2025-04-02 15:48:54.033545: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 15:48:54.437879: lr: 0.000754 
2025-04-02 15:48:54.438084: This epoch took 131.548908 s
 
2025-04-02 15:48:54.438220: 
epoch:  269 
2025-04-02 15:50:54.902883: train loss : -0.7051 
2025-04-02 15:51:12.732932: validation loss: -0.2535 
2025-04-02 15:51:12.733857: Average global foreground Dice: [np.float32(0.7604), np.float32(0.5616)] 
2025-04-02 15:51:12.734410: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 15:51:13.135948: lr: 0.000753 
2025-04-02 15:51:13.136448: saving scheduled checkpoint file... 
2025-04-02 15:51:13.164690: saving checkpoint... 
2025-04-02 15:51:13.572617: done, saving took 0.44 seconds 
2025-04-02 15:51:13.576179: done 
2025-04-02 15:51:13.576268: This epoch took 139.137978 s
 
2025-04-02 15:51:13.576339: 
epoch:  270 
2025-04-02 15:53:04.496021: train loss : -0.6959 
2025-04-02 15:53:20.802561: validation loss: -0.2776 
2025-04-02 15:53:20.803881: Average global foreground Dice: [np.float32(0.7886), np.float32(0.5923)] 
2025-04-02 15:53:20.804632: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 15:53:21.207871: lr: 0.000752 
2025-04-02 15:53:21.208353: This epoch took 127.631934 s
 
2025-04-02 15:53:21.208724: 
epoch:  271 
2025-04-02 15:55:10.415660: train loss : -0.6699 
2025-04-02 15:55:24.818408: validation loss: -0.3359 
2025-04-02 15:55:24.819827: Average global foreground Dice: [np.float32(0.7949), np.float32(0.5836)] 
2025-04-02 15:55:24.820481: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 15:55:25.246808: lr: 0.000751 
2025-04-02 15:55:25.247260: This epoch took 124.038137 s
 
2025-04-02 15:55:25.247577: 
epoch:  272 
2025-04-02 15:57:19.763484: train loss : -0.6912 
2025-04-02 15:57:34.745360: validation loss: -0.1877 
2025-04-02 15:57:34.746228: Average global foreground Dice: [np.float32(0.7947), np.float32(0.6047)] 
2025-04-02 15:57:34.746780: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 15:57:35.090708: lr: 0.000751 
2025-04-02 15:57:35.091028: This epoch took 129.843011 s
 
2025-04-02 15:57:35.091214: 
epoch:  273 
2025-04-02 15:59:32.888012: train loss : -0.6658 
2025-04-02 15:59:49.512147: validation loss: -0.3893 
2025-04-02 15:59:49.513212: Average global foreground Dice: [np.float32(0.8214), np.float32(0.6315)] 
2025-04-02 15:59:49.513566: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 15:59:49.896241: lr: 0.00075 
2025-04-02 15:59:49.896431: This epoch took 134.805120 s
 
2025-04-02 15:59:49.896503: 
epoch:  274 
2025-04-02 16:01:44.943430: train loss : -0.6792 
2025-04-02 16:01:58.353954: validation loss: -0.1433 
2025-04-02 16:01:58.354738: Average global foreground Dice: [np.float32(0.7709), np.float32(0.571)] 
2025-04-02 16:01:58.355264: (interpret this as an estimate for the Dice of the different classes. This is not exact.) 
2025-04-02 16:01:58.764595: lr: 0.000749 
2025-04-02 16:01:58.764919: saving scheduled checkpoint file... 
2025-04-02 16:01:58.788723: saving checkpoint... 
2025-04-02 16:01:59.172378: done, saving took 0.41 seconds 
2025-04-02 16:01:59.176310: done 
2025-04-02 16:01:59.176919: This epoch took 129.280357 s
 
2025-04-02 16:01:59.177515: 
epoch:  275 

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import utils\n",
    "import json\n",
    "from os.path import join\n",
    "from instance2border_core import instance2border_core\n",
    "import zarr\n",
    "from acvl_utils.miscellaneous.ptqdm import ptqdm\n",
    "import pickle\n",
    "from skimage.measure import regionprops\n",
    "from typing import List, Tuple, Dict, Any\n",
    "import numpy as np\n",
    "import cc3d\n",
    "import copy\n",
    "from scipy.ndimage import label as nd_label\n",
    "from skimage.morphology import footprint_rectangle, dilation\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from tqdm import tqdm\n",
    "import numpy_indexed as npi\n",
    "from typing import Tuple, Type\n",
    "from skimage.morphology import binary_erosion, dilation, ball, footprint_rectangle\n",
    "\n",
    "\n",
    "def preprocess_all(load_dir: str, names: List[str], save_dir: str, target_spacing: float,\n",
    "                   target_particle_size_in_pixel: int, dataset_name: str, processes: int,\n",
    "                   border_thickness_in_pixel: int, gpu: bool, binary: bool, device: int) -> None:\n",
    "    \"\"\"\n",
    "    Preprocesses all the samples in the dataset.\n",
    "\n",
    "    :param load_dir: Path to the base directory that contains the dataset structured in the form of the directories 'images' and 'instance_seg' and the files metadata.json.\n",
    "    :param names: The name(s) without extension of the image(s) that should be used for training.\n",
    "    :param save_dir: Path to the preprocessed dataset directory.\n",
    "    :param target_spacing: The target spacing in millimeters.\n",
    "    :param target_particle_size_in_pixel: The target particle size in pixels.\n",
    "    :param dataset_name: The name of the preprocessed dataset.\n",
    "    :param processes: Number of processes to use for parallel processing. None to disable multiprocessing.\n",
    "    :param border_thickness_in_pixel: Border thickness in pixel.\n",
    "    :param gpu: Flag indicating whether to use the GPU for preprocessing.\n",
    "    :param binary: Flag indicating whether to a binary mask is used instead of instance segmentation.\n",
    "    :param device: Value indicating which GPU to use (0 or 1 only)\n",
    "    \"\"\"\n",
    "    metadata_load_filepath = join(load_dir, \"metadata.json\")\n",
    "\n",
    "    with open(metadata_load_filepath) as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    target_spacing = [target_spacing] * 3\n",
    "    target_particle_size_in_pixel = [target_particle_size_in_pixel] * 3\n",
    "\n",
    "    image_save_dir = join(save_dir, dataset_name, \"imagesTr\")\n",
    "    semantic_seg_save_dir = join(save_dir, dataset_name, \"labelsTr\")\n",
    "    instance_seg_save_dir = join(save_dir, dataset_name, \"labelsTr_instance\")\n",
    "    semantic_seg_zarr_save_dir = join(save_dir, dataset_name, \"labelsTr_zarr\")\n",
    "    instance_seg_zarr_save_dir = join(save_dir, dataset_name, \"labelsTr_instance_zarr\")\n",
    "    Path(instance_seg_save_dir).mkdir(parents=True, exist_ok=True)\n",
    "    Path(image_save_dir).mkdir(parents=True, exist_ok=True)\n",
    "    Path(semantic_seg_save_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for name in names:\n",
    "        if name not in metadata:\n",
    "            raise RuntimeError(\"{} is missing in metadata!\".format(name))\n",
    "\n",
    "    image_load_filepaths = [join(load_dir, \"images\", name + \".nii.gz\") for name in names]\n",
    "    if binary:\n",
    "        seg_load_filepaths = [join(load_dir, \"binary_mask\", name + \".nii.gz\") for name in names]\n",
    "    else:\n",
    "        seg_load_filepaths = [join(load_dir, \"instance_seg\", name + \".nii.gz\") for name in names]\n",
    "\n",
    "    if processes is None:\n",
    "        for i in tqdm(range(len(names))):\n",
    "            preprocess_single(i, names=names, image_load_filepaths=image_load_filepaths, seg_load_filepaths=seg_load_filepaths,\n",
    "                      metadata_load_filepath=metadata_load_filepath, image_save_dir=image_save_dir,\n",
    "                      semantic_seg_save_dir=semantic_seg_save_dir, instance_seg_save_dir=instance_seg_save_dir,\n",
    "                      semantic_seg_zarr_save_dir=semantic_seg_zarr_save_dir, instance_seg_zarr_save_dir=instance_seg_zarr_save_dir,\n",
    "                      target_spacing=target_spacing, target_particle_size_in_pixel=target_particle_size_in_pixel,\n",
    "                      border_thickness_in_pixel=border_thickness_in_pixel, gpu=gpu, binary=binary, device=device)\n",
    "    else:\n",
    "        ptqdm(preprocess_single, range(len(names)), processes, names=names, image_load_filepaths=image_load_filepaths,\n",
    "                  seg_load_filepaths=seg_load_filepaths, metadata_load_filepath=metadata_load_filepath,\n",
    "                  image_save_dir=image_save_dir, semantic_seg_save_dir=semantic_seg_save_dir,\n",
    "                  instance_seg_save_dir=instance_seg_save_dir, semantic_seg_zarr_save_dir=semantic_seg_zarr_save_dir,\n",
    "                  instance_seg_zarr_save_dir=instance_seg_zarr_save_dir, target_spacing=target_spacing,\n",
    "                  target_particle_size_in_pixel=target_particle_size_in_pixel,\n",
    "                  border_thickness_in_pixel=border_thickness_in_pixel, gpu=gpu, binary=binary, device=device)\n",
    "\n",
    "    utils.generate_dataset_json(join(save_dir, dataset_name, 'dataset.json'), join(save_dir, dataset_name, \"imagesTr\"), None, (\"noNorm\",), {0: 'bg', 1: 'core', 2: 'border'}, dataset_name)\n",
    "\n",
    "    gen_regionprops(join(save_dir, dataset_name, \"labelsTr_instance\"), join(save_dir, dataset_name, \"regionprops.pkl\"))\n",
    "\n",
    "\n",
    "def preprocess_single(i: int,\n",
    "                      names: List[str],\n",
    "                      image_load_filepaths: List[str],\n",
    "                      seg_load_filepaths: List[str],\n",
    "                      metadata_load_filepath: str,\n",
    "                      image_save_dir: str,\n",
    "                      semantic_seg_save_dir: str,\n",
    "                      instance_seg_save_dir: str,\n",
    "                      semantic_seg_zarr_save_dir: str,\n",
    "                      instance_seg_zarr_save_dir: str,\n",
    "                      target_spacing: List[float],\n",
    "                      target_particle_size_in_pixel: List[int],\n",
    "                      border_thickness_in_pixel: int,\n",
    "                      gpu: bool,\n",
    "                      binary: bool,\n",
    "                      device: int) -> None:\n",
    "    \"\"\"\n",
    "    Preprocess a single 3D particle segmentation image.\n",
    "\n",
    "    Args:\n",
    "        i (int): Index of the image to preprocess.\n",
    "        names (List[str]): Names of the images to preprocess.\n",
    "        image_load_filepaths (List[str]): Paths to the input 3D particle segmentation image files.\n",
    "        seg_load_filepaths (List[str]): Paths to the input instance segmentation or border-core representation image files.\n",
    "        metadata_load_filepath (str): Path to the metadata file.\n",
    "        image_save_dir (str): Path to the directory to save the preprocessed images.\n",
    "        semantic_seg_save_dir (str): Path to the directory to save the semantic segmentation images.\n",
    "        instance_seg_save_dir (str): Path to the directory to save the instance segmentation images.\n",
    "        semantic_seg_zarr_save_dir (str): Path to the directory to save the semantic segmentation images in zarr format.\n",
    "        instance_seg_zarr_save_dir (str): Path to the directory to save the instance segmentation images in zarr format.\n",
    "        target_spacing (List[float]): Target spacing in millimeters.\n",
    "        target_particle_size_in_pixel (List[int]): Target particle size in pixels.\n",
    "        border_thickness_in_pixel (int): Border thickness in pixels.\n",
    "        gpu (bool): If True, use GPU for resampling.\n",
    "        binary (bool): If True, a binary mask is used instead of instance segmentation.\n",
    "        device (int): Value indicating which GPU to use (0 or 1 only)\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    name = names[i]\n",
    "    image_load_filepath = image_load_filepaths[i]\n",
    "    seg_load_filepath = seg_load_filepaths[i]\n",
    "\n",
    "    with open(metadata_load_filepath) as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    image = utils.load_nifti(image_load_filepath)\n",
    "\n",
    "    # zscore = {\"mean\": zscore[0], \"std\": zscore[1]}\n",
    "    zscore = {\"mean\": np.mean(image), \"std\": np.std(image)} # Automated Z-Scoring per image\n",
    "    image = utils.standardize(image, zscore)\n",
    "\n",
    "    image_shape = image.shape\n",
    "    source_particle_size_in_mm = [metadata[name][\"particle_size\"]] * 3\n",
    "    source_spacing = [metadata[name][\"spacing\"]] * 3\n",
    "    target_particle_size_in_mm = tuple(utils.pixel2mm(target_particle_size_in_pixel, target_spacing))\n",
    "\n",
    "    size_conversion_factor = utils.compute_size_conversion_factor(source_particle_size_in_mm, source_spacing, target_particle_size_in_mm, target_spacing)\n",
    "    target_patch_size_in_pixel = np.rint(np.asarray(image_shape) / size_conversion_factor).astype(int)\n",
    "    target_patch_size_in_pixel = target_patch_size_in_pixel.tolist()\n",
    "\n",
    "    image = utils.resample(image, target_patch_size_in_pixel, 1/(size_conversion_factor[0]), gpu=gpu, disable=True, device=device)\n",
    "    patch_name = \"{}\".format(name)\n",
    "    image_save_filepath = join(image_save_dir, patch_name + \"_0000.nii.gz\")\n",
    "    utils.save_nifti(image_save_filepath, image, spacing=target_spacing) # Why not saved as np.uint16? Originally saving it as np.float32: I think it is because of the normalization which converts to float 3/8/25\n",
    "\n",
    "    if binary:\n",
    "        semantic_seg = utils.load_nifti(seg_load_filepath)\n",
    "        semantic_seg = utils.resample(semantic_seg, target_patch_size_in_pixel, 1/(size_conversion_factor[0]), gpu=gpu, seg=True, disable=True, device=device)\n",
    "        semantic_seg = generate_bordercore(semantic_seg)\n",
    "        instance_seg, _ = border_core2instance(semantic_seg)\n",
    "    else:\n",
    "        instance_seg = utils.load_nifti(seg_load_filepath)\n",
    "        instance_seg = utils.resample(instance_seg, target_patch_size_in_pixel, 1/(size_conversion_factor[0]), gpu=gpu, seg=True, disable=True, device=device)\n",
    "        semantic_seg = instance2border_core(instance_seg, border_thickness_in_pixel)\n",
    "\n",
    "    instance_seg_save_filepath = join(instance_seg_save_dir, patch_name + \".nii.gz\")\n",
    "    utils.save_nifti(instance_seg_save_filepath, instance_seg, spacing=target_spacing, is_seg=True, dtype=np.uint16)\n",
    "    semantic_seg_save_filepath = join(semantic_seg_save_dir, patch_name + \".nii.gz\")\n",
    "    utils.save_nifti(semantic_seg_save_filepath, semantic_seg, spacing=target_spacing, is_seg=True, dtype=np.uint8)\n",
    "    semantic_seg_zarr_save_filepath = join(semantic_seg_zarr_save_dir, patch_name + \".zarr\")\n",
    "    semantic_seg = zarr.array(semantic_seg)\n",
    "    zarr.save(semantic_seg_zarr_save_filepath, semantic_seg, chunks=(64, 64, 64))\n",
    "    instance_seg_zarr_save_filepath = join(instance_seg_zarr_save_dir, patch_name + \".zarr\")\n",
    "    instance_seg = zarr.array(instance_seg)\n",
    "    zarr.save(instance_seg_zarr_save_filepath, instance_seg, chunks=(64, 64, 64))\n",
    "\n",
    "\n",
    "def gen_regionprops(load_dir: str, metadata_filepath: str) -> None:\n",
    "    \"\"\"Extracts regionprops features from the given instance segmentation data and saves the data to the given file.\n",
    "\n",
    "    Args:\n",
    "        load_dir (str): Absolute path to the directory containing instance segmentation data.\n",
    "        metadata_filepath (str): Absolute path to the file where the extracted regionprops features should be saved.\n",
    "    \"\"\"\n",
    "    names = utils.load_filepaths(load_dir, return_path=False, return_extension=False)\n",
    "    metadata = {}\n",
    "\n",
    "    len_props_total, len_props_filtered_total = 0, 0\n",
    "    for name in tqdm(names):\n",
    "        instance_seg = utils.load_nifti(join(load_dir, name + \".nii.gz\"))\n",
    "        props, len_props, len_props_filtered = gen_regionprops_single(instance_seg)\n",
    "        len_props_total += len_props\n",
    "        len_props_filtered_total += len_props_filtered\n",
    "        metadata[name] = props\n",
    "\n",
    "    with open(metadata_filepath, 'wb') as handle:\n",
    "        pickle.dump(metadata, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "def gen_regionprops_single(instance_seg: np.ndarray) -> Tuple[Dict[int, Tuple[int, int, int, int, int, int]], int, int]:\n",
    "    \"\"\"Extracts regionprops features from a single instance segmentation volume.\n",
    "\n",
    "    Args:\n",
    "        instance_seg (np.ndarray): A 3D numpy array containing the instance segmentation data.\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing the extracted regionprops features, the number of total regionprops, and the number of filtered regionprops.\n",
    "    \"\"\"\n",
    "    props = {prop.label: prop.bbox for prop in regionprops(instance_seg)}\n",
    "\n",
    "    props_filtered = {}\n",
    "    image_shape = instance_seg.shape\n",
    "    for label, bbox in props.items():\n",
    "        bbox_reshaped = [[bbox[i], bbox[i + len(bbox) // 2]] for i in range(len(bbox) // 2)]\n",
    "        bbox_reshaped = np.asarray(bbox_reshaped)\n",
    "        ok = True\n",
    "        for axis in range(len(image_shape)):\n",
    "            if bbox_reshaped[axis][0] == 0 or bbox_reshaped[axis][1] == image_shape[axis]:\n",
    "                ok = False\n",
    "        if ok:\n",
    "            props_filtered[label] = bbox\n",
    "\n",
    "    return props_filtered, len(props), len(props_filtered)\n",
    "\n",
    "\n",
    "def generate_bordercore(image, border_thickness=1, n_erosions=1):\n",
    "    \"\"\"\n",
    "    Generate border pixels from 3D binary masks.\n",
    "    \n",
    "    Parameters:\n",
    "        image (np.ndarray): 3D binary image (0s and 255s, or really 0 and any other positive value).\n",
    "        border_thickness (int): Thickness of the border region.\n",
    "        n_erosions (int): Number of erosion iterations.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Image with cores labeled as 255 and borders labeled as 127.\n",
    "    \"\"\"\n",
    "    # Ensure binary input (convert 255 to 1 for processing)\n",
    "    binary_image = image > 0\n",
    "\n",
    "    # Define 3D structuring elements\n",
    "    erosion_kernel = ball(n_erosions)  # Spherical structuring element for erosion\n",
    "    dilation_kernel = footprint_rectangle([2 * border_thickness + 1, 2 * border_thickness + 1, 2 * border_thickness + 1])  # Cubic structuring element for dilation\n",
    "\n",
    "    # Apply 3D erosion\n",
    "    eroded_image = binary_erosion(binary_image, erosion_kernel)\n",
    "\n",
    "    # Apply 3D dilation\n",
    "    dilated = dilation(eroded_image, dilation_kernel)\n",
    "\n",
    "    # Assign labels: cores as 1, borders as 2, background as 0\n",
    "    bordercore = np.zeros_like(image, dtype=np.uint8)\n",
    "    bordercore[eroded_image] = 1  # Core pixels\n",
    "    bordercore[dilated & ~eroded_image] = 2  # Border pixels\n",
    "\n",
    "    return bordercore\n",
    "\n",
    "\n",
    "def border_core2instance(border_core: np.ndarray, dtype: Type = np.uint16) -> Tuple[np.ndarray, int]:\n",
    "    border_core_array = np.array(border_core)\n",
    "    component_seg = cc3d.connected_components(border_core_array > 0).astype(dtype)\n",
    "    instances = np.zeros_like(border_core, dtype=dtype)\n",
    "    num_instances = 0\n",
    "    props = {i: bbox for i, bbox in enumerate(cc3d.statistics(component_seg)[\"bounding_boxes\"]) if i != 0}\n",
    "    \n",
    "    for label, bbox in tqdm(props.items(), desc=\"Border-Core2Instance\"):\n",
    "        filter_mask = component_seg[bbox] == label\n",
    "        border_core_patch = copy.deepcopy(border_core[bbox])\n",
    "        border_core_patch[filter_mask != 1] = 0\n",
    "        instances_patch = border_core_component2instance_dilation(border_core_patch).astype(dtype)\n",
    "        instances_patch[instances_patch > 0] += num_instances\n",
    "        num_instances = max(num_instances, np.max(instances_patch))\n",
    "        patch_labels = np.unique(instances_patch)\n",
    "        patch_labels = patch_labels[patch_labels > 0]\n",
    "        for patch_label in patch_labels:\n",
    "            instances[bbox][instances_patch == patch_label] = patch_label\n",
    "    return instances, num_instances\n",
    "\n",
    "def border_core_component2instance_dilation(patch: np.ndarray, core_label: int = 2, border_label: int = 1) -> np.ndarray:\n",
    "    '''The values used for core and border don't actually matter: \n",
    "       'num_instances = nd_label(patch == core_label, output=core_instances)' assigns unique instance labels where patch == core_label, regardless of whether core_label is 1, 255, or any other value.\n",
    "       'border = patch == border_label' creates a binary mask (True for border, False elsewhere). Whether border_label is 2, 127, or any other value does not affect behavior.\n",
    "       'dilated = dilation(core_instances, footprint_rectangle([3,3,3]))' expands the core_instances which are the instance labels (1-# of instances) and the background (0). Thus, all instances are \"brighter\" than the surrounding background (no border that is brighter/darker than core).\n",
    "    '''\n",
    "    core_instances = np.zeros_like(patch, dtype=np.uint16)\n",
    "    num_instances = nd_label(patch == core_label, output=core_instances)\n",
    "    if num_instances == 0:\n",
    "        return patch\n",
    "    # patch, core_instances, num_instances = remove_small_cores(patch, core_instances, core_label, border_label) # Weird effect on segmentation...\n",
    "    # core_instances = np.zeros_like(patch, dtype=np.uint16)\n",
    "    # num_instances = nd_label(patch == core_label, output=core_instances)\n",
    "    # if num_instances == 0:\n",
    "    #     return patch\n",
    "    instances = copy.deepcopy(core_instances)\n",
    "    border = patch == border_label\n",
    "    while np.sum(border) > 0:\n",
    "        dilated = dilation(core_instances, footprint_rectangle([3,3,3])) # Bottleneck when many instances\n",
    "        dilated[patch == 0] = 0\n",
    "        diff = (core_instances == 0) & (dilated != core_instances)\n",
    "        instances[diff & border] = dilated[diff & border]\n",
    "        border[diff] = 0\n",
    "        core_instances = dilated\n",
    "    return instances\n",
    "\n",
    "def remove_small_cores(\n",
    "    patch: np.ndarray, \n",
    "    core_instances: np.ndarray, \n",
    "    core_label: int, \n",
    "    border_label: int, \n",
    "    min_distance: float = 1, \n",
    "    min_ratio_threshold: float = 0.95, \n",
    "    max_distance: float = 3, \n",
    "    max_ratio_threshold: float = 0.0) -> Tuple[np.ndarray, np.ndarray, int]:\n",
    "\n",
    "    distances = distance_transform_edt(patch == core_label)\n",
    "    core_ids = np.unique(core_instances)\n",
    "    core_ids_to_remove = []\n",
    "    for core_id in core_ids:\n",
    "        core_distances = distances[core_instances == core_id]\n",
    "        num_min_distances = np.count_nonzero(core_distances <= min_distance)\n",
    "        num_max_distances = np.count_nonzero(core_distances >= max_distance)\n",
    "        num_core_voxels = np.count_nonzero(core_instances == core_id)\n",
    "        min_ratio = num_min_distances / num_core_voxels\n",
    "        max_ratio = num_max_distances / num_core_voxels\n",
    "        if (min_ratio_threshold is None or min_ratio >= min_ratio_threshold) and (max_ratio_threshold is None or max_ratio <= max_ratio_threshold):\n",
    "            core_ids_to_remove.append(core_id)\n",
    "    num_cores = len(core_ids) - len(core_ids_to_remove)\n",
    "    if len(core_ids_to_remove) > 0:\n",
    "        target_values = np.zeros_like(core_ids_to_remove, dtype=int)\n",
    "        shape = patch.shape\n",
    "        core_instances = npi.remap(core_instances.flatten(), core_ids_to_remove, target_values).reshape(shape)\n",
    "        patch[(patch == core_label) & (core_instances == 0)] = border_label\n",
    "\n",
    "    return patch, core_instances, num_cores\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument('-i', \"--input\", required=True,\n",
    "#                         help=\"Absolute input path to the base folder that contains the dataset structured in the form of the directories 'images' and 'instance_seg' and the file metadata.json.\")\n",
    "#     parser.add_argument('-o', \"--output\", required=True, help=\"Absolute output path to the preprocessed dataset directory.\")\n",
    "#     parser.add_argument('-n', \"--name\", required=False, type=str, default=None, nargs=\"+\", help=\"(Optional) The name(s) without extension of the image(s) that should be used for training. Multiple names must be separated by spaces.\")\n",
    "#     parser.add_argument('-t', '--task', required=False, default=500, type=int, help=\"(Optional) The task id that should be assigned to this dataset.\")\n",
    "#     parser.add_argument('-z', '--zscore', default=(5850.29762143569, 7078.294543817302), required=False, type=float, nargs=2,\n",
    "#                         help=\"(Optional) The target spacing in millimeters given as three numbers separate by spaces.\")\n",
    "#     parser.add_argument('-target_particle_size', default=60, required=False, type=int,\n",
    "#                         help=\"(Optional) The target particle size in pixels given as three numbers separate by spaces.\")\n",
    "#     parser.add_argument('-target_spacing', default=0.1, required=False, type=float,\n",
    "#                         help=\"(Optional) The target spacing in millimeters given as three numbers separate by spaces.\")\n",
    "#     parser.add_argument('-p', '--processes', required=False, default=None, type=int, help=\"(Optional) Number of processes to use for parallel processing. None to disable multiprocessing.\")\n",
    "#     parser.add_argument('-thickness', required=False, default=2, type=int, help=\"(Optional) Border thickness in pixel.\")\n",
    "#     parser.add_argument('--disable_gpu', required=False, default=False, action=\"store_true\", help=\"(Optional) Disables use of the GPU for preprocessing.\")\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     parser = argparse.ArgumentParser(description=\"Preprocess a dataset for training a particle segmentation model.\")\n",
    "\n",
    "#     names = args.name\n",
    "\n",
    "#     if names is None:\n",
    "#         names = utils.load_filepaths(join(args.input, \"images\"), extension=\".nii.gz\", return_path=False, return_extension=False)\n",
    "\n",
    "#     print(\"Samples: \", names)\n",
    "#     print(\"Num samples: \", len(names))\n",
    "\n",
    "#     dataset_name = \"Task{}_ParticleSeg3D\".format(str(args.task).zfill(3))\n",
    "\n",
    "#     preprocess_all(args.input, names, args.output, args.target_spacing, args.target_particle_size, dataset_name, args.processes, args.thickness, not args.disable_gpu, args.zscore)\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def setup_paths(dir_location, is_original_data, output_to_cloud, task):\n",
    "    if dir_location.lower() == 'internal':\n",
    "        base_path = r'C:\\Senior_Design'\n",
    "    elif dir_location.lower() == 'external':\n",
    "        base_path = r'D:\\Senior_Design'\n",
    "    elif dir_location.lower() == 'cloud':\n",
    "        base_path = r'C:\\Users\\dchen\\OneDrive - University of Connecticut\\Courses\\Year 4\\Fall 2024\\BME 4900 and 4910W (Kumavor)\\Python\\Files'\n",
    "    elif dir_location.lower() == 'refine':\n",
    "        base_path = r'D:\\Darren\\Files'\n",
    "    else:\n",
    "        raise ValueError('Invalid directory location type')\n",
    "    \n",
    "    base_input_path = os.path.join(base_path, 'database')\n",
    "    if is_original_data:\n",
    "        input_path = os.path.join(base_input_path, 'orignal_dataset', 'training', 'Task' + str(task))\n",
    "    else:\n",
    "        input_path = os.path.join(base_input_path, 'tablet_dataset', 'training', 'Task' + str(task))\n",
    "    \n",
    "    if not os.path.isdir(input_path):\n",
    "        raise ValueError(\"This input path is not valid:\\n\" + input_path)\n",
    "\n",
    "    if output_to_cloud:\n",
    "        # base_path = r'C:\\Users\\dchen\\OneDrive - University of Connecticut\\Courses\\Year 4\\Fall 2024\\BME 4900 and 4910W (Kumavor)\\Python\\Files'\n",
    "        base_path = r'D:\\Darren\\OneDrive - University of Connecticut\\Courses\\Year 4\\Fall 2024\\BME 4900 and 4910W (Kumavor)\\Python\\Files'\n",
    "    output_path = os.path.join(base_path, 'training', 'nnUNet_raw_data_base', 'nnUNet_raw_data')\n",
    "    if not os.path.isdir(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    print('Paths set')\n",
    "    return input_path, output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths set\n",
      "Samples:  ['2_Tablet_Aug1', '2_Tablet_Aug2', '2_Tablet_Aug3', '2_Tablet_Aug4', '2_Tablet_Aug5', '4_GenericD12_Aug1', '4_GenericD12_Aug2', '4_GenericD12_Aug3', '4_GenericD12_Aug4', '4_GenericD12_Aug5', '5_ClaritinD12_Aug1', '5_ClaritinD12_Aug2', '5_ClaritinD12_Aug3', '5_ClaritinD12_Aug4', '5_ClaritinD12_Aug5']\n",
      "Num samples:  15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import utils\n",
    "from os.path import join\n",
    "\n",
    "# Set argument values directly\n",
    "input_path = \"/absolute/path/to/dataset\"  # Absolute path to the directory containing 'metadata.json', 'images', and either 'instance_seg' or 'border_core' directories\n",
    "output_path = \"/absolute/path/to/output\"  # Absolute path where the preprocessed dataset will be stored\n",
    "names = None  # List of image names (without extensions) to use for training; None to use all available images\n",
    "task = '504'  # Task ID (int) assigned to the dataset\n",
    "target_spacing = 0.1  # Target spacing in millimeters\n",
    "target_particle_size = 60  # Target particle size in pixels\n",
    "processes = None  # Number of processes for parallel processing; None disables multiprocessing\n",
    "thickness = 4  # Border thickness in pixels (erosion only)\n",
    "disable_gpu = False  # If True, disables GPU usage for preprocessing\n",
    "binary = True # Used if the border-core representation is used instead of instance segmentation.\n",
    "device = 1 # Value indicating which GPU to use.\n",
    "\n",
    "# Paths\n",
    "input_path, output_path = setup_paths('refine', False, False, task)\n",
    "\n",
    "if names is None:\n",
    "    names = utils.load_filepaths(join(input_path, \"images\"), extension=\".nii.gz\", return_path=False, return_extension=False)\n",
    "\n",
    "print(\"Samples: \", names)\n",
    "print(\"Num samples: \", len(names))\n",
    "\n",
    "dataset_name = \"Task{}_ParticleSeg3D\".format(str(task).zfill(3))\n",
    "\n",
    "preprocess_all(input_path, names, output_path, target_spacing, target_particle_size, dataset_name, processes, thickness, not disable_gpu, binary, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Senior_Design_py310_source",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

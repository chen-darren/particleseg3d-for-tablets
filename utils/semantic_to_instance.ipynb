{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def setup_paths(dir_location, is_original_data):\n",
    "    if dir_location.lower() == 'internal':\n",
    "        base_path = r'C:\\Senior_Design'\n",
    "    elif dir_location.lower() == 'external':\n",
    "        base_path = r'D:\\Senior_Design'\n",
    "    elif dir_location.lower() == 'cloud':\n",
    "        base_path = r'C:\\Users\\dchen\\OneDrive - University of Connecticut\\Courses\\Year 4\\Fall 2024\\BME 4900 and 4910W (Kumavor)\\Python\\Files'\n",
    "    elif dir_location.lower() == 'refine':\n",
    "        base_path = r'D:\\Darren\\Files'\n",
    "    else:\n",
    "        raise ValueError('Invalid directory location type')\n",
    "    \n",
    "    base_gt_path = os.path.join(base_path, 'database')\n",
    "    if is_original_data:\n",
    "        gt_path = os.path.join(base_gt_path, 'orignal_dataset', 'segmented', 'tiff')\n",
    "    else:\n",
    "        gt_path = os.path.join(base_gt_path, 'tablet_dataset', 'segmented', 'tiff')\n",
    "    \n",
    "    binary_path = gt_path.replace('segmented', 'binary')  \n",
    "    if not os.path.isdir(binary_path):\n",
    "        os.makedirs(binary_path)\n",
    "    bordercore_path = gt_path.replace('segmented', 'bordercore')  \n",
    "    if not os.path.isdir(bordercore_path):\n",
    "        os.makedirs(bordercore_path)  \n",
    "    instance_path = gt_path.replace('segmented', 'instance_v2')\n",
    "    if not os.path.isdir(instance_path):\n",
    "        os.makedirs(instance_path)\n",
    "\n",
    "    print('Paths set')\n",
    "    return gt_path, binary_path, bordercore_path, instance_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Pixel Values from Ground Truth TIFF Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_unique_pixel_values(folder_path):\n",
    "    \"\"\"Extract unique pixel values and their counts from a TIFF stack in a folder.\"\"\"\n",
    "    pixel_values = []\n",
    "    \n",
    "    for filename in sorted(os.listdir(folder_path)):\n",
    "        if filename.endswith('.tif') or filename.endswith('.tiff'):\n",
    "            img = tiff.imread(os.path.join(folder_path, filename))\n",
    "            pixel_values.append(img.flatten())  # Flatten to a 1D array\n",
    "    \n",
    "    # Concatenate all pixel values and get unique values with counts\n",
    "    all_pixels = np.concatenate(pixel_values)\n",
    "    unique_values, counts = np.unique(all_pixels, return_counts=True)\n",
    "    \n",
    "    return unique_values, counts  # Return both unique values and their frequencies\n",
    "\n",
    "def highlight_pixel_value_one_image(folder_path, target_value):\n",
    "    \"\"\"Display an image where only a specific pixel value is shown, using the middle file in the folder.\"\"\"\n",
    "    tiff_files = sorted([f for f in os.listdir(folder_path) if f.endswith('.tif') or f.endswith('.tiff')])\n",
    "    \n",
    "    if not tiff_files:\n",
    "        raise FileNotFoundError(\"No TIFF files found in the folder.\")\n",
    "    \n",
    "    # Select the middle file\n",
    "    middle_file = tiff_files[len(tiff_files) // 2]\n",
    "    img = tiff.imread(os.path.join(folder_path, middle_file))  # Load the middle file\n",
    "    \n",
    "    # Create a mask where only the target pixel value is highlighted\n",
    "    highlighted_img = np.where(img == target_value, target_value, 0).astype(np.uint8)\n",
    "    \n",
    "    plt.imshow(highlighted_img, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()  # Display without saving\n",
    "\n",
    "def load_tiff_stack_from_dir(directory):\n",
    "    \"\"\"Loads a stack of TIFF images from a directory into a 3D NumPy array.\"\"\"\n",
    "    tiff_files = sorted([f for f in os.listdir(directory) if f.lower().endswith('.tiff') or f.lower().endswith('.tif')])\n",
    "    \n",
    "    if not tiff_files:\n",
    "        raise FileNotFoundError(\"No TIFF files found in the directory.\")\n",
    "\n",
    "    stack = [tiff.imread(os.path.join(directory, f)) for f in tiff_files]\n",
    "    return np.stack(stack, axis=0)  # Stack images along the first dimension (depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_path = r'd:\\Darren\\Files\\database\\tablet_dataset\\segmented\\tiff\\2_Tablet'\n",
    "pixel_values, counts = extract_unique_pixel_values(tiff_path)\n",
    "print(pixel_values)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_path = r'd:\\Darren\\Files\\database\\tablet_dataset\\segmented\\tiff\\2_Tablet'\n",
    "highlight_pixel_value_one_image(tiff_path, target_value=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_path = r'd:\\Darren\\Files\\database\\tablet_dataset\\segmented\\tiff\\4_GenericD12'\n",
    "pixel_values, counts = extract_unique_pixel_values(tiff_path)\n",
    "print(pixel_values)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_path = r'd:\\Darren\\Files\\database\\tablet_dataset\\segmented\\tiff\\4_GenericD12'\n",
    "highlight_pixel_value_one_image(tiff_path, target_value=182)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_path = r'd:\\Darren\\Files\\database\\tablet_dataset\\segmented\\tiff\\5_ClaritinD12'\n",
    "pixel_values, counts = extract_unique_pixel_values(tiff_path)\n",
    "print(pixel_values)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_path = r'd:\\Darren\\Files\\database\\tablet_dataset\\segmented\\tiff\\5_ClaritinD12'\n",
    "highlight_pixel_value_one_image(tiff_path, target_value=159)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic to Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_to_binary(input_path, output_path, target_value):\n",
    "    tiff_stack = load_tiff_stack_from_dir(input_path)\n",
    "    \n",
    "    # Create a mask where only the target pixel value is highlighted\n",
    "    binary_mask = np.where(tiff_stack == target_value, 255, 0).astype(np.uint8)\n",
    "    \n",
    "    for i in tqdm(range(binary_mask.shape[0]), desc=f\"Processing {os.path.basename(input_path)}\", unit=\"slice\"):\n",
    "        binary_path = os.path.join(output_path, f\"slice_{i:04d}.tiff\")\n",
    "        tiff.imwrite(binary_path, binary_mask[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dir_location = 'refine'\n",
    "gt_path, binary_path, _, _ = setup_paths(dir_location, False)\n",
    "# img_names = ['2_Tablet_Aug1', '2_Tablet_Aug2', '2_Tablet_Aug3', '2_Tablet_Aug4', '2_Tablet_Aug5',\n",
    "#                '4_GenericD12_Aug1', '4_GenericD12_Aug2', '4_GenericD12_Aug3', '4_GenericD12_Aug4', '4_GenericD12_Aug5',\n",
    "#                '5_ClaritinD12_Aug1', '5_ClaritinD12_Aug2', '5_ClaritinD12_Aug3', '5_ClaritinD12_Aug4', '5_ClaritinD12_Aug5']\n",
    "# target_values = [255, 255, 255, 255, 255,\n",
    "#                  182, 182, 182, 182, 182,\n",
    "#                  159, 159, 159, 159, 159]\n",
    "img_names = ['2_Tablet', '4_GenericD12', '5_ClaritinD12']\n",
    "target_values = [255, 182, 159]\n",
    "for img_name, target_value in zip(img_names, target_values):\n",
    "    input_path = os.path.join(gt_path, img_name)\n",
    "    output_path = os.path.join(binary_path, img_name)\n",
    "    if not os.path.isdir(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    semantic_to_binary(input_path, output_path, target_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary to Border-Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tifffile as tiff\n",
    "from skimage.morphology import binary_erosion, dilation, ball, footprint_rectangle\n",
    "\n",
    "import numpy as np\n",
    "from skimage.morphology import ball, binary_erosion, dilation, footprint_rectangle\n",
    "\n",
    "def generate_bordercore(image, border_thickness=1): # Uses erosion and dilation to generate border-core.\n",
    "    \"\"\"\n",
    "    Generate border pixels from 3D binary masks.\n",
    "    \n",
    "    Parameters:\n",
    "        image (np.ndarray): 3D binary image (0s and 255s, or really 0 and any other positive value).\n",
    "        border_thickness (int): Thickness of the border region.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Image with cores labeled as 255 and borders labeled as 127.\n",
    "    \"\"\"\n",
    "    n_erosions = border_thickness\n",
    "\n",
    "    # Ensure binary input (convert 255 to 1 for processing)\n",
    "    binary_image = image > 0\n",
    "\n",
    "    # Define 3D structuring elements\n",
    "    erosion_kernel = ball(n_erosions)  # Spherical structuring element for erosion\n",
    "    dilation_kernel = footprint_rectangle([2 * border_thickness + 1, 2 * border_thickness + 1, 2 * border_thickness + 1])  # Cubic structuring element for dilation\n",
    "    # dilation_kernel = ball(border_thickness)\n",
    "\n",
    "    # Apply 3D erosion\n",
    "    eroded_image = binary_erosion(binary_image, erosion_kernel)\n",
    "\n",
    "    # Apply 3D dilation\n",
    "    dilated = dilation(eroded_image, dilation_kernel)\n",
    "\n",
    "    # Assign labels: cores as 255, borders as 127, background as 0\n",
    "    bordercore = np.zeros_like(image, dtype=np.uint8)\n",
    "    bordercore[eroded_image] = 255  # Core pixels\n",
    "    bordercore[dilated & ~eroded_image] = 127  # Border pixels\n",
    "\n",
    "    return bordercore\n",
    "\n",
    "\n",
    "# def generate_bordercore(image, border_thickness=1): # Uses for erosion only to generate border-core.\n",
    "#     \"\"\"\n",
    "#     Generate border pixels from 3D binary masks.\n",
    "    \n",
    "#     Parameters:\n",
    "#         image (np.ndarray): 3D binary image (0s and 255s, or really 0 and any other positive value).\n",
    "#         border_thickness (int): Thickness of the border region.\n",
    "        \n",
    "#     Returns:\n",
    "#         np.ndarray: Image with cores labeled as 255 and borders labeled as 127.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Ensure binary input (convert 255 to 1 for processing)\n",
    "#     binary_image = image > 0\n",
    "\n",
    "#     # Define 3D structuring elements\n",
    "#     erosion_kernel = ball(border_thickness)  # Spherical structuring element for erosion\n",
    "\n",
    "#     # Apply 3D erosion\n",
    "#     eroded_image = binary_erosion(binary_image, erosion_kernel)\n",
    "\n",
    "\n",
    "#     # Assign labels: cores as 255, borders as 127, background as 0\n",
    "#     bordercore = np.zeros_like(image, dtype=np.uint8)\n",
    "#     bordercore[eroded_image] = 255  # Core pixels\n",
    "#     bordercore[binary_image & ~eroded_image] = 127  # Border pixels\n",
    "\n",
    "#     return bordercore\n",
    "\n",
    "\n",
    "def process_tiff_stack_dir(input_dir: str, border_thickness=1, n_erosions=1):\n",
    "    \"\"\"\n",
    "    Process all TIFF images in a directory as a single 3D volume.\n",
    "    \n",
    "    Parameters:\n",
    "        input_dir (str): Directory containing TIFF images.\n",
    "        border_thickness (int): Border Thickness for dilation.\n",
    "        n_erosions (int): Number of erosion iterations.\n",
    "    \"\"\"\n",
    "    input_path = Path(input_dir)\n",
    "    output_path = Path(str(input_dir).replace('binary', 'bordercore_v2'))\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Get all TIFF files and sort them to maintain order\n",
    "    tiff_files = sorted(input_path.glob(\"*.tiff\"))\n",
    "    if not tiff_files:\n",
    "        raise ValueError(\"No TIFF files found in the directory.\")\n",
    "\n",
    "    # Read the entire directory as a 3D stack\n",
    "    stack = np.array([tiff.imread(str(file)) for file in tiff_files], dtype=np.uint8)\n",
    "\n",
    "    # Process the 3D volume\n",
    "    processed_stack = generate_bordercore(stack, border_thickness)\n",
    "\n",
    "    # Save each slice as an individual TIFF file\n",
    "    for i, slice_ in enumerate(processed_stack):\n",
    "        slice_path = os.path.join(output_path, f\"slice_{i:04d}.tiff\")\n",
    "        tiff.imwrite(slice_path, slice_.astype(np.uint8))\n",
    "\n",
    "    print(f\"Processed 3D stack saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths set\n",
      "Processed 3D stack saved to: D:\\Darren\\Files\\database\\tablet_dataset\\bordercore_v2\\tiff\\2_Tablet\n",
      "Processed 3D stack saved to: D:\\Darren\\Files\\database\\tablet_dataset\\bordercore_v2\\tiff\\4_GenericD12\n",
      "Processed 3D stack saved to: D:\\Darren\\Files\\database\\tablet_dataset\\bordercore_v2\\tiff\\5_ClaritinD12\n"
     ]
    }
   ],
   "source": [
    "dir_location = 'refine'\n",
    "_, binary_path, _, _ = setup_paths(dir_location, False)\n",
    "# img_names = ['2_Tablet_Aug1', '2_Tablet_Aug2', '2_Tablet_Aug3', '2_Tablet_Aug4', '2_Tablet_Aug5',\n",
    "#             '4_GenericD12_Aug1', '4_GenericD12_Aug2', '4_GenericD12_Aug3', '4_GenericD12_Aug4', '4_GenericD12_Aug5',\n",
    "#             '5_ClaritinD12_Aug1', '5_ClaritinD12_Aug2', '5_ClaritinD12_Aug3', '5_ClaritinD12_Aug4', '5_ClaritinD12_Aug5']\n",
    "img_names = ['2_Tablet', '4_GenericD12', '5_ClaritinD12']\n",
    "\n",
    "for img_name in img_names:\n",
    "    input_path = os.path.join(binary_path, img_name)\n",
    "    process_tiff_stack_dir(input_path, border_thickness=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Border-Core to Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import cc3d\n",
    "import copy\n",
    "from scipy.ndimage import label as nd_label\n",
    "from skimage.morphology import footprint_rectangle, dilation, ball\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from tqdm import tqdm\n",
    "import numpy_indexed as npi\n",
    "from typing import Tuple, Type\n",
    "\n",
    "def process_tiff_dir(input_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    border_core = load_tiff_stack_from_dir(input_dir)\n",
    "    instances, _ = border_core2instance(border_core)\n",
    "    for i in tqdm(range(instances.shape[0]), desc=f\"Processing {os.path.basename(input_dir)}\", unit=\"slice\"):\n",
    "        output_path = os.path.join(output_dir, f\"slice_{i:04d}.tiff\")\n",
    "        tiff.imwrite(output_path, instances[i])\n",
    "    print(f\"Processing complete. Output saved to {output_dir}\")\n",
    "\n",
    "def border_core2instance(border_core: np.ndarray, dtype: Type = np.uint16) -> Tuple[np.ndarray, int]:\n",
    "    border_core_array = np.array(border_core)\n",
    "    component_seg = cc3d.connected_components(border_core_array > 0).astype(dtype)\n",
    "    instances = np.zeros_like(border_core, dtype=dtype)\n",
    "    num_instances = 0\n",
    "    props = {i: bbox for i, bbox in enumerate(cc3d.statistics(component_seg)[\"bounding_boxes\"]) if i != 0}\n",
    "    \n",
    "    for label, bbox in tqdm(props.items(), desc=\"Border-Core2Instance\"):\n",
    "        filter_mask = component_seg[bbox] == label\n",
    "        border_core_patch = copy.deepcopy(border_core[bbox])\n",
    "        border_core_patch[filter_mask != 1] = 0\n",
    "        instances_patch = border_core_component2instance_dilation(border_core_patch).astype(dtype)\n",
    "        instances_patch[instances_patch > 0] += num_instances\n",
    "        num_instances = max(num_instances, np.max(instances_patch))\n",
    "        patch_labels = np.unique(instances_patch)\n",
    "        patch_labels = patch_labels[patch_labels > 0]\n",
    "        for patch_label in patch_labels:\n",
    "            instances[bbox][instances_patch == patch_label] = patch_label\n",
    "    return instances, num_instances\n",
    "\n",
    "def border_core_component2instance_dilation(patch: np.ndarray, core_label: int = 255, border_label: int = 127) -> np.ndarray:\n",
    "    '''The values used for core and border don't actually matter: \n",
    "       'num_instances = nd_label(patch == core_label, output=core_instances)' assigns unique instance labels where patch == core_label, regardless of whether core_label is 1, 255, or any other value.\n",
    "       'border = patch == border_label' creates a binary mask (True for border, False elsewhere). Whether border_label is 2, 127, or any other value does not affect behavior.\n",
    "       'dilated = dilation(core_instances, footprint_rectangle([3,3,3]))' expands the core_instances which are the instance labels (1-# of instances) and the background (0). Thus, all instances are \"brighter\" than the surrounding background (no border that is brighter/darker than core).\n",
    "    '''\n",
    "    core_instances = np.zeros_like(patch, dtype=np.uint16)\n",
    "    num_instances = nd_label(patch == core_label, output=core_instances)\n",
    "    if num_instances == 0:\n",
    "        return patch\n",
    "    # patch, core_instances, num_instances = remove_small_cores(patch, core_instances, core_label, border_label) # Weird effect on segmentation...\n",
    "    # core_instances = np.zeros_like(patch, dtype=np.uint16)\n",
    "    # num_instances = nd_label(patch == core_label, output=core_instances)\n",
    "    # if num_instances == 0:\n",
    "    #     return patch\n",
    "    instances = copy.deepcopy(core_instances)\n",
    "    border = patch == border_label\n",
    "    while np.sum(border) > 0:\n",
    "        # dilated = dilation(core_instances, footprint_rectangle([3,3,3])) # Bottleneck when many instances\n",
    "        dilated = dilation(core_instances, ball(1)) # Bottleneck when many instances\n",
    "        dilated[patch == 0] = 0\n",
    "        diff = (core_instances == 0) & (dilated != core_instances)\n",
    "        instances[diff & border] = dilated[diff & border]\n",
    "        border[diff] = 0\n",
    "        core_instances = dilated\n",
    "    return instances\n",
    "\n",
    "def remove_small_cores(\n",
    "    patch: np.ndarray, \n",
    "    core_instances: np.ndarray, \n",
    "    core_label: int, \n",
    "    border_label: int, \n",
    "    min_distance: float = 1, \n",
    "    min_ratio_threshold: float = 0.95, \n",
    "    max_distance: float = 3, \n",
    "    max_ratio_threshold: float = 0.0) -> Tuple[np.ndarray, np.ndarray, int]:\n",
    "\n",
    "    distances = distance_transform_edt(patch == core_label)\n",
    "    core_ids = np.unique(core_instances)\n",
    "    core_ids_to_remove = []\n",
    "    for core_id in core_ids:\n",
    "        core_distances = distances[core_instances == core_id]\n",
    "        num_min_distances = np.count_nonzero(core_distances <= min_distance)\n",
    "        num_max_distances = np.count_nonzero(core_distances >= max_distance)\n",
    "        num_core_voxels = np.count_nonzero(core_instances == core_id)\n",
    "        min_ratio = num_min_distances / num_core_voxels\n",
    "        max_ratio = num_max_distances / num_core_voxels\n",
    "        if (min_ratio_threshold is None or min_ratio >= min_ratio_threshold) and (max_ratio_threshold is None or max_ratio <= max_ratio_threshold):\n",
    "            core_ids_to_remove.append(core_id)\n",
    "    num_cores = len(core_ids) - len(core_ids_to_remove)\n",
    "    if len(core_ids_to_remove) > 0:\n",
    "        target_values = np.zeros_like(core_ids_to_remove, dtype=int)\n",
    "        shape = patch.shape\n",
    "        core_instances = npi.remap(core_instances.flatten(), core_ids_to_remove, target_values).reshape(shape)\n",
    "        patch[(patch == core_label) & (core_instances == 0)] = border_label\n",
    "\n",
    "    return patch, core_instances, num_cores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Border-Core2Instance: 100%|██████████| 25530/25530 [02:12<00:00, 192.54it/s]\n",
      "Processing 2_Tablet: 100%|██████████| 950/950 [00:10<00:00, 86.94slice/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Output saved to D:\\Darren\\Files\\database\\tablet_dataset\\instance_v2\\tiff\\2_Tablet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Border-Core2Instance: 100%|██████████| 11657/11657 [1:44:54<00:00,  1.85it/s]    \n",
      "Processing 4_GenericD12: 100%|██████████| 956/956 [00:17<00:00, 53.45slice/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Output saved to D:\\Darren\\Files\\database\\tablet_dataset\\instance_v2\\tiff\\4_GenericD12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Border-Core2Instance:   0%|          | 0/15394 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "dir_location = 'refine'\n",
    "_, _, bordercore_path, instance_path = setup_paths(dir_location, False)\n",
    "# img_names = ['2_Tablet_Aug1', '2_Tablet_Aug2', '2_Tablet_Aug3', '2_Tablet_Aug4', '2_Tablet_Aug5',\n",
    "#             '4_GenericD12_Aug1', '4_GenericD12_Aug2', '4_GenericD12_Aug3', '4_GenericD12_Aug4', '4_GenericD12_Aug5',\n",
    "#             '5_ClaritinD12_Aug1', '5_ClaritinD12_Aug2', '5_ClaritinD12_Aug3', '5_ClaritinD12_Aug4', '5_ClaritinD12_Aug5']\n",
    "img_names = ['2_Tablet', '4_GenericD12', '5_ClaritinD12']\n",
    "\n",
    "for img_name in img_names:\n",
    "    input_path = os.path.join(bordercore_path, img_name)\n",
    "    output_path = os.path.join(instance_path, img_name)\n",
    "    process_tiff_dir(input_path, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Senior_Design_py310_source",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def setup_paths(dir_location, is_original_data):\n",
    "    if dir_location.lower() == 'internal':\n",
    "        base_path = r'C:\\Senior_Design'\n",
    "    elif dir_location.lower() == 'external':\n",
    "        base_path = r'D:\\Senior_Design'\n",
    "    elif dir_location.lower() == 'cloud':\n",
    "        base_path = r'C:\\Users\\dchen\\OneDrive - University of Connecticut\\Courses\\Year 4\\Fall 2024\\BME 4900 and 4910W (Kumavor)\\Python\\Files'\n",
    "    elif dir_location.lower() == 'refine':\n",
    "        base_path = r'D:\\Darren\\Files'\n",
    "    else:\n",
    "        raise ValueError('Invalid directory location type')\n",
    "    \n",
    "    base_gt_path = os.path.join(base_path, 'database')\n",
    "    if is_original_data:\n",
    "        gt_path = os.path.join(base_gt_path, 'orignal_dataset', 'segmented', 'tiff')\n",
    "    else:\n",
    "        gt_path = os.path.join(base_gt_path, 'tablet_dataset', 'segmented', 'tiff')\n",
    "    \n",
    "    binary_path = gt_path.replace('segmented', 'binary')  \n",
    "    if not os.path.isdir(binary_path):\n",
    "        os.makedirs(binary_path)\n",
    "    bordercore_path = gt_path.replace('segmented', 'bordercore')  \n",
    "    if not os.path.isdir(bordercore_path):\n",
    "        os.makedirs(bordercore_path)  \n",
    "    instance_path = gt_path.replace('segmented', 'instance_temp')\n",
    "    if not os.path.isdir(instance_path):\n",
    "        os.makedirs(instance_path)\n",
    "\n",
    "    print('Paths set')\n",
    "    return gt_path, binary_path, bordercore_path, instance_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Pixel Values from Ground Truth TIFF Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_unique_pixel_values(folder_path):\n",
    "    \"\"\"Extract unique pixel values and their counts from a TIFF stack in a folder.\"\"\"\n",
    "    pixel_values = []\n",
    "    \n",
    "    for filename in sorted(os.listdir(folder_path)):\n",
    "        if filename.endswith('.tif') or filename.endswith('.tiff'):\n",
    "            img = tiff.imread(os.path.join(folder_path, filename))\n",
    "            pixel_values.append(img.flatten())  # Flatten to a 1D array\n",
    "    \n",
    "    # Concatenate all pixel values and get unique values with counts\n",
    "    all_pixels = np.concatenate(pixel_values)\n",
    "    unique_values, counts = np.unique(all_pixels, return_counts=True)\n",
    "    \n",
    "    return unique_values, counts  # Return both unique values and their frequencies\n",
    "\n",
    "def highlight_pixel_value_one_image(folder_path, target_value):\n",
    "    \"\"\"Display an image where only a specific pixel value is shown, using the middle file in the folder.\"\"\"\n",
    "    tiff_files = sorted([f for f in os.listdir(folder_path) if f.endswith('.tif') or f.endswith('.tiff')])\n",
    "    \n",
    "    if not tiff_files:\n",
    "        raise FileNotFoundError(\"No TIFF files found in the folder.\")\n",
    "    \n",
    "    # Select the middle file\n",
    "    middle_file = tiff_files[len(tiff_files) // 2]\n",
    "    img = tiff.imread(os.path.join(folder_path, middle_file))  # Load the middle file\n",
    "    \n",
    "    # Create a mask where only the target pixel value is highlighted\n",
    "    highlighted_img = np.where(img == target_value, target_value, 0).astype(np.uint8)\n",
    "    \n",
    "    plt.imshow(highlighted_img, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()  # Display without saving\n",
    "\n",
    "def load_tiff_stack_from_dir(directory):\n",
    "    \"\"\"Loads a stack of TIFF images from a directory into a 3D NumPy array.\"\"\"\n",
    "    tiff_files = sorted([f for f in os.listdir(directory) if f.lower().endswith('.tiff') or f.lower().endswith('.tif')])\n",
    "    \n",
    "    if not tiff_files:\n",
    "        raise FileNotFoundError(\"No TIFF files found in the directory.\")\n",
    "\n",
    "    stack = [tiff.imread(os.path.join(directory, f)) for f in tiff_files]\n",
    "    return np.stack(stack, axis=0)  # Stack images along the first dimension (depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_path = r'd:\\Darren\\Files\\database\\tablet_dataset\\segmented\\tiff\\2_Tablet'\n",
    "pixel_values, counts = extract_unique_pixel_values(tiff_path)\n",
    "print(pixel_values)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_path = r'd:\\Darren\\Files\\database\\tablet_dataset\\segmented\\tiff\\2_Tablet'\n",
    "highlight_pixel_value_one_image(tiff_path, target_value=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_path = r'd:\\Darren\\Files\\database\\tablet_dataset\\segmented\\tiff\\4_GenericD12'\n",
    "pixel_values, counts = extract_unique_pixel_values(tiff_path)\n",
    "print(pixel_values)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_path = r'd:\\Darren\\Files\\database\\tablet_dataset\\segmented\\tiff\\4_GenericD12'\n",
    "highlight_pixel_value_one_image(tiff_path, target_value=182)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_path = r'd:\\Darren\\Files\\database\\tablet_dataset\\segmented\\tiff\\5_ClaritinD12'\n",
    "pixel_values, counts = extract_unique_pixel_values(tiff_path)\n",
    "print(pixel_values)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_path = r'd:\\Darren\\Files\\database\\tablet_dataset\\segmented\\tiff\\5_ClaritinD12'\n",
    "highlight_pixel_value_one_image(tiff_path, target_value=159)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic to Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_to_binary(input_path, output_path, target_value):\n",
    "    tiff_stack = load_tiff_stack_from_dir(input_path)\n",
    "    \n",
    "    # Create a mask where only the target pixel value is highlighted\n",
    "    binary_mask = np.where(tiff_stack == target_value, 255, 0).astype(np.uint8)\n",
    "    \n",
    "    for i in tqdm(range(binary_mask.shape[0]), desc=f\"Processing {os.path.basename(input_path)}\", unit=\"slice\"):\n",
    "        binary_path = os.path.join(output_path, f\"slice_{i:04d}.tiff\")\n",
    "        tiff.imwrite(binary_path, binary_mask[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dir_location = 'refine'\n",
    "gt_path, binary_path, _, _ = setup_paths(dir_location, False)\n",
    "# img_names = ['2_Tablet_Aug1', '2_Tablet_Aug2', '2_Tablet_Aug3', '2_Tablet_Aug4', '2_Tablet_Aug5',\n",
    "#                '4_GenericD12_Aug1', '4_GenericD12_Aug2', '4_GenericD12_Aug3', '4_GenericD12_Aug4', '4_GenericD12_Aug5',\n",
    "#                '5_ClaritinD12_Aug1', '5_ClaritinD12_Aug2', '5_ClaritinD12_Aug3', '5_ClaritinD12_Aug4', '5_ClaritinD12_Aug5']\n",
    "# target_values = [255, 255, 255, 255, 255,\n",
    "#                  182, 182, 182, 182, 182,\n",
    "#                  159, 159, 159, 159, 159]\n",
    "img_names = ['2_Tablet', '4_GenericD12', '5_ClaritinD12']\n",
    "target_values = [255, 182, 159]\n",
    "for img_name, target_value in zip(img_names, target_values):\n",
    "    input_path = os.path.join(gt_path, img_name)\n",
    "    output_path = os.path.join(binary_path, img_name)\n",
    "    if not os.path.isdir(output_path):\n",
    "        os.makedirs(output_path)\n",
    "    semantic_to_binary(input_path, output_path, target_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary to Border-Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tifffile as tiff\n",
    "from skimage.morphology import binary_erosion, dilation, ball, footprint_rectangle\n",
    "\n",
    "\n",
    "def generate_bordercore(image, border_thickness=1): # Uses erosion and dilation to generate border-core.\n",
    "    \"\"\"\n",
    "    Generate border pixels from 3D binary masks.\n",
    "    \n",
    "    Parameters:\n",
    "        image (np.ndarray): 3D binary image (0s and 255s, or really 0 and any other positive value).\n",
    "        border_thickness (int): Thickness of the border region.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: Image with cores labeled as 255 and borders labeled as 127.\n",
    "    \"\"\"\n",
    "    n_erosions = border_thickness\n",
    "\n",
    "    # Ensure binary input (convert 255 to 1 for processing)\n",
    "    binary_image = image > 0\n",
    "\n",
    "    # Define 3D structuring elements\n",
    "    erosion_kernel = ball(n_erosions)  # Spherical structuring element for erosion\n",
    "    dilation_kernel = footprint_rectangle([2 * border_thickness + 1, 2 * border_thickness + 1, 2 * border_thickness + 1])  # Cubic structuring element for dilation\n",
    "    # dilation_kernel = ball(border_thickness)\n",
    "\n",
    "    # Apply 3D erosion\n",
    "    eroded_image = binary_erosion(binary_image, erosion_kernel)\n",
    "\n",
    "    # Apply 3D dilation\n",
    "    dilated = dilation(eroded_image, dilation_kernel)\n",
    "\n",
    "    # Assign labels: cores as 255, borders as 127, background as 0\n",
    "    bordercore = np.zeros_like(image, dtype=np.uint8)\n",
    "    bordercore[eroded_image] = 255  # Core pixels\n",
    "    bordercore[dilated & ~eroded_image] = 127  # Border pixels\n",
    "\n",
    "    return bordercore\n",
    "\n",
    "\n",
    "# def generate_bordercore(image, border_thickness=1): # Uses for erosion only to generate border-core.\n",
    "#     \"\"\"\n",
    "#     Generate border pixels from 3D binary masks.\n",
    "    \n",
    "#     Parameters:\n",
    "#         image (np.ndarray): 3D binary image (0s and 255s, or really 0 and any other positive value).\n",
    "#         border_thickness (int): Thickness of the border region.\n",
    "        \n",
    "#     Returns:\n",
    "#         np.ndarray: Image with cores labeled as 255 and borders labeled as 127.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # Ensure binary input (convert 255 to 1 for processing)\n",
    "#     binary_image = image > 0\n",
    "\n",
    "#     # Define 3D structuring elements\n",
    "#     erosion_kernel = ball(border_thickness)  # Spherical structuring element for erosion\n",
    "\n",
    "#     # Apply 3D erosion\n",
    "#     eroded_image = binary_erosion(binary_image, erosion_kernel)\n",
    "\n",
    "\n",
    "#     # Assign labels: cores as 255, borders as 127, background as 0\n",
    "#     bordercore = np.zeros_like(image, dtype=np.uint8)\n",
    "#     bordercore[eroded_image] = 255  # Core pixels\n",
    "#     bordercore[binary_image & ~eroded_image] = 127  # Border pixels\n",
    "\n",
    "#     return bordercore\n",
    "\n",
    "\n",
    "def process_tiff_stack_dir(input_dir: str, border_thickness=1):\n",
    "    \"\"\"\n",
    "    Process all TIFF images in a directory as a single 3D volume.\n",
    "    \n",
    "    Parameters:\n",
    "        input_dir (str): Directory containing TIFF images.\n",
    "        border_thickness (int): Border Thickness for dilation.\n",
    "        n_erosions (int): Number of erosion iterations.\n",
    "    \"\"\"\n",
    "    input_path = Path(input_dir)\n",
    "    output_path = Path(str(input_dir).replace('binary', 'bordercore'))\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Get all TIFF files and sort them to maintain order\n",
    "    tiff_files = sorted(input_path.glob(\"*.tiff\"))\n",
    "    if not tiff_files:\n",
    "        raise ValueError(\"No TIFF files found in the directory.\")\n",
    "\n",
    "    # Read the entire directory as a 3D stack\n",
    "    stack = np.array([tiff.imread(str(file)) for file in tiff_files], dtype=np.uint8)\n",
    "\n",
    "    # Process the 3D volume\n",
    "    processed_stack = generate_bordercore(stack, border_thickness)\n",
    "\n",
    "    # Save each slice as an individual TIFF file\n",
    "    for i, slice_ in enumerate(processed_stack):\n",
    "        slice_path = os.path.join(output_path, f\"slice_{i:04d}.tiff\")\n",
    "        tiff.imwrite(slice_path, slice_.astype(np.uint8))\n",
    "\n",
    "    print(f\"Processed 3D stack saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_location = 'refine'\n",
    "_, binary_path, _, _ = setup_paths(dir_location, False)\n",
    "# img_names = ['2_Tablet_Aug1', '2_Tablet_Aug2', '2_Tablet_Aug3', '2_Tablet_Aug4', '2_Tablet_Aug5',\n",
    "#             '4_GenericD12_Aug1', '4_GenericD12_Aug2', '4_GenericD12_Aug3', '4_GenericD12_Aug4', '4_GenericD12_Aug5',\n",
    "#             '5_ClaritinD12_Aug1', '5_ClaritinD12_Aug2', '5_ClaritinD12_Aug3', '5_ClaritinD12_Aug4', '5_ClaritinD12_Aug5']\n",
    "img_names = ['2_Tablet', '4_GenericD12', '5_ClaritinD12']\n",
    "\n",
    "for img_name in img_names:\n",
    "    input_path = os.path.join(binary_path, img_name)\n",
    "    process_tiff_stack_dir(input_path, border_thickness=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Border-Core to Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import cc3d\n",
    "import copy\n",
    "from scipy.ndimage import label as nd_label\n",
    "from skimage.morphology import footprint_rectangle, dilation, ball\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from tqdm import tqdm\n",
    "import numpy_indexed as npi\n",
    "from typing import Tuple, Type\n",
    "from acvl_utils.miscellaneous.ptqdm import ptqdm\n",
    "\n",
    "\n",
    "def process_tiff_dir(input_dir, output_dir, processes=None):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    border_core = load_tiff_stack_from_dir(input_dir)\n",
    "    instances, _ = border_core2instance(border_core, processes=processes)\n",
    "    for i in tqdm(range(instances.shape[0]), desc=f\"Processing {os.path.basename(input_dir)}\", unit=\"slice\"):\n",
    "        output_path = os.path.join(output_dir, f\"slice_{i:04d}.tiff\")\n",
    "        tiff.imwrite(output_path, instances[i])\n",
    "    print(f\"Processing complete. Output saved to {output_dir}\")\n",
    "\n",
    "def border_core2instance(border_core: np.ndarray, dtype: Type = np.uint16, processes: int = None) -> Tuple[np.ndarray, int]:\n",
    "    border_core_array = np.array(border_core)\n",
    "    component_seg = cc3d.connected_components(border_core_array > 0).astype(dtype) # Original method\n",
    "    instances = np.zeros_like(border_core, dtype=dtype)\n",
    "    num_instances = 0\n",
    "    props = {i: bbox for i, bbox in enumerate(cc3d.statistics(component_seg)[\"bounding_boxes\"]) if i != 0}\n",
    "\n",
    "    if processes is None or processes == 0:\n",
    "        for label, bbox in tqdm(props.items(), desc=\"Border-Core2Instance\"):\n",
    "            filter_mask = component_seg[bbox] == label\n",
    "            border_core_patch = copy.deepcopy(border_core[bbox])\n",
    "            border_core_patch[filter_mask != 1] = 0\n",
    "            instances_patch = border_core_component2instance_dilation(border_core_patch).astype(dtype)\n",
    "            instances_patch[instances_patch > 0] += num_instances\n",
    "            num_instances = max(num_instances, np.max(instances_patch))\n",
    "            # patch_labels = np.unique(instances_patch)\n",
    "            # patch_labels = patch_labels[patch_labels > 0]\n",
    "            # for patch_label in patch_labels:\n",
    "            #     instances[bbox][instances_patch == patch_label] = patch_label\n",
    "            instances[bbox][instances_patch > 0] = instances_patch[instances_patch > 0] # SOOOOOOO MUCH FASTER THAN THE 4 LINES ABOVE!!!!!!!! Confirmed no impact on segmentation!\n",
    "\n",
    "    else:\n",
    "        border_core_patches = []\n",
    "        for label, bbox in props.items():\n",
    "            filter_mask = component_seg[bbox] == label\n",
    "            border_core_patch = copy.deepcopy(border_core[bbox])\n",
    "            border_core_patch[filter_mask != 1] = 0\n",
    "            border_core_patches.append(border_core_patch)\n",
    "\n",
    "        instances_patches = ptqdm(border_core_component2instance_dilation, border_core_patches, processes, desc=\"Border-Core2Instance\")\n",
    "\n",
    "        for index, (label, bbox) in enumerate(tqdm(props.items())):\n",
    "            instances_patch = instances_patches[index].astype(dtype)\n",
    "            instances_patch[instances_patch > 0] += num_instances\n",
    "            num_instances = max(num_instances, int(np.max(instances_patch)))\n",
    "            # patch_labels = np.unique(instances_patch)\n",
    "            # patch_labels = patch_labels[patch_labels > 0]\n",
    "            # for patch_label in patch_labels:\n",
    "            #     instances[bbox][instances_patch == patch_label] = patch_label\n",
    "            instances[bbox][instances_patch > 0] = instances_patch[instances_patch > 0] # SOOOOOOO MUCH FASTER THAN THE 4 LINES ABOVE!!!!!!!! Confirmed no impact on segmentation!\n",
    "\n",
    "    return instances, num_instances\n",
    "\n",
    "def border_core_component2instance_dilation(patch: np.ndarray, core_label: int = 255, border_label: int = 127) -> np.ndarray:\n",
    "    '''The values used for core and border don't actually matter: \n",
    "       'num_instances = nd_label(patch == core_label, output=core_instances)' assigns unique instance labels where patch == core_label, regardless of whether core_label is 1, 255, or any other value.\n",
    "       'border = patch == border_label' creates a binary mask (True for border, False elsewhere). Whether border_label is 2, 127, or any other value does not affect behavior.\n",
    "       'dilated = dilation(core_instances, footprint_rectangle([3,3,3]))' expands the core_instances which are the instance labels (1-# of instances) and the background (0). Thus, all instances are \"brighter\" than the surrounding background (no border that is brighter/darker than core).\n",
    "    '''\n",
    "    # core_instances = np.zeros_like(patch, dtype=np.uint16)\n",
    "    # num_instances = nd_label(patch == core_label, output=core_instances)\n",
    "    core_instances = cc3d.connected_components(patch == core_label, connectivity=6) # cc3d.connected_components is better optimized than scipy.ndimage.label | Confirmed no impact on segmentation!\n",
    "    num_instances = core_instances.max()\n",
    "    \n",
    "    if num_instances == 0:\n",
    "        return patch\n",
    "    \n",
    "    # # Significiant bottleneck when patch size is big and has many particles in it (same reason as for the for loop that iterates through the patch labels)\n",
    "    # patch, core_instances, num_instances = remove_small_cores(patch, core_instances, core_label, border_label) # Weird effect on segmentation...\n",
    "    # # core_instances = np.zeros_like(patch, dtype=np.uint16)\n",
    "    # # num_instances = nd_label(patch == core_label, output=core_instances)\n",
    "    # core_instances = cc3d.connected_components(patch == core_label, connectivity=6) # cc3d.connected_components is better optimized than scipy.ndimage.label\n",
    "    # num_instances = core_instances.max()\n",
    "    # if num_instances == 0:\n",
    "    #     return patch\n",
    "    \n",
    "    instances = copy.deepcopy(core_instances)\n",
    "    border = patch == border_label\n",
    "    while np.sum(border) > 0:\n",
    "        dilated = dilation(core_instances, footprint_rectangle([3,3,3])) # Bottleneck when many instances\n",
    "        # dilated = dilation(core_instances, ball(1)) # Bottleneck when many instances\n",
    "        dilated[patch == 0] = 0\n",
    "        diff = (core_instances == 0) & (dilated != core_instances)\n",
    "        instances[diff & border] = dilated[diff & border]\n",
    "        border[diff] = 0\n",
    "        core_instances = dilated\n",
    "    return instances\n",
    "\n",
    "\n",
    "def remove_small_cores(\n",
    "    patch: np.ndarray, \n",
    "    core_instances: np.ndarray, \n",
    "    core_label: int, \n",
    "    border_label: int, \n",
    "    min_distance: float = 1, \n",
    "    min_ratio_threshold: float = 0.95, \n",
    "    max_distance: float = 3, \n",
    "    max_ratio_threshold: float = 0.0) -> Tuple[np.ndarray, np.ndarray, int]:\n",
    "\n",
    "    distances = distance_transform_edt(patch == core_label)\n",
    "    core_ids = np.unique(core_instances)\n",
    "    core_ids_to_remove = []\n",
    "    for core_id in core_ids:\n",
    "        core_distances = distances[core_instances == core_id]\n",
    "        num_min_distances = np.count_nonzero(core_distances <= min_distance)\n",
    "        num_max_distances = np.count_nonzero(core_distances >= max_distance)\n",
    "        num_core_voxels = np.count_nonzero(core_instances == core_id)\n",
    "        min_ratio = num_min_distances / num_core_voxels\n",
    "        max_ratio = num_max_distances / num_core_voxels\n",
    "        if (min_ratio_threshold is None or min_ratio >= min_ratio_threshold) and (max_ratio_threshold is None or max_ratio <= max_ratio_threshold):\n",
    "            core_ids_to_remove.append(core_id)\n",
    "    num_cores = len(core_ids) - len(core_ids_to_remove)\n",
    "    if len(core_ids_to_remove) > 0:\n",
    "        target_values = np.zeros_like(core_ids_to_remove, dtype=int)\n",
    "        shape = patch.shape\n",
    "        core_instances = npi.remap(core_instances.flatten(), core_ids_to_remove, target_values).reshape(shape)\n",
    "        patch[(patch == core_label) & (core_instances == 0)] = border_label\n",
    "\n",
    "    return patch, core_instances, num_cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Border-Core2Instance: 100%|██████████| 11657/11657 [00:33<00:00, 348.71it/s] \n",
      "Processing 4_GenericD12: 100%|██████████| 956/956 [00:02<00:00, 464.49slice/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. Output saved to D:\\Darren\\Files\\database\\tablet_dataset\\instance_temp\\tiff\\4_GenericD12\n"
     ]
    }
   ],
   "source": [
    "dir_location = 'refine'\n",
    "_, _, bordercore_path, instance_path = setup_paths(dir_location, False)\n",
    "# img_names = ['2_Tablet_Aug1', '2_Tablet_Aug2', '2_Tablet_Aug3', '2_Tablet_Aug4', '2_Tablet_Aug5',\n",
    "#             '4_GenericD12_Aug1', '4_GenericD12_Aug2', '4_GenericD12_Aug3', '4_GenericD12_Aug4', '4_GenericD12_Aug5',\n",
    "#             '5_ClaritinD12_Aug1', '5_ClaritinD12_Aug2', '5_ClaritinD12_Aug3', '5_ClaritinD12_Aug4', '5_ClaritinD12_Aug5']\n",
    "# img_names = ['2_Tablet', '4_GenericD12', '5_ClaritinD12']\n",
    "img_names = ['4_GenericD12']\n",
    "\n",
    "for img_name in img_names:\n",
    "    input_path = os.path.join(bordercore_path, img_name)\n",
    "    output_path = os.path.join(instance_path, img_name)\n",
    "    process_tiff_dir(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Border-Core2Instance:   0%|          | 1/11657 [03:19<645:22:52, 199.33s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m input_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(bordercore_path, img_name)\n\u001b[0;32m     11\u001b[0m output_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(instance_path, img_name)\n\u001b[1;32m---> 12\u001b[0m \u001b[43mprocess_tiff_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 18\u001b[0m, in \u001b[0;36mprocess_tiff_dir\u001b[1;34m(input_dir, output_dir, processes)\u001b[0m\n\u001b[0;32m     16\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(output_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     17\u001b[0m border_core \u001b[38;5;241m=\u001b[39m load_tiff_stack_from_dir(input_dir)\n\u001b[1;32m---> 18\u001b[0m instances, _ \u001b[38;5;241m=\u001b[39m \u001b[43mborder_core2instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mborder_core\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocesses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocesses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(instances\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(input_dir)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslice\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     20\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mslice_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m04d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.tiff\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 36\u001b[0m, in \u001b[0;36mborder_core2instance\u001b[1;34m(border_core, dtype, processes)\u001b[0m\n\u001b[0;32m     34\u001b[0m border_core_patch \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(border_core[bbox])\n\u001b[0;32m     35\u001b[0m border_core_patch[filter_mask \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 36\u001b[0m instances_patch \u001b[38;5;241m=\u001b[39m \u001b[43mborder_core_component2instance_dilation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mborder_core_patch\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(dtype)\n\u001b[0;32m     37\u001b[0m instances_patch[instances_patch \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m num_instances\n\u001b[0;32m     38\u001b[0m num_instances \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(num_instances, np\u001b[38;5;241m.\u001b[39mmax(instances_patch))\n",
      "Cell \u001b[1;32mIn[4], line 81\u001b[0m, in \u001b[0;36mborder_core_component2instance_dilation\u001b[1;34m(patch, core_label, border_label)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_instances \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m patch\n\u001b[1;32m---> 81\u001b[0m patch, core_instances, num_instances \u001b[38;5;241m=\u001b[39m \u001b[43mremove_small_cores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcore_instances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcore_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mborder_label\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Weird effect on segmentation...\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# core_instances = np.zeros_like(patch, dtype=np.uint16)\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# num_instances = nd_label(patch == core_label, output=core_instances)\u001b[39;00m\n\u001b[0;32m     84\u001b[0m core_instances \u001b[38;5;241m=\u001b[39m cc3d\u001b[38;5;241m.\u001b[39mconnected_components(patch \u001b[38;5;241m==\u001b[39m core_label, connectivity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m) \u001b[38;5;66;03m# cc3d.connected_components is better optimized than scipy.ndimage.label\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 113\u001b[0m, in \u001b[0;36mremove_small_cores\u001b[1;34m(patch, core_instances, core_label, border_label, min_distance, min_ratio_threshold, max_distance, max_ratio_threshold)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_small_cores\u001b[39m(\n\u001b[0;32m    103\u001b[0m     patch: np\u001b[38;5;241m.\u001b[39mndarray, \n\u001b[0;32m    104\u001b[0m     core_instances: np\u001b[38;5;241m.\u001b[39mndarray, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    109\u001b[0m     max_distance: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, \n\u001b[0;32m    110\u001b[0m     max_ratio_threshold: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mint\u001b[39m]:\n\u001b[0;32m    112\u001b[0m     distances \u001b[38;5;241m=\u001b[39m distance_transform_edt(patch \u001b[38;5;241m==\u001b[39m core_label)\n\u001b[1;32m--> 113\u001b[0m     core_ids \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore_instances\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m     core_ids_to_remove \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m core_id \u001b[38;5;129;01min\u001b[39;00m core_ids:\n",
      "File \u001b[1;32mc:\\Users\\ZEISS\\anaconda3\\envs\\Senior_Design_py310_source\\lib\\site-packages\\numpy\\lib\\arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[0;32m    272\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mequal_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mequal_nan\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ZEISS\\anaconda3\\envs\\Senior_Design_py310_source\\lib\\site-packages\\numpy\\lib\\arraysetops.py:336\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[0;32m    334\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar[perm]\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 336\u001b[0m     \u001b[43mar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    337\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar\n\u001b[0;32m    338\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(aux\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool_)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dir_location = 'refine'\n",
    "_, _, bordercore_path, instance_path = setup_paths(dir_location, False)\n",
    "# img_names = ['2_Tablet_Aug1', '2_Tablet_Aug2', '2_Tablet_Aug3', '2_Tablet_Aug4', '2_Tablet_Aug5',\n",
    "#             '4_GenericD12_Aug1', '4_GenericD12_Aug2', '4_GenericD12_Aug3', '4_GenericD12_Aug4', '4_GenericD12_Aug5',\n",
    "#             '5_ClaritinD12_Aug1', '5_ClaritinD12_Aug2', '5_ClaritinD12_Aug3', '5_ClaritinD12_Aug4', '5_ClaritinD12_Aug5']\n",
    "# img_names = ['2_Tablet', '4_GenericD12', '5_ClaritinD12']\n",
    "img_names = ['4_GenericD12']\n",
    "\n",
    "for img_name in img_names:\n",
    "    input_path = os.path.join(bordercore_path, img_name)\n",
    "    output_path = os.path.join(instance_path, img_name)\n",
    "    process_tiff_dir(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_location = 'refine'\n",
    "_, _, bordercore_path, instance_path = setup_paths(dir_location, False)\n",
    "img_names = ['2_Tablet_Aug1', '2_Tablet_Aug2', '2_Tablet_Aug3', '2_Tablet_Aug4', '2_Tablet_Aug5',\n",
    "            '4_GenericD12_Aug1', '4_GenericD12_Aug2', '4_GenericD12_Aug3', '4_GenericD12_Aug4', '4_GenericD12_Aug5',\n",
    "            '5_ClaritinD12_Aug1', '5_ClaritinD12_Aug2', '5_ClaritinD12_Aug3', '5_ClaritinD12_Aug4', '5_ClaritinD12_Aug5']\n",
    "# img_names = ['2_Tablet', '4_GenericD12', '5_ClaritinD12']\n",
    "\n",
    "for img_name in img_names:\n",
    "    input_path = os.path.join(bordercore_path, img_name)\n",
    "    output_path = os.path.join(instance_path, img_name)\n",
    "    process_tiff_dir(input_path, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to Compare Two TIFF Stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/950 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 950/950 [00:12<00:00, 78.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average MAE: 0.0000\n",
      "Average MSE: 0.0000\n",
      "Total different pixels: 0 / 420822450 (0.00%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_tiff(filepath):\n",
    "    return np.array(Image.open(filepath))\n",
    "\n",
    "def compare_dirs(dir1, dir2, diff_threshold=0):\n",
    "    files1 = sorted([f for f in os.listdir(dir1) if f.endswith('.tif') or f.endswith('.tiff')])\n",
    "    files2 = sorted([f for f in os.listdir(dir2) if f.endswith('.tif') or f.endswith('.tiff')])\n",
    "\n",
    "    assert len(files1) == len(files2), \"Number of slices do not match\"\n",
    "    \n",
    "    total_mae = 0\n",
    "    total_mse = 0\n",
    "    total_diff_pixels = 0\n",
    "    total_pixels = 0\n",
    "    n = len(files1)\n",
    "\n",
    "    for f1, f2 in tqdm(zip(files1, files2), total=n):\n",
    "        img1 = load_tiff(os.path.join(dir1, f1)).astype(np.float32)\n",
    "        img2 = load_tiff(os.path.join(dir2, f2)).astype(np.float32)\n",
    "\n",
    "        assert img1.shape == img2.shape, f\"Shape mismatch: {f1} vs {f2}\"\n",
    "\n",
    "        diff = np.abs(img1 - img2)\n",
    "        diff_pixels = np.sum(diff > diff_threshold)\n",
    "        num_pixels = diff.size\n",
    "\n",
    "        total_mae += np.mean(diff)\n",
    "        total_mse += np.mean(diff ** 2)\n",
    "        total_diff_pixels += diff_pixels\n",
    "        total_pixels += num_pixels\n",
    "\n",
    "    avg_mae = total_mae / n\n",
    "    avg_mse = total_mse / n\n",
    "    diff_percent = (total_diff_pixels / total_pixels) * 100\n",
    "\n",
    "    print(f\"\\nAverage MAE: {avg_mae:.4f}\")\n",
    "    print(f\"Average MSE: {avg_mse:.4f}\")\n",
    "    print(f\"Total different pixels: {total_diff_pixels} / {total_pixels} ({diff_percent:.2f}%)\")\n",
    "\n",
    "# Example usage\n",
    "dir1 = r'd:\\Darren\\Files\\database\\tablet_dataset\\instance\\tiff\\2_Tablet'\n",
    "dir2 = r'd:\\Darren\\Files\\database\\tablet_dataset\\instance_temp\\tiff\\2_Tablet'\n",
    "compare_dirs(dir1, dir2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Senior_Design_py310_source",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

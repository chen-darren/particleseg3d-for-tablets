{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#    Copyright 2020 Division of Medical Image Computing, German Cancer Research Center (DKFZ), Heidelberg, Germany\n",
    "#\n",
    "#    Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#    you may not use this file except in compliance with the License.\n",
    "#    You may obtain a copy of the License at\n",
    "#\n",
    "#        http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#    Unless required by applicable law or agreed to in writing, software\n",
    "#    distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#    See the License for the specific language governing permissions and\n",
    "#    limitations under the License.\n",
    "\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from batchgenerators.utilities.file_and_folder_operations import *\n",
    "from nnunet.configuration import default_num_threads\n",
    "\n",
    "\n",
    "def verify_all_same_orientation(folder):\n",
    "    \"\"\"\n",
    "    This should run after cropping\n",
    "    :param folder:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    nii_files = subfiles(folder, suffix=\".nii.gz\", join=True)\n",
    "    orientations = []\n",
    "    for n in nii_files:\n",
    "        img = nib.load(n)\n",
    "        affine = img.affine\n",
    "        orientation = nib.aff2axcodes(affine)\n",
    "        orientations.append(orientation)\n",
    "    # now we need to check whether they are all the same\n",
    "    orientations = np.array(orientations)\n",
    "    unique_orientations = np.unique(orientations, axis=0)\n",
    "    all_same = len(unique_orientations) == 1\n",
    "    return all_same, unique_orientations\n",
    "\n",
    "\n",
    "def verify_same_geometry(img_1: sitk.Image, img_2: sitk.Image):\n",
    "    ori1, spacing1, direction1, size1 = img_1.GetOrigin(), img_1.GetSpacing(), img_1.GetDirection(), img_1.GetSize()\n",
    "    ori2, spacing2, direction2, size2 = img_2.GetOrigin(), img_2.GetSpacing(), img_2.GetDirection(), img_2.GetSize()\n",
    "\n",
    "    same_ori = np.all(np.isclose(ori1, ori2))\n",
    "    if not same_ori:\n",
    "        print(\"the origin does not match between the images:\")\n",
    "        print(ori1)\n",
    "        print(ori2)\n",
    "\n",
    "    same_spac = np.all(np.isclose(spacing1, spacing2))\n",
    "    if not same_spac:\n",
    "        print(\"the spacing does not match between the images\")\n",
    "        print(spacing1)\n",
    "        print(spacing2)\n",
    "\n",
    "    same_dir = np.all(np.isclose(direction1, direction2))\n",
    "    if not same_dir:\n",
    "        print(\"the direction does not match between the images\")\n",
    "        print(direction1)\n",
    "        print(direction2)\n",
    "\n",
    "    same_size = np.all(np.isclose(size1, size2))\n",
    "    if not same_size:\n",
    "        print(\"the size does not match between the images\")\n",
    "        print(size1)\n",
    "        print(size2)\n",
    "\n",
    "    if same_ori and same_spac and same_dir and same_size:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def verify_contains_only_expected_labels(itk_img: str, valid_labels: (tuple, list)):\n",
    "    print('verify_contains_only_expected_labels for', itk_img, 'is starting!')\n",
    "    img_npy = sitk.GetArrayFromImage(sitk.ReadImage(itk_img))\n",
    "    uniques = np.unique(img_npy)\n",
    "    invalid_uniques = [i for i in uniques if i not in valid_labels]\n",
    "    if len(invalid_uniques) == 0:\n",
    "        r = True\n",
    "    else:\n",
    "        r = False\n",
    "    print('verify_contains_only_expected_labels for', itk_img, 'is done!')\n",
    "    return r, invalid_uniques\n",
    "\n",
    "\n",
    "def verify_dataset_integrity(folder):\n",
    "    \"\"\"\n",
    "    folder needs the imagesTr, imagesTs and labelsTr subfolders. There also needs to be a dataset.json\n",
    "    checks if all training cases and labels are present\n",
    "    checks if all test cases (if any) are present\n",
    "    for each case, checks whether all modalities apre present\n",
    "    for each case, checks whether the pixel grids are aligned\n",
    "    checks whether the labels really only contain values they should\n",
    "    :param folder:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    assert isfile(join(folder, \"dataset.json\")), \"There needs to be a dataset.json file in folder, folder=%s\" % folder\n",
    "    assert isdir(join(folder, \"imagesTr\")), \"There needs to be a imagesTr subfolder in folder, folder=%s\" % folder\n",
    "    assert isdir(join(folder, \"labelsTr\")), \"There needs to be a labelsTr subfolder in folder, folder=%s\" % folder\n",
    "    dataset = load_json(join(folder, \"dataset.json\"))\n",
    "    training_cases = dataset['training']\n",
    "    num_modalities = len(dataset['modality'].keys())\n",
    "    test_cases = dataset['test']\n",
    "    expected_train_identifiers = [i['image'].split(\"/\")[-1][:-7] for i in training_cases]\n",
    "    expected_test_identifiers = [i.split(\"/\")[-1][:-7] for i in test_cases]\n",
    "    print('Expected train identifiers:', expected_train_identifiers)\n",
    "\n",
    "    ## check training set\n",
    "    nii_files_in_imagesTr = subfiles((join(folder, \"imagesTr\")), suffix=\".nii.gz\", join=False)\n",
    "    nii_files_in_labelsTr = subfiles((join(folder, \"labelsTr\")), suffix=\".nii.gz\", join=False)\n",
    "    print('nii_files_in_imagesTr:', nii_files_in_imagesTr)\n",
    "    print('nii_files_in_labelsTr:', nii_files_in_labelsTr)\n",
    "\n",
    "    label_files = []\n",
    "    geometries_OK = True\n",
    "    has_nan = False\n",
    "\n",
    "    # check all cases\n",
    "    if len(expected_train_identifiers) != len(np.unique(expected_train_identifiers)): raise RuntimeError(\"found duplicate training cases in dataset.json\")\n",
    "\n",
    "    print(\"Verifying training set\")\n",
    "    for c in expected_train_identifiers:\n",
    "        print(\"checking case\", c)\n",
    "        # check if all files are present\n",
    "        expected_label_file = join(folder, \"labelsTr\", c + \".nii.gz\")\n",
    "        label_files.append(expected_label_file)\n",
    "        expected_image_files = [join(folder, \"imagesTr\", c + \"_%04.0d.nii.gz\" % i) for i in range(num_modalities)]\n",
    "        assert isfile(expected_label_file), \"could not find label file for case %s. Expected file: \\n%s\" % (\n",
    "            c, expected_label_file)\n",
    "        assert all([isfile(i) for i in\n",
    "                    expected_image_files]), \"some image files are missing for case %s. Expected files:\\n %s\" % (\n",
    "            c, expected_image_files)\n",
    "\n",
    "        # verify that all modalities and the label have the same shape and geometry.\n",
    "        label_itk = sitk.ReadImage(expected_label_file)\n",
    "\n",
    "        nans_in_seg = np.any(np.isnan(sitk.GetArrayFromImage(label_itk)))\n",
    "        has_nan = has_nan | nans_in_seg\n",
    "        if nans_in_seg:\n",
    "            print(\"There are NAN values in segmentation %s\" % expected_label_file)\n",
    "\n",
    "        images_itk = [sitk.ReadImage(i) for i in expected_image_files]\n",
    "        for i, img in enumerate(images_itk):\n",
    "            nans_in_image = np.any(np.isnan(sitk.GetArrayFromImage(img)))\n",
    "            has_nan = has_nan | nans_in_image\n",
    "            same_geometry = verify_same_geometry(img, label_itk)\n",
    "            if not same_geometry:\n",
    "                geometries_OK = False\n",
    "                print(\"The geometry of the image %s does not match the geometry of the label file. The pixel arrays \"\n",
    "                      \"will not be aligned and nnU-Net cannot use this data. Please make sure your image modalities \"\n",
    "                      \"are coregistered and have the same geometry as the label\" % expected_image_files[0][:-12])\n",
    "            if nans_in_image:\n",
    "                print(\"There are NAN values in image %s\" % expected_image_files[i])\n",
    "\n",
    "        # now remove checked files from the lists nii_files_in_imagesTr and nii_files_in_labelsTr\n",
    "        for i in expected_image_files:\n",
    "            nii_files_in_imagesTr.remove(os.path.basename(i))\n",
    "        nii_files_in_labelsTr.remove(os.path.basename(expected_label_file))\n",
    "\n",
    "    # check for stragglers\n",
    "    print('nii_files_in_imagesTr:', nii_files_in_imagesTr)\n",
    "    print('nii_files_in_labelsTr:', nii_files_in_labelsTr)\n",
    "    assert len(\n",
    "        nii_files_in_imagesTr) == 0, \"there are training cases in imagesTr that are not listed in dataset.json: %s\" % nii_files_in_imagesTr\n",
    "    assert len(\n",
    "        nii_files_in_labelsTr) == 0, \"there are training cases in labelsTr that are not listed in dataset.json: %s\" % nii_files_in_labelsTr\n",
    "\n",
    "    # verify that only properly declared values are present in the labels\n",
    "    print(\"Verifying label values\")\n",
    "    expected_labels = list(int(i) for i in dataset['labels'].keys())\n",
    "    expected_labels.sort()\n",
    "\n",
    "    # check if labels are in consecutive order\n",
    "    assert expected_labels[0] == 0, 'The first label must be 0 and maps to the background'\n",
    "    labels_valid_consecutive = np.ediff1d(expected_labels) == 1\n",
    "    assert all(labels_valid_consecutive), f'Labels must be in consecutive order (0, 1, 2, ...). The labels {np.array(expected_labels)[1:][~labels_valid_consecutive]} do not satisfy this restriction'\n",
    "\n",
    "    print('Beginning verify_contains_only_expected_labels!')\n",
    "    p = Pool(default_num_threads)\n",
    "    results = p.starmap(verify_contains_only_expected_labels, zip(label_files, [expected_labels] * len(label_files)))\n",
    "    p.close()\n",
    "    p.join()\n",
    "\n",
    "    fail = False\n",
    "    print(\"Expected label values are\", expected_labels)\n",
    "    for i, r in enumerate(results):\n",
    "        if not r[0]:\n",
    "            print(\"Unexpected labels found in file %s. Found these unexpected values (they should not be there) %s\" % (\n",
    "                label_files[i], r[1]))\n",
    "            fail = True\n",
    "\n",
    "    if fail:\n",
    "        raise AssertionError(\n",
    "            \"Found unexpected labels in the training dataset. Please correct that or adjust your dataset.json accordingly\")\n",
    "    else:\n",
    "        print(\"Labels OK\")\n",
    "\n",
    "    # check test set, but only if there actually is a test set\n",
    "    if len(expected_test_identifiers) > 0:\n",
    "        print(\"Verifying test set\")\n",
    "        nii_files_in_imagesTs = subfiles((join(folder, \"imagesTs\")), suffix=\".nii.gz\", join=False)\n",
    "\n",
    "        for c in expected_test_identifiers:\n",
    "            # check if all files are present\n",
    "            expected_image_files = [join(folder, \"imagesTs\", c + \"_%04.0d.nii.gz\" % i) for i in range(num_modalities)]\n",
    "            assert all([isfile(i) for i in\n",
    "                        expected_image_files]), \"some image files are missing for case %s. Expected files:\\n %s\" % (\n",
    "                c, expected_image_files)\n",
    "\n",
    "            # verify that all modalities and the label have the same geometry. We use the affine for this\n",
    "            if num_modalities > 1:\n",
    "                images_itk = [sitk.ReadImage(i) for i in expected_image_files]\n",
    "                reference_img = images_itk[0]\n",
    "\n",
    "                for i, img in enumerate(images_itk[1:]):\n",
    "                    assert verify_same_geometry(img, reference_img), \"The modalities of the image %s do not seem to be \" \\\n",
    "                                                                     \"registered. Please coregister your modalities.\" % (\n",
    "                                                                         expected_image_files[i])\n",
    "\n",
    "            # now remove checked files from the lists nii_files_in_imagesTr and nii_files_in_labelsTr\n",
    "            for i in expected_image_files:\n",
    "                nii_files_in_imagesTs.remove(os.path.basename(i))\n",
    "        assert len(\n",
    "            nii_files_in_imagesTs) == 0, \"there are training cases in imagesTs that are not listed in dataset.json: %s\" % nii_files_in_imagesTr\n",
    "\n",
    "    all_same, unique_orientations = verify_all_same_orientation(join(folder, \"imagesTr\"))\n",
    "    if not all_same:\n",
    "        print(\n",
    "            \"WARNING: Not all images in the dataset have the same axis ordering. We very strongly recommend you correct that by reorienting the data. fslreorient2std should do the trick\")\n",
    "    # save unique orientations to dataset.json\n",
    "    if not geometries_OK:\n",
    "        raise Warning(\"GEOMETRY MISMATCH FOUND! CHECK THE TEXT OUTPUT! This does not cause an error at this point  but you should definitely check whether your geometries are alright!\")\n",
    "    else:\n",
    "        print(\"Dataset OK\")\n",
    "\n",
    "    if has_nan:\n",
    "        raise RuntimeError(\"Some images have nan values in them. This will break the training. See text output above to see which ones\")\n",
    "\n",
    "\n",
    "def reorient_to_RAS(img_fname: str, output_fname: str = None):\n",
    "    img = nib.load(img_fname)\n",
    "    canonical_img = nib.as_closest_canonical(img)\n",
    "    if output_fname is None:\n",
    "        output_fname = img_fname\n",
    "    nib.save(canonical_img, output_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected train identifiers: ['2_Tablet_Aug1', '2_Tablet_Aug2', '2_Tablet_Aug3', '2_Tablet_Aug4', '2_Tablet_Aug5', '4_GenericD12_Aug1', '4_GenericD12_Aug2', '4_GenericD12_Aug3', '4_GenericD12_Aug4', '4_GenericD12_Aug5', '5_ClaritinD12_Aug1', '5_ClaritinD12_Aug2', '5_ClaritinD12_Aug3', '5_ClaritinD12_Aug4', '5_ClaritinD12_Aug5']\n",
      "nii_files_in_imagesTr: ['2_Tablet_Aug1_0000.nii.gz', '2_Tablet_Aug2_0000.nii.gz', '2_Tablet_Aug3_0000.nii.gz', '2_Tablet_Aug4_0000.nii.gz', '2_Tablet_Aug5_0000.nii.gz', '4_GenericD12_Aug1_0000.nii.gz', '4_GenericD12_Aug2_0000.nii.gz', '4_GenericD12_Aug3_0000.nii.gz', '4_GenericD12_Aug4_0000.nii.gz', '4_GenericD12_Aug5_0000.nii.gz', '5_ClaritinD12_Aug1_0000.nii.gz', '5_ClaritinD12_Aug2_0000.nii.gz', '5_ClaritinD12_Aug3_0000.nii.gz', '5_ClaritinD12_Aug4_0000.nii.gz', '5_ClaritinD12_Aug5_0000.nii.gz']\n",
      "nii_files_in_labelsTr: ['2_Tablet_Aug1.nii.gz', '2_Tablet_Aug2.nii.gz', '2_Tablet_Aug3.nii.gz', '2_Tablet_Aug4.nii.gz', '2_Tablet_Aug5.nii.gz', '4_GenericD12_Aug1.nii.gz', '4_GenericD12_Aug2.nii.gz', '4_GenericD12_Aug3.nii.gz', '4_GenericD12_Aug4.nii.gz', '4_GenericD12_Aug5.nii.gz', '5_ClaritinD12_Aug1.nii.gz', '5_ClaritinD12_Aug2.nii.gz', '5_ClaritinD12_Aug3.nii.gz', '5_ClaritinD12_Aug4.nii.gz', '5_ClaritinD12_Aug5.nii.gz']\n",
      "Verifying training set\n",
      "checking case 2_Tablet_Aug1\n",
      "checking case 2_Tablet_Aug2\n",
      "checking case 2_Tablet_Aug3\n",
      "checking case 2_Tablet_Aug4\n",
      "checking case 2_Tablet_Aug5\n",
      "checking case 4_GenericD12_Aug1\n",
      "checking case 4_GenericD12_Aug2\n",
      "checking case 4_GenericD12_Aug3\n",
      "checking case 4_GenericD12_Aug4\n",
      "checking case 4_GenericD12_Aug5\n",
      "checking case 5_ClaritinD12_Aug1\n",
      "checking case 5_ClaritinD12_Aug2\n",
      "checking case 5_ClaritinD12_Aug3\n",
      "checking case 5_ClaritinD12_Aug4\n",
      "checking case 5_ClaritinD12_Aug5\n",
      "nii_files_in_imagesTr: []\n",
      "nii_files_in_labelsTr: []\n",
      "Verifying label values\n",
      "Beginning verify_contains_only_expected_labels!\n"
     ]
    }
   ],
   "source": [
    "verify_dataset_integrity(r'c:\\Users\\dchen\\OneDrive - University of Connecticut\\Courses\\Year 4\\Fall 2024\\BME 4900 and 4910W (Kumavor)\\Python\\Files\\training\\nnUNet_raw_data_base\\nnUNet_raw_data\\Task500_ParticleSeg3D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected train identifiers: ['2_Tablet_Aug1', '2_Tablet_Aug2', '2_Tablet_Aug3', '2_Tablet_Aug4', '2_Tablet_Aug5', '4_GenericD12_Aug1', '4_GenericD12_Aug2', '4_GenericD12_Aug3', '4_GenericD12_Aug4', '4_GenericD12_Aug5', '5_ClaritinD12_Aug1', '5_ClaritinD12_Aug2', '5_ClaritinD12_Aug3', '5_ClaritinD12_Aug4', '5_ClaritinD12_Aug5']\n",
      "nii_files_in_imagesTr: ['2_Tablet_Aug1_0000.nii.gz', '2_Tablet_Aug2_0000.nii.gz', '2_Tablet_Aug3_0000.nii.gz', '2_Tablet_Aug4_0000.nii.gz', '2_Tablet_Aug5_0000.nii.gz', '4_GenericD12_Aug1_0000.nii.gz', '4_GenericD12_Aug2_0000.nii.gz', '4_GenericD12_Aug3_0000.nii.gz', '4_GenericD12_Aug4_0000.nii.gz', '4_GenericD12_Aug5_0000.nii.gz', '5_ClaritinD12_Aug1_0000.nii.gz', '5_ClaritinD12_Aug2_0000.nii.gz', '5_ClaritinD12_Aug3_0000.nii.gz', '5_ClaritinD12_Aug4_0000.nii.gz', '5_ClaritinD12_Aug5_0000.nii.gz']\n",
      "nii_files_in_labelsTr: ['2_Tablet_Aug1.nii.gz', '2_Tablet_Aug2.nii.gz', '2_Tablet_Aug3.nii.gz', '2_Tablet_Aug4.nii.gz', '2_Tablet_Aug5.nii.gz', '4_GenericD12_Aug1.nii.gz', '4_GenericD12_Aug2.nii.gz', '4_GenericD12_Aug3.nii.gz', '4_GenericD12_Aug4.nii.gz', '4_GenericD12_Aug5.nii.gz', '5_ClaritinD12_Aug1.nii.gz', '5_ClaritinD12_Aug2.nii.gz', '5_ClaritinD12_Aug3.nii.gz', '5_ClaritinD12_Aug4.nii.gz', '5_ClaritinD12_Aug5.nii.gz']\n",
      "Verifying training set\n",
      "checking case 2_Tablet_Aug1\n",
      "checking case 2_Tablet_Aug2\n",
      "checking case 2_Tablet_Aug3\n",
      "checking case 2_Tablet_Aug4\n",
      "checking case 2_Tablet_Aug5\n",
      "checking case 4_GenericD12_Aug1\n",
      "checking case 4_GenericD12_Aug2\n",
      "checking case 4_GenericD12_Aug3\n",
      "checking case 4_GenericD12_Aug4\n",
      "checking case 4_GenericD12_Aug5\n",
      "checking case 5_ClaritinD12_Aug1\n",
      "checking case 5_ClaritinD12_Aug2\n",
      "checking case 5_ClaritinD12_Aug3\n",
      "checking case 5_ClaritinD12_Aug4\n",
      "checking case 5_ClaritinD12_Aug5\n",
      "nii_files_in_imagesTr: []\n",
      "nii_files_in_labelsTr: []\n",
      "Verifying label values\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "verify_dataset_integrity(r'c:\\Users\\dchen\\OneDrive - University of Connecticut\\Courses\\Year 4\\Fall 2024\\BME 4900 and 4910W (Kumavor)\\Python\\Files\\training\\nnUNet_raw_data_base\\nnUNet_raw_data\\Task501_ParticleSeg3D')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Senior_Design_py310_source",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.measure import regionprops\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.stats import skew, kurtosis\n",
    "from skimage import measure\n",
    "from scipy.spatial.distance import pdist\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "def load_data_from_dir(input_dir):\n",
    "    \"\"\"Load 3D instance segmentation from a directory of 2D TIFF slices.\"\"\"\n",
    "    file_list = sorted([f for f in os.listdir(input_dir) if f.endswith('.tiff')])\n",
    "    if not file_list:\n",
    "        raise ValueError(f\"No TIFF images found in {input_dir}\")\n",
    "    return np.stack([tiff.imread(os.path.join(input_dir, f)) for f in file_list])\n",
    "\n",
    "def compute_psd(segmentation):\n",
    "    \"\"\"Compute volume, surface area, diameter, and sphericity for each particle in the 3D segmentation.\"\"\"\n",
    "    labels = segmentation\n",
    "    props = regionprops(labels)\n",
    "\n",
    "    def compute_metrics(prop):\n",
    "        if prop.label == 0:  # Exclude background\n",
    "            return None\n",
    "\n",
    "        instance_label = prop.label  # Instance ID\n",
    "        volume = prop.area  # Voxel count as volume\n",
    "        \n",
    "        bbox = prop.bbox\n",
    "        min_x, min_y, min_z, max_x, max_y, max_z = bbox\n",
    "        surface_area = (\n",
    "            np.sum(segmentation[min_x+1:max_x, min_y:max_y, min_z:max_z] != \n",
    "                   segmentation[min_x:max_x-1, min_y:max_y, min_z:max_z]) +\n",
    "            np.sum(segmentation[min_x:max_x, min_y+1:max_y, min_z:max_z] != \n",
    "                   segmentation[min_x:max_x, min_y:max_y-1, min_z:max_z]) +\n",
    "            np.sum(segmentation[min_x:max_x, min_y:max_y, min_z+1:max_z] != \n",
    "                   segmentation[min_x:max_x, min_y:max_y, min_z:max_z-1])\n",
    "        )\n",
    "        \n",
    "        # Get other regionprops properties\n",
    "        diameter = prop.equivalent_diameter_area # (6 * volume / np.pi) ** (1/3)\n",
    "\n",
    "        # Compute sphericity: the ratio of the surface area of a sphere with the same volume as the object to the surface area of the object itself\n",
    "        sphericity = (np.pi ** (1/3) * (6 * volume) ** (2/3)) / surface_area if surface_area > 0 else 0\n",
    "        if sphericity > 1:\n",
    "            sphericity = 0\n",
    "\n",
    "        return instance_label, volume, surface_area, diameter, sphericity\n",
    "    \n",
    "    results = Parallel(n_jobs=-1)(delayed(compute_metrics)(prop) for prop in props)\n",
    "    results = [r for r in results if r is not None]  # Remove None values\n",
    "\n",
    "    if results:\n",
    "        instance_labels, volumes, surface_areas, diameters, sphericities = zip(*results)\n",
    "    else:\n",
    "        instance_labels, volumes, surface_areas, diameters, sphericities = ([], [], [], [], [])\n",
    "\n",
    "    return [np.array(instance_labels), np.array(volumes), np.array(surface_areas), np.array(diameters), np.array(sphericities)]\n",
    "\n",
    "def filter_by_iqr(raw_psd_metrics, threshold_factor=7.5):\n",
    "    \"\"\"Remove outliers using the IQR method and return filtered data.\"\"\"\n",
    "    if len(raw_psd_metrics[0]) == 0:\n",
    "        return raw_psd_metrics  # Return empty if no data\n",
    "\n",
    "    Q1 = np.percentile(raw_psd_metrics[1], 25)\n",
    "    Q3 = np.percentile(raw_psd_metrics[1], 75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - threshold_factor * IQR\n",
    "    upper_bound = Q3 + threshold_factor * IQR\n",
    "\n",
    "    mask = (raw_psd_metrics[1] >= lower_bound) & (raw_psd_metrics[1] <= upper_bound)\n",
    "    return [raw_psd_metrics[0][mask], raw_psd_metrics[1][mask], raw_psd_metrics[2][mask], raw_psd_metrics[3][mask], raw_psd_metrics[4][mask]]\n",
    "\n",
    "def filter_by_threshold(raw_psd_metrics, threshold=('diameter', 50)):\n",
    "    \"\"\"Filter particles based on a specified threshold for various metrics.\"\"\"\n",
    "    # Apply the appropriate threshold based on the specified metric\n",
    "    if threshold[0] == 'volume':\n",
    "        mask = raw_psd_metrics[1] <= threshold[1]\n",
    "    elif threshold[0] == 'surface area':\n",
    "        mask = raw_psd_metrics[2] <= threshold[1]\n",
    "    elif threshold[0] == 'diameter':\n",
    "        mask = raw_psd_metrics[3] <= threshold[1]\n",
    "    else:\n",
    "        raise ValueError('The threshold type must be one of the following: `volume`, `surface area`, or `diameter`!')\n",
    "    \n",
    "    # Return the filtered data based on the threshold\n",
    "    return [raw_psd_metrics[0][mask], raw_psd_metrics[1][mask], raw_psd_metrics[2][mask], raw_psd_metrics[3][mask], raw_psd_metrics[4][mask]], threshold\n",
    "\n",
    "def bin_data(data, bin_edges):\n",
    "    \"\"\"Bin the data according to the bin edges and return the bin counts.\"\"\"\n",
    "    counts, _ = np.histogram(data, bins=bin_edges)\n",
    "    return counts\n",
    "\n",
    "def save_psd_to_csv(psd_metrics, save_path):\n",
    "    \"\"\"Apply outlier removal using IQR and save results to CSV.\"\"\"\n",
    "    df = pd.DataFrame({\n",
    "        \"Instance\": psd_metrics[0],\n",
    "        \"Volume\": psd_metrics[1],\n",
    "        \"Surface Area\": psd_metrics[2],\n",
    "        \"Diameter\": psd_metrics[3],\n",
    "        \"Sphericity\": psd_metrics[4]\n",
    "    })\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f\"Saved PSD as CSV to {save_path}\")\n",
    "\n",
    "def save_histogram(data, bin_edges, title, xlabel, save_path):\n",
    "    \"\"\"Save histogram plot with scaled x-axis, excluding zero values.\"\"\"\n",
    "    data = data[data > 0]  # Exclude zero values\n",
    "    if len(data) == 0:\n",
    "        print(f\"Warning: No valid data for histogram {title}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.hist(data, bins=bin_edges, edgecolor='black', alpha=0.7)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(\"Particle Count\")\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def save_binned_psd(psd_metrics, save_path, num_bins=50, threshold=None):\n",
    "    \"\"\"Save binned Particle Size Distribution (PSD) to CSV for multiple metrics.\"\"\"\n",
    "    volume_min = 0\n",
    "    surface_area_min = 0\n",
    "    diameter_min = 0\n",
    "    sphericity_min = 0\n",
    "    \n",
    "    # Range from 0 to 1\n",
    "    sphericity_max = 1\n",
    "    \n",
    "    if threshold is None:\n",
    "        # Calculate the range for each dataset and round accordingly\n",
    "        volume_max = np.ceil(max(psd_metrics[1]))   # Round up\n",
    "        surface_area_max = np.ceil(max(psd_metrics[2]))   # Round up\n",
    "        diameter_max = np.ceil(max(psd_metrics[3]))   # Round up\n",
    "    else:\n",
    "        if threshold[0] == 'volume':\n",
    "            volume_max = threshold[1]\n",
    "            diameter_max = np.ceil((6 * volume_max / np.pi) ** (1/3))\n",
    "            surface_area_max = np.ceil(4 * np.pi * (diameter_max / 2) ** 2)\n",
    "        elif threshold[0] == 'surface area':\n",
    "            surface_area_max = threshold[1]\n",
    "            diameter_max = np.ceil(np.sqrt(surface_area_max / (4 * np.pi)) * 2)\n",
    "            volume_max = np.ceil((4/3) * np.pi * (diameter_max / 2) ** 3)\n",
    "            print('Please note that thresholding based on surface area may lead to odd binned histograms due to the very approximate estimation of surface area that is not directly related to volume or diameter.')\n",
    "        elif threshold[0] == 'diameter':\n",
    "            diameter_max = threshold[1]\n",
    "            volume_max = np.ceil((4/3) * np.pi * (diameter_max / 2) ** 3)\n",
    "            surface_area_max = np.ceil(4 * np.pi * (diameter_max / 2) ** 2)\n",
    "        else:\n",
    "            raise ValueError('The threshold type must be one of the following: `volume`, `surface area`, or `diameter`!')\n",
    "\n",
    "    def create_bins(min_val, max_val, num_bins):\n",
    "        bin_range = max_val - min_val\n",
    "        if bin_range >= num_bins:\n",
    "            return np.linspace(min_val, max_val, num_bins + 1, dtype=int)\n",
    "        else:\n",
    "            extra_bins = num_bins - bin_range  # Add extra bins if range is small\n",
    "            return np.linspace(min_val, max_val + extra_bins, num_bins + 1, dtype=int)\n",
    "\n",
    "    def create_log_bins(min_val, max_val, num_bins, epsilon=1e-6):\n",
    "        # Shift values to avoid log(0) error\n",
    "        min_val = max(min_val, epsilon)\n",
    "        log_min = np.log10(min_val)\n",
    "        log_max = np.log10(max_val)\n",
    "        log_bins = np.logspace(log_min, log_max, num_bins + 1)\n",
    "        return np.unique(log_bins)\n",
    "    \n",
    "    def create_power_bins(min_val, max_val, num_bins, power=2):\n",
    "        # Create bins using a power law scaling\n",
    "        bins = np.linspace(min_val ** power, max_val ** power, num_bins + 1) ** (1 / power)\n",
    "        return np.unique(np.round(bins).astype(int))\n",
    "\n",
    "    # Create bins for volume and surface area using logarithmic spacing\n",
    "    volume_bins = create_bins(volume_min, volume_max, num_bins)\n",
    "    surface_area_bins = np.linspace(surface_area_min, surface_area_max, num_bins + 1)\n",
    "    diameter_bins = np.linspace(diameter_min, diameter_max, num_bins + 1)\n",
    "    sphericity_bins = np.linspace(sphericity_min, sphericity_max, num_bins + 1)\n",
    "\n",
    "    volume_counts = bin_data(psd_metrics[1], volume_bins)\n",
    "    surface_area_counts = bin_data(psd_metrics[2], surface_area_bins)\n",
    "    diameter_counts = bin_data(psd_metrics[3], diameter_bins)\n",
    "    sphericity_counts = bin_data(psd_metrics[4], sphericity_bins)\n",
    "\n",
    "    volume_bin_ranges = [f\"{v1}.0-{v2}.0\" for v1, v2 in zip(volume_bins[:-1], volume_bins[1:])]\n",
    "    surface_area_bin_ranges = [f\"{s1}-{s2}\" for s1, s2 in zip(surface_area_bins[:-1], surface_area_bins[1:])]\n",
    "    diameter_bin_ranges = [f\"{d1}-{d2}\" for d1, d2 in zip(diameter_bins[:-1], diameter_bins[1:])]\n",
    "    sphericity_bin_ranges = [f\"{d1}-{d2}\" for d1, d2 in zip(sphericity_bins[:-1], sphericity_bins[1:])]\n",
    "    \n",
    "    binned_df = pd.DataFrame({\n",
    "        \"Volume Bin Range\": volume_bin_ranges,\n",
    "        \"Volume Count\": volume_counts,\n",
    "        \"Surface Area Bin Range\": surface_area_bin_ranges,\n",
    "        \"Surface Area Count\": surface_area_counts,\n",
    "        \"Diameter Bin Range\": diameter_bin_ranges,\n",
    "        \"Diameter Count\": diameter_counts,\n",
    "        \"Sphericity Bin Range\": sphericity_bin_ranges,\n",
    "        \"Sphericity Count\": sphericity_counts\n",
    "    })\n",
    "\n",
    "    binned_df.to_csv(save_path, index=False)\n",
    "    print(f\"Saved binned PSD results to {save_path}\")\n",
    "\n",
    "    return [volume_bins, surface_area_bins, diameter_bins, sphericity_bins]\n",
    "\n",
    "def save_summary_metrics(psd_metrics, psd_metric_names, save_dir, run_tag, name, prefix):\n",
    "    \"\"\"Compute and save summary metrics (mean, std, median, IQR, percentiles, skewness, kurtosis) for PSD data.\"\"\"\n",
    "    \n",
    "   # Compute basic statistics\n",
    "    total_particles = len(psd_metrics[0])\n",
    "    total_volume = np.sum(psd_metrics[1])\n",
    "    total_surface_area = np.sum(psd_metrics[2])\n",
    "    \n",
    "    summary = {\n",
    "        \"Total Particles\": total_particles,\n",
    "        \"Total Volume\": total_volume,\n",
    "        \"Total Surface Area\": total_surface_area\n",
    "    }\n",
    "    \n",
    "    if len(psd_metrics) - 1 != len(psd_metric_names):\n",
    "        raise RuntimeError(\"Mismatch between the number of PSD metrics and metric names.\")\n",
    "    \n",
    "    for psd_metric, psd_metric_name in zip(psd_metrics[1:], psd_metric_names):\n",
    "        skewness = skew(psd_metric)\n",
    "        kurt = kurtosis(psd_metric)\n",
    "        percentiles = np.percentile(psd_metric, [25, 50, 75])\n",
    "\n",
    "        # Add calculated metrics to summary\n",
    "        summary.update({\n",
    "            f\"Mean {psd_metric_name}\": np.mean(psd_metric),\n",
    "            f\"Std {psd_metric_name}\": np.std(psd_metric),\n",
    "            f\"Median {psd_metric_name}\": np.median(psd_metric),\n",
    "            f\"IQR {psd_metric_name}\": percentiles[2] - percentiles[0],\n",
    "            \n",
    "            f\"{psd_metric_name} 25th Percentile\": percentiles[0],\n",
    "            f\"{psd_metric_name} 50th Percentile (Median)\": percentiles[1],\n",
    "            f\"{psd_metric_name} 75th Percentile\": percentiles[2],\n",
    "            \n",
    "            f\"{psd_metric_name} Skewness\": skewness,\n",
    "            f\"{psd_metric_name} Kurtosis\": kurt,\n",
    "        })\n",
    "    \n",
    "    # Convert the summary dictionary to a DataFrame\n",
    "    summary_df = pd.DataFrame(summary, index=[0])\n",
    "\n",
    "    # Create the directory to save the summary file\n",
    "    summary_folder = os.path.join(save_dir, \"summary\", run_tag, name)\n",
    "    os.makedirs(summary_folder, exist_ok=True)\n",
    "\n",
    "    # Define the path to save the summary CSV file\n",
    "    summary_path = os.path.join(summary_folder, f\"{name}_{prefix}_summary.csv\")\n",
    "    \n",
    "    # Save the summary DataFrame to CSV\n",
    "    summary_df.to_csv(summary_path, index=False)\n",
    "    \n",
    "    print(f\"Saved summary metrics for {name} ({prefix}) to {summary_path}\")\n",
    "\n",
    "def psd(input_dir, run_tag, names, save_dir, save=True):\n",
    "    \"\"\"Analyze 3D instance segmentation and compute particle size distribution (PSD).\"\"\"\n",
    "    for name in names:\n",
    "        segmentation = load_data_from_dir(os.path.join(input_dir, name))\n",
    "        raw_psd_metrics = compute_psd(segmentation)\n",
    "\n",
    "        if save:\n",
    "            table_folder = os.path.join(save_dir, \"table\", run_tag, name)\n",
    "            hist_folder = os.path.join(save_dir, \"histogram\", run_tag, name)\n",
    "            os.makedirs(table_folder, exist_ok=True)\n",
    "            os.makedirs(hist_folder, exist_ok=True)\n",
    "\n",
    "            # Save original CSV\n",
    "            orignal_csv_path = os.path.join(table_folder, f\"{name}_raw_psd.csv\")\n",
    "            save_psd_to_csv(raw_psd_metrics, orignal_csv_path)\n",
    "\n",
    "            # Save IQR-filtered CSV\n",
    "            iqr_filt_psd_metrics = filter_by_iqr(raw_psd_metrics)\n",
    "            iqr_filt_csv_path = os.path.join(table_folder, f\"{name}_iqr_filt_psd.csv\")\n",
    "            save_psd_to_csv(iqr_filt_psd_metrics, iqr_filt_csv_path)\n",
    "\n",
    "            # Save threshold-filtered CSV\n",
    "            thresh_filt_psd_metrics, threshold = filter_by_threshold(raw_psd_metrics)\n",
    "            thresh_filt_csv_path = os.path.join(table_folder, f\"{name}_thresh_filt_psd.csv\")\n",
    "            save_psd_to_csv(thresh_filt_psd_metrics, thresh_filt_csv_path)\n",
    "\n",
    "            # Save binned PSD CSVs\n",
    "            raw_psd_bins = save_binned_psd(raw_psd_metrics, os.path.join(table_folder, f\"{name}_raw_binned_psd.csv\"), num_bins=75)\n",
    "            iqr_filt_psd_bins = save_binned_psd(iqr_filt_psd_metrics, os.path.join(table_folder, f\"{name}_iqr_filt_binned_psd.csv\"), num_bins=75)\n",
    "            thresh_filt_psd_bins = save_binned_psd(thresh_filt_psd_metrics, os.path.join(table_folder, f\"{name}_thresh_filt_binned_psd.csv\"), num_bins=75, threshold=threshold)\n",
    "\n",
    "            # Save histograms\n",
    "            psd_metric_names = ['Volume', 'Surface Area', 'Diameter', 'Sphericity']\n",
    "            psd_metric_tags = ['volume', 'surface', 'diameter', 'sphericity']\n",
    "\n",
    "            if len(psd_metric_names) != len(psd_metric_tags):\n",
    "                raise RuntimeError(\"Mismatch between the number of PSD metric names and tags.\")\n",
    "            \n",
    "            # Raw PSD values\n",
    "            if not (len(raw_psd_metrics) - 1 == len(raw_psd_bins) == len(psd_metric_names) == len(psd_metric_tags)):\n",
    "                raise RuntimeError(\"Mismatch between the number of raw PSD metrics, bins, names, and tags.\")\n",
    "            for raw_psd_metric, raw_psd_bin, psd_metric_name, psd_metric_tag in zip(raw_psd_metrics[1:], raw_psd_bins, psd_metric_names, psd_metric_tags):\n",
    "                if np.max(raw_psd_metric) <= 1:   \n",
    "                    title = f\"{psd_metric_name}\"\n",
    "                else:\n",
    "                    title = f\"{psd_metric_name} (voxels)\"\n",
    "                save_histogram(raw_psd_metric, raw_psd_bin, f\"Raw Particle {psd_metric_name} Distribution\", title, os.path.join(hist_folder, f\"{name}_raw_{psd_metric_tag}_hist.png\"))\n",
    "                \n",
    "            # IQR-filterd PSD values\n",
    "            if not (len(iqr_filt_psd_metrics) - 1 == len(iqr_filt_psd_bins) == len(psd_metric_names) == len(psd_metric_tags)):\n",
    "                raise RuntimeError(\"Mismatch between the number of IQR-filtered PSD metrics, bins, names, and tags.\")\n",
    "            for iqr_filt_psd_metric, iqr_filt_psd_bin, psd_metric_name, psd_metric_tag in zip(iqr_filt_psd_metrics[1:], iqr_filt_psd_bins, psd_metric_names, psd_metric_tags):\n",
    "                if np.max(iqr_filt_psd_metric) <= 1:   \n",
    "                    title = f\"{psd_metric_name}\"\n",
    "                else:\n",
    "                    title = f\"{psd_metric_name} (voxels)\"\n",
    "                save_histogram(iqr_filt_psd_metric, iqr_filt_psd_bin, f\"IQR-Filtered Particle {psd_metric_name} Distribution\", title, os.path.join(hist_folder, f\"{name}_iqr_filt_{psd_metric_tag}_hist.png\"))\n",
    "                \n",
    "            # Threshold-filterd PSD values\n",
    "            if not (len(thresh_filt_psd_metrics) - 1 == len(thresh_filt_psd_bins) == len(psd_metric_names) == len(psd_metric_tags)):\n",
    "                raise RuntimeError(\"Mismatch between the number of threshold-filtered PSD metrics, bins, names, and tags.\")\n",
    "            for thresh_filt_psd_metric, thresh_filt_psd_bin, psd_metric_name, psd_metric_tag in zip(thresh_filt_psd_metrics[1:], thresh_filt_psd_bins, psd_metric_names, psd_metric_tags):\n",
    "                if np.max(thresh_filt_psd_metric) <= 1:   \n",
    "                    title = f\"{psd_metric_name}\"\n",
    "                else:\n",
    "                    title = f\"{psd_metric_name} (voxels)\"\n",
    "                save_histogram(thresh_filt_psd_metric, thresh_filt_psd_bin, f\"Threshold-Filtered Particle {psd_metric_name} Distribution\", title, os.path.join(hist_folder, f\"{name}_thresh_filt_{psd_metric_tag}_hist.png\"))\n",
    "\n",
    "            # Save summary metrics\n",
    "            lists_of_psd_metrics = [raw_psd_metrics, iqr_filt_psd_metrics, thresh_filt_psd_metrics]\n",
    "            prefixes = ['raw', 'iqr_filt', 'thresh_filt']\n",
    "\n",
    "            if len(lists_of_psd_metrics) != len(prefixes):\n",
    "                raise RuntimeError(\"Mismatch between the number of PSD metric lists and prefixes.\")\n",
    "            \n",
    "            for list_of_psd_metrics, prefix in zip(lists_of_psd_metrics, prefixes):\n",
    "                save_summary_metrics(list_of_psd_metrics, psd_metric_names, save_dir, run_tag, name, prefix=prefix)\n",
    "\n",
    "            print(f\"Saved results for {name}.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_paths(dir_location, run_tag, output_to_cloud=False):\n",
    "    if dir_location.lower() == 'internal':\n",
    "        base_path = r'C:\\Senior_Design'\n",
    "    elif dir_location.lower() == 'external':\n",
    "        base_path = r'D:\\Senior_Design'\n",
    "    elif dir_location.lower() == 'cloud':\n",
    "        base_path = r'C:\\Users\\dchen\\OneDrive - University of Connecticut\\Courses\\Year 4\\Fall 2024\\BME 4900 and 4910W (Kumavor)\\Python\\Files'\n",
    "    elif dir_location.lower() == 'refine':\n",
    "        base_path = r'D:\\Darren\\Files'\n",
    "    else:\n",
    "        raise ValueError('Invalid directory location type')\n",
    "\n",
    "    base_input_path = os.path.join(base_path, 'outputs', 'tiff')\n",
    "    psd_path = os.path.join(base_path, 'outputs', 'metrics', 'particle_size_dist_v5')\n",
    "    \n",
    "    if output_to_cloud:\n",
    "        psd_path = os.path.join(r'C:\\Users\\dchen\\OneDrive - University of Connecticut\\Courses\\Year 4\\Fall 2024\\BME 4900 and 4910W (Kumavor)\\Python\\Files', 'outputs', 'metrics', 'particle_size_dist')\n",
    "\n",
    "    input_tiff_path = os.path.join(base_input_path, run_tag)\n",
    "\n",
    "    print('Paths set')\n",
    "    print('Input:', input_tiff_path)\n",
    "    print('Output:', psd_path)\n",
    "    print()\n",
    "    return input_tiff_path, psd_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths set\n",
      "Input: D:\\Darren\\Files\\outputs\\tiff\\pretrained_tab40_gen35_clar35_fold4\n",
      "Output: D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v4\n",
      "\n",
      "Saved PSD as CSV to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v4\\table\\ground_truth\\2_Tablet\\2_Tablet_raw_psd.csv\n",
      "Saved PSD as CSV to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v4\\table\\ground_truth\\2_Tablet\\2_Tablet_iqr_filt_psd.csv\n",
      "Saved PSD as CSV to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v4\\table\\ground_truth\\2_Tablet\\2_Tablet_thresh_filt_psd.csv\n",
      "Saved binned PSD results to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v4\\table\\ground_truth\\2_Tablet\\2_Tablet_raw_binned_psd.csv\n",
      "Saved binned PSD results to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v4\\table\\ground_truth\\2_Tablet\\2_Tablet_iqr_filt_binned_psd.csv\n",
      "Saved binned PSD results to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v4\\table\\ground_truth\\2_Tablet\\2_Tablet_thresh_filt_binned_psd.csv\n",
      "Saved summary metrics for 2_Tablet (raw) to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v4\\summary\\ground_truth\\2_Tablet\\2_Tablet_raw_summary.csv\n",
      "Saved summary metrics for 2_Tablet (iqr_filt) to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v4\\summary\\ground_truth\\2_Tablet\\2_Tablet_iqr_filt_summary.csv\n",
      "Saved summary metrics for 2_Tablet (thresh_filt) to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v4\\summary\\ground_truth\\2_Tablet\\2_Tablet_thresh_filt_summary.csv\n",
      "Saved results for 2_Tablet.\n",
      "\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 21.3 TiB for an array with shape (2931989735395,) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\ZEISS\\anaconda3\\envs\\Senior_Design_py310_source\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 463, in _process_worker\n    r = call_item()\n  File \"c:\\Users\\ZEISS\\anaconda3\\envs\\Senior_Design_py310_source\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"c:\\Users\\ZEISS\\anaconda3\\envs\\Senior_Design_py310_source\\lib\\site-packages\\joblib\\parallel.py\", line 598, in __call__\n    return [func(*args, **kwargs)\n  File \"c:\\Users\\ZEISS\\anaconda3\\envs\\Senior_Design_py310_source\\lib\\site-packages\\joblib\\parallel.py\", line 598, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"C:\\Users\\ZEISS\\AppData\\Local\\Temp\\ipykernel_17044\\2796866426.py\", line 62, in compute_metrics\n  File \"C:\\Users\\ZEISS\\AppData\\Local\\Temp\\ipykernel_17044\\2796866426.py\", line 48, in manual_feret_diameter_and_surface_area\n  File \"c:\\Users\\ZEISS\\anaconda3\\envs\\Senior_Design_py310_source\\lib\\site-packages\\scipy\\spatial\\distance.py\", line 2322, in pdist\n    return pdist_fn(X, out=out, **kwargs)\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 21.3 TiB for an array with shape (2931989735395,) and data type float64\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# input_tiff_path = r'd:\\Darren\\OneDrive - University of Connecticut\\Courses\\Year 4\\Fall 2024\\BME 4900 and 4910W (Kumavor)\\Python\\Files\\database\\tablet_dataset\\instance\\tiff'\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# input_tiff_path = r'd:\\Senior_Design\\database\\tablet_dataset\\instance\\tiff'\u001b[39;00m\n\u001b[0;32m     12\u001b[0m run_tag \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mground_truth\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 14\u001b[0m \u001b[43mpsd\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tiff_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_tag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpsd_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 308\u001b[0m, in \u001b[0;36mpsd\u001b[1;34m(input_dir, run_tag, names, save_dir, save)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m names:\n\u001b[0;32m    307\u001b[0m     segmentation \u001b[38;5;241m=\u001b[39m load_data_from_dir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_dir, name))\n\u001b[1;32m--> 308\u001b[0m     raw_psd_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_psd\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegmentation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    310\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m save:\n\u001b[0;32m    311\u001b[0m         table_folder \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(save_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m, run_tag, name)\n",
      "Cell \u001b[1;32mIn[4], line 76\u001b[0m, in \u001b[0;36mcompute_psd\u001b[1;34m(segmentation)\u001b[0m\n\u001b[0;32m     72\u001b[0m         sphericity \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m instance_label, volume, surface_area, diameter, feret, solidity, sphericity\n\u001b[1;32m---> 76\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprop\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprops\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m results \u001b[38;5;241m=\u001b[39m [r \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]  \u001b[38;5;66;03m# Remove None values\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results:\n",
      "File \u001b[1;32mc:\\Users\\ZEISS\\anaconda3\\envs\\Senior_Design_py310_source\\lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ZEISS\\anaconda3\\envs\\Senior_Design_py310_source\\lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ZEISS\\anaconda3\\envs\\Senior_Design_py310_source\\lib\\site-packages\\joblib\\parallel.py:1754\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1748\u001b[0m \n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1751\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1752\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1754\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1755\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1757\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ZEISS\\anaconda3\\envs\\Senior_Design_py310_source\\lib\\site-packages\\joblib\\parallel.py:1789\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1785\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediately raise the error by\u001b[39;00m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1789\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ZEISS\\anaconda3\\envs\\Senior_Design_py310_source\\lib\\site-packages\\joblib\\parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    739\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    741\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    742\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    744\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\ZEISS\\anaconda3\\envs\\Senior_Design_py310_source\\lib\\site-packages\\joblib\\parallel.py:763\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 763\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 21.3 TiB for an array with shape (2931989735395,) and data type float64"
     ]
    }
   ],
   "source": [
    "dir_location = 'refine'\n",
    "run_tag = 'pretrained_tab40_gen35_clar35_fold4'\n",
    "input_tiff_path, psd_path = setup_paths(dir_location, run_tag)\n",
    "save = True  # Set to True if you want to save both histograms and PSD data\n",
    "names = ['2_Tablet', '4_GenericD12', '5_ClaritinD12']\n",
    "\n",
    "# For ground truth instance segmentation\n",
    "# input_tiff_path = r'C:\\Users\\dchen\\OneDrive - University of Connecticut\\Courses\\Year 4\\Fall 2024\\BME 4900 and 4910W (Kumavor)\\Python\\Files\\database\\tablet_dataset\\instance\\tiff'\n",
    "input_tiff_path = r'd:\\Darren\\Files\\database\\tablet_dataset\\instance\\tiff'\n",
    "# input_tiff_path = r'd:\\Darren\\OneDrive - University of Connecticut\\Courses\\Year 4\\Fall 2024\\BME 4900 and 4910W (Kumavor)\\Python\\Files\\database\\tablet_dataset\\instance\\tiff'\n",
    "# input_tiff_path = r'd:\\Senior_Design\\database\\tablet_dataset\\instance\\tiff'\n",
    "run_tag = 'ground_truth'\n",
    "\n",
    "psd(input_tiff_path, run_tag, names, psd_path, save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_location = 'refine'\n",
    "run_tag = 'pretrained_tab40_gen35_clar35_fold1'\n",
    "input_tiff_path, psd_path = setup_paths(dir_location, run_tag)\n",
    "save = True  # Set to True if you want to save both histograms and PSD data\n",
    "names = ['2_Tablet', '4_GenericD12', '5_ClaritinD12']\n",
    "\n",
    "# # For ground truth instance segmentation\n",
    "# # input_tiff_path = r'C:\\Users\\dchen\\OneDrive - University of Connecticut\\Courses\\Year 4\\Fall 2024\\BME 4900 and 4910W (Kumavor)\\Python\\Files\\database\\tablet_dataset\\instance\\tiff'\n",
    "# input_tiff_path = r'd:\\Darren\\Files\\database\\tablet_dataset\\instance\\tiff'\n",
    "# # input_tiff_path = r'd:\\Darren\\OneDrive - University of Connecticut\\Courses\\Year 4\\Fall 2024\\BME 4900 and 4910W (Kumavor)\\Python\\Files\\database\\tablet_dataset\\instance\\tiff'\n",
    "# # input_tiff_path = r'd:\\Senior_Design\\database\\tablet_dataset\\instance\\tiff'\n",
    "# run_tag = 'ground_truth'\n",
    "\n",
    "psd(input_tiff_path, run_tag, names, psd_path, save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_location = 'refine'\n",
    "run_tag = 'pretrained_tab40_gen35_clar35_fold2'\n",
    "input_tiff_path, psd_path = setup_paths(dir_location, run_tag)\n",
    "save = True  # Set to True if you want to save both histograms and PSD data\n",
    "names = ['2_Tablet', '4_GenericD12', '5_ClaritinD12']\n",
    "\n",
    "# # For ground truth instance segmentation\n",
    "# # input_tiff_path = r'C:\\Users\\dchen\\OneDrive - University of Connecticut\\Courses\\Year 4\\Fall 2024\\BME 4900 and 4910W (Kumavor)\\Python\\Files\\database\\tablet_dataset\\instance\\tiff'\n",
    "# input_tiff_path = r'd:\\Darren\\Files\\database\\tablet_dataset\\instance\\tiff'\n",
    "# # input_tiff_path = r'd:\\Darren\\OneDrive - University of Connecticut\\Courses\\Year 4\\Fall 2024\\BME 4900 and 4910W (Kumavor)\\Python\\Files\\database\\tablet_dataset\\instance\\tiff'\n",
    "# # input_tiff_path = r'd:\\Senior_Design\\database\\tablet_dataset\\instance\\tiff'\n",
    "# run_tag = 'ground_truth'\n",
    "\n",
    "psd(input_tiff_path, run_tag, names, psd_path, save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_location = 'refine'\n",
    "run_tag = 'pretrained_tab40_gen35_clar35_fold3'\n",
    "input_tiff_path, psd_path = setup_paths(dir_location, run_tag)\n",
    "save = True  # Set to True if you want to save both histograms and PSD data\n",
    "names = ['2_Tablet', '4_GenericD12', '5_ClaritinD12']\n",
    "\n",
    "# # For ground truth instance segmentation\n",
    "# # input_tiff_path = r'C:\\Users\\dchen\\OneDrive - University of Connecticut\\Courses\\Year 4\\Fall 2024\\BME 4900 and 4910W (Kumavor)\\Python\\Files\\database\\tablet_dataset\\instance\\tiff'\n",
    "# input_tiff_path = r'd:\\Darren\\Files\\database\\tablet_dataset\\instance\\tiff'\n",
    "# # input_tiff_path = r'd:\\Darren\\OneDrive - University of Connecticut\\Courses\\Year 4\\Fall 2024\\BME 4900 and 4910W (Kumavor)\\Python\\Files\\database\\tablet_dataset\\instance\\tiff'\n",
    "# # input_tiff_path = r'd:\\Senior_Design\\database\\tablet_dataset\\instance\\tiff'\n",
    "# run_tag = 'ground_truth'\n",
    "\n",
    "psd(input_tiff_path, run_tag, names, psd_path, save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_location = 'refine'\n",
    "run_tag = 'pretrained_tab40_gen35_clar35_fold4'\n",
    "input_tiff_path, psd_path = setup_paths(dir_location, run_tag)\n",
    "save = True  # Set to True if you want to save both histograms and PSD data\n",
    "names = ['2_Tablet', '4_GenericD12', '5_ClaritinD12']\n",
    "\n",
    "# # For ground truth instance segmentation\n",
    "# # input_tiff_path = r'C:\\Users\\dchen\\OneDrive - University of Connecticut\\Courses\\Year 4\\Fall 2024\\BME 4900 and 4910W (Kumavor)\\Python\\Files\\database\\tablet_dataset\\instance\\tiff'\n",
    "# input_tiff_path = r'd:\\Darren\\Files\\database\\tablet_dataset\\instance\\tiff'\n",
    "# # input_tiff_path = r'd:\\Darren\\OneDrive - University of Connecticut\\Courses\\Year 4\\Fall 2024\\BME 4900 and 4910W (Kumavor)\\Python\\Files\\database\\tablet_dataset\\instance\\tiff'\n",
    "# # input_tiff_path = r'd:\\Senior_Design\\database\\tablet_dataset\\instance\\tiff'\n",
    "# run_tag = 'ground_truth'\n",
    "\n",
    "psd(input_tiff_path, run_tag, names, psd_path, save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_location = 'refine'\n",
    "run_tag = 'pretrained_tab40_gen35_clar35_foldsALL'\n",
    "input_tiff_path, psd_path = setup_paths(dir_location, run_tag)\n",
    "save = True  # Set to True if you want to save both histograms and PSD data\n",
    "names = ['2_Tablet', '4_GenericD12', '5_ClaritinD12']\n",
    "\n",
    "# # For ground truth instance segmentation\n",
    "# # input_tiff_path = r'C:\\Users\\dchen\\OneDrive - University of Connecticut\\Courses\\Year 4\\Fall 2024\\BME 4900 and 4910W (Kumavor)\\Python\\Files\\database\\tablet_dataset\\instance\\tiff'\n",
    "# input_tiff_path = r'd:\\Darren\\Files\\database\\tablet_dataset\\instance\\tiff'\n",
    "# # input_tiff_path = r'd:\\Darren\\OneDrive - University of Connecticut\\Courses\\Year 4\\Fall 2024\\BME 4900 and 4910W (Kumavor)\\Python\\Files\\database\\tablet_dataset\\instance\\tiff'\n",
    "# # input_tiff_path = r'd:\\Senior_Design\\database\\tablet_dataset\\instance\\tiff'\n",
    "# run_tag = 'ground_truth'\n",
    "\n",
    "psd(input_tiff_path, run_tag, names, psd_path, save)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Senior_Design_py310_source",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

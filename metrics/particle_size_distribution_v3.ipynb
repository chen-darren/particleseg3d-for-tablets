{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.measure import regionprops\n",
    "from joblib import Parallel, delayed\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "\n",
    "def load_data_from_dir(input_dir):\n",
    "    \"\"\"Load 3D instance segmentation from a directory of 2D TIFF slices.\"\"\"\n",
    "    file_list = sorted([f for f in os.listdir(input_dir) if f.endswith('.tiff')])\n",
    "    if not file_list:\n",
    "        raise ValueError(f\"No TIFF images found in {input_dir}\")\n",
    "    return np.stack([tiff.imread(os.path.join(input_dir, f)) for f in file_list])\n",
    "\n",
    "def compute_psd(segmentation):\n",
    "    \"\"\"Compute volume, surface area (using Marching Cubes), and sphericity for each particle in the 3D segmentation.\"\"\"\n",
    "    labels = segmentation\n",
    "    props = regionprops(labels)\n",
    "\n",
    "    def compute_metrics(prop):\n",
    "        if prop.label == 0:  # Exclude background\n",
    "            return None\n",
    "\n",
    "        instance_label = prop.label  # Instance ID\n",
    "        volume = prop.area  # Voxel count as volume\n",
    "        bbox = prop.bbox\n",
    "        min_x, min_y, min_z, max_x, max_y, max_z = bbox\n",
    "        surface_area = (\n",
    "            np.sum(segmentation[min_x+1:max_x, min_y:max_y, min_z:max_z] != \n",
    "                   segmentation[min_x:max_x-1, min_y:max_y, min_z:max_z]) +\n",
    "            np.sum(segmentation[min_x:max_x, min_y+1:max_y, min_z:max_z] != \n",
    "                   segmentation[min_x:max_x, min_y:max_y-1, min_z:max_z]) +\n",
    "            np.sum(segmentation[min_x:max_x, min_y:max_y, min_z+1:max_z] != \n",
    "                   segmentation[min_x:max_x, min_y:max_y, min_z:max_z-1])\n",
    "        )\n",
    "        # Compute spherical equivalent diameter\n",
    "        diameter = (6 * volume / np.pi) ** (1/3)\n",
    "\n",
    "        # Compute sphericity: the ratio of the surface area of a sphere with the same volume as the object to the surface area of the object itself\n",
    "        sphericity = (np.pi ** (1/3) * (6 * volume) ** (2/3)) / surface_area if surface_area > 0 else 0\n",
    "        if sphericity > 1:\n",
    "            sphericity = 0\n",
    "\n",
    "        return instance_label, volume, surface_area, diameter, sphericity\n",
    "    \n",
    "    results = Parallel(n_jobs=-1)(delayed(compute_metrics)(prop) for prop in props)\n",
    "    results = [r for r in results if r is not None]  # Remove None values\n",
    "\n",
    "    if results:\n",
    "        instance_labels, volumes, surface_areas, diameters, sphericities = zip(*results)\n",
    "    else:\n",
    "        instance_labels, volumes, surface_areas, diameters, sphericities = ([], [], [], [], [], [])\n",
    "\n",
    "    return np.array(instance_labels), np.array(volumes), np.array(surface_areas), np.array(diameters), np.array(sphericities)\n",
    "\n",
    "def filter_by_iqr(instance_labels, volume, surface_areas, diameters, sphericities, threshold_factor=7.5):\n",
    "    \"\"\"Remove outliers using the IQR method and return filtered data.\"\"\"\n",
    "    if len(volume) == 0:\n",
    "        return instance_labels, volume, surface_areas, diameters, sphericities  # Return empty if no data\n",
    "\n",
    "    Q1 = np.percentile(volume, 25)\n",
    "    Q3 = np.percentile(volume, 75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - threshold_factor * IQR\n",
    "    upper_bound = Q3 + threshold_factor * IQR\n",
    "\n",
    "    mask = (volume >= lower_bound) & (volume <= upper_bound)\n",
    "    return instance_labels[mask], volume[mask], surface_areas[mask], diameters[mask], sphericities[mask]\n",
    "\n",
    "def filter_by_threshold(instance_labels, volumes, surface_areas, diameters, sphericities, threshold=('diameter', 50)):\n",
    "    \"\"\"Filter particles based on a specified threshold for various metrics.\"\"\"\n",
    "    # Apply the appropriate threshold based on the specified metric\n",
    "    if threshold[0] == 'volume':\n",
    "        mask = volumes <= threshold[1]\n",
    "    elif threshold[0] == 'surface area':\n",
    "        mask = surface_areas <= threshold[1]\n",
    "    elif threshold[0] == 'diameter':\n",
    "        mask = diameters <= threshold[1]\n",
    "    else:\n",
    "        raise ValueError('The threshold type must be one of the following: `volume`, `surface area`, or `diameter`!')\n",
    "    \n",
    "    # Return the filtered data based on the threshold\n",
    "    return instance_labels[mask], volumes[mask], surface_areas[mask], diameters[mask], sphericities[mask], threshold\n",
    "\n",
    "def bin_data(data, bin_edges):\n",
    "    \"\"\"Bin the data according to the bin edges and return the bin counts.\"\"\"\n",
    "    counts, _ = np.histogram(data, bins=bin_edges)\n",
    "    return counts\n",
    "\n",
    "def save_psd_to_csv(instance_labels, volumes, surface_areas, diameters, sphericities, save_path):\n",
    "    \"\"\"Apply outlier removal using IQR and save results to CSV.\"\"\"\n",
    "    df = pd.DataFrame({\n",
    "        \"Instance\": instance_labels,\n",
    "        \"Volume\": volumes,\n",
    "        \"Surface Area\": surface_areas,\n",
    "        \"Diameter\": diameters,\n",
    "        \"Sphericity\": sphericities\n",
    "    })\n",
    "    df.to_csv(save_path, index=False)\n",
    "    print(f\"Saved PSD as CSV to {save_path}\")\n",
    "\n",
    "def save_histogram(data, bin_edges, title, xlabel, save_path):\n",
    "    \"\"\"Save histogram plot with scaled x-axis, excluding zero values.\"\"\"\n",
    "    data = data[data > 0]  # Exclude zero values\n",
    "    if len(data) == 0:\n",
    "        print(f\"Warning: No valid data for histogram {title}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.hist(data, bins=bin_edges, edgecolor='black', alpha=0.7)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(\"Particle Count\")\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def save_binned_psd(volumes, surface_areas, diameters, sphericities, save_path, num_bins=50, threshold=None):\n",
    "    \"\"\"Save binned Particle Size Distribution (PSD) to CSV for multiple metrics.\"\"\"\n",
    "    volume_min = 0\n",
    "    surface_area_min = 0\n",
    "    diameter_min = 0\n",
    "    sphericity_min = 0\n",
    "    \n",
    "    if threshold is None:\n",
    "        # Calculate the range for each dataset and round accordingly\n",
    "        volume_max = np.ceil(max(volumes))   # Round up\n",
    "        surface_area_max = np.ceil(max(surface_areas))   # Round up\n",
    "        diameter_max = np.ceil(max(diameters))   # Round up\n",
    "        sphericity_max = np.ceil(max(sphericities))   # Round up\n",
    "    else:\n",
    "        if threshold[0] == 'volume':\n",
    "            volume_max = threshold[1]\n",
    "            diameter_max = np.ceil((6 * volume_max / np.pi) ** (1/3))\n",
    "            surface_area_max = np.ceil(4 * np.pi * (diameter_max / 2) ** 2)\n",
    "            sphericity_max = (np.pi ** (1/3) * (6 * volume_max) ** (2/3)) / surface_area_max\n",
    "\n",
    "        elif threshold[0] == 'surface area':\n",
    "            surface_area_max = threshold[1]\n",
    "            diameter_max = np.ceil(np.sqrt(surface_area_max / (4 * np.pi)) * 2)\n",
    "            volume_max = np.ceil((4/3) * np.pi * (diameter_max / 2) ** 3)\n",
    "            sphericity_max = (np.pi ** (1/3) * (6 * volume_max) ** (2/3)) / surface_area_max\n",
    "            print('Please note that thresholding based on surface area may lead to odd binned histograms due to the very approximate estimation of surface area that is not directly related to volume or diameter.')\n",
    "            \n",
    "        elif threshold[0] == 'diameter':\n",
    "            diameter_max = threshold[1]\n",
    "            volume_max = np.ceil((4/3) * np.pi * (diameter_max / 2) ** 3)\n",
    "            surface_area_max = np.ceil(4 * np.pi * (diameter_max / 2) ** 2)\n",
    "            sphericity_max = (np.pi ** (1/3) * (6 * volume_max) ** (2/3)) / surface_area_max\n",
    "\n",
    "        else:\n",
    "            raise ValueError('The threshold type must be one of the following: `volume`, `surface area`, or `diameter`!')\n",
    "\n",
    "    def create_bins(min_val, max_val, num_bins):\n",
    "        bin_range = max_val - min_val\n",
    "        if bin_range >= num_bins:\n",
    "            return np.linspace(min_val, max_val, num_bins + 1, dtype=int)\n",
    "        else:\n",
    "            extra_bins = num_bins - bin_range  # Add extra bins if range is small\n",
    "            return np.linspace(min_val, max_val + extra_bins, num_bins + 1, dtype=int)\n",
    "\n",
    "    def create_log_bins(min_val, max_val, num_bins, epsilon=1e-6):\n",
    "        # Shift values to avoid log(0) error\n",
    "        min_val = max(min_val, epsilon)\n",
    "        log_min = np.log10(min_val)\n",
    "        log_max = np.log10(max_val)\n",
    "        log_bins = np.logspace(log_min, log_max, num_bins + 1)\n",
    "        return np.unique(log_bins)\n",
    "    \n",
    "    def create_power_bins(min_val, max_val, num_bins, power=2):\n",
    "        # Create bins using a power law scaling\n",
    "        bins = np.linspace(min_val ** power, max_val ** power, num_bins + 1) ** (1 / power)\n",
    "        return np.unique(np.round(bins).astype(int))\n",
    "\n",
    "    # Create bins for volume and surface area using logarithmic spacing\n",
    "    volume_bins = create_bins(volume_min, volume_max, num_bins)\n",
    "    surface_area_bins = create_bins(surface_area_min, surface_area_max, num_bins)\n",
    "    diameter_bins = np.linspace(diameter_min, diameter_max, num_bins + 1)\n",
    "    sphericity_bins = np.linspace(sphericity_min, sphericity_max, num_bins + 1)\n",
    "\n",
    "    volume_counts = bin_data(volumes, volume_bins)\n",
    "    surface_area_counts = bin_data(surface_areas, surface_area_bins)\n",
    "    diameter_counts = bin_data(diameters, diameter_bins)\n",
    "    sphericity_counts = bin_data(sphericities, sphericity_bins)\n",
    "\n",
    "    volume_bin_ranges = [f\"{v1}.0-{v2}.0\" for v1, v2 in zip(volume_bins[:-1], volume_bins[1:])]\n",
    "    surface_area_bin_ranges = [f\"{s1}.0-{s2}.0\" for s1, s2 in zip(surface_area_bins[:-1], surface_area_bins[1:])]\n",
    "    diameter_bin_ranges = [f\"{d1}-{d2}\" for d1, d2 in zip(diameter_bins[:-1], diameter_bins[1:])]\n",
    "    sphericity_bin_ranges = [f\"{d1}-{d2}\" for d1, d2 in zip(sphericity_bins[:-1], sphericity_bins[1:])]\n",
    "    \n",
    "    binned_df = pd.DataFrame({\n",
    "        \"Volume Bin Range\": volume_bin_ranges,\n",
    "        \"Volume Count\": volume_counts,\n",
    "        \"Surface Area Bin Range\": surface_area_bin_ranges,\n",
    "        \"Surface Area Count\": surface_area_counts,\n",
    "        \"Diameter Bin Range\": diameter_bin_ranges,\n",
    "        \"Diameter Count\": diameter_counts,\n",
    "        \"Sphericity Bin Range\": sphericity_bin_ranges,\n",
    "        \"Sphericity Count\": sphericity_counts\n",
    "    })\n",
    "\n",
    "    binned_df.to_csv(save_path, index=False)\n",
    "    print(f\"Saved binned PSD results to {save_path}\")\n",
    "\n",
    "    return volume_bins, surface_area_bins, diameter_bins, sphericity_bins\n",
    "\n",
    "def save_summary_metrics(volumes, surface_areas, diameters, sphericities, save_dir, run_tag, name, prefix=\"raw\"):\n",
    "    \"\"\"Compute and save summary metrics (mean, std, median, IQR, percentiles, skewness, kurtosis) for PSD data.\"\"\"\n",
    "    \n",
    "    # Compute basic summary statistics\n",
    "    total_particles = len(volumes)\n",
    "    total_volume = np.sum(volumes)\n",
    "    total_surface_area = np.sum(surface_areas)\n",
    "    total_diameter = np.sum(diameters)\n",
    "    total_sphericity = np.sum(sphericities)\n",
    "    \n",
    "    volume_skewness = skew(volumes)\n",
    "    volume_kurtosis = kurtosis(volumes)\n",
    "    \n",
    "    surface_area_skewness = skew(surface_areas)\n",
    "    surface_area_kurtosis = kurtosis(surface_areas)\n",
    "    \n",
    "    diameter_skewness = skew(diameters)\n",
    "    diameter_kurtosis = kurtosis(diameters)\n",
    "    \n",
    "    sphericity_skewness = skew(sphericities)\n",
    "    sphericity_kurtosis = kurtosis(sphericities)\n",
    "    \n",
    "    # Percentiles for volume, surface area, diameter, Feret, and sphericity\n",
    "    volume_percentiles = np.percentile(volumes, [25, 50, 75])\n",
    "    surface_area_percentiles = np.percentile(surface_areas, [25, 50, 75])\n",
    "    diameter_percentiles = np.percentile(diameters, [25, 50, 75])\n",
    "    sphericity_percentiles = np.percentile(sphericities, [25, 50, 75])\n",
    "    \n",
    "    # Create a dictionary with all the summary metrics\n",
    "    summary = {\n",
    "        # Basic statistics for volume, surface area, and diameter\n",
    "        \"Mean Volume\": np.mean(volumes),\n",
    "        \"Std Volume\": np.std(volumes),\n",
    "        \"Median Volume\": np.median(volumes),\n",
    "        \"IQR Volume\": np.percentile(volumes, 75) - np.percentile(volumes, 25),\n",
    "\n",
    "        \"Mean Surface Area\": np.mean(surface_areas),\n",
    "        \"Std Surface Area\": np.std(surface_areas),\n",
    "        \"Median Surface Area\": np.median(surface_areas),\n",
    "        \"IQR Surface Area\": np.percentile(surface_areas, 75) - np.percentile(surface_areas, 25),\n",
    "\n",
    "        \"Mean Diameter\": np.mean(diameters),\n",
    "        \"Std Diameter\": np.std(diameters),\n",
    "        \"Median Diameter\": np.median(diameters),\n",
    "        \"IQR Diameter\": np.percentile(diameters, 75) - np.percentile(diameters, 25),\n",
    "\n",
    "        \"Mean Sphericity\": np.mean(sphericities),\n",
    "        \"Std Sphericity\": np.std(sphericities),\n",
    "        \"Median Sphericity\": np.median(sphericities),\n",
    "        \"IQR Sphericity\": np.percentile(sphericities, 75) - np.percentile(sphericities, 25),\n",
    "        \n",
    "        # Total sums for all metrics\n",
    "        \"Total Particles\": total_particles,\n",
    "        \"Total Volume\": total_volume,\n",
    "        \"Total Surface Area\": total_surface_area,\n",
    "        \"Total Diameter\": total_diameter,\n",
    "        \"Total Sphericity\": total_sphericity,\n",
    "        \n",
    "        # Skewness and Kurtosis for all metrics\n",
    "        \"Volume Skewness\": volume_skewness,\n",
    "        \"Volume Kurtosis\": volume_kurtosis,\n",
    "        \n",
    "        \"Surface Area Skewness\": surface_area_skewness,\n",
    "        \"Surface Area Kurtosis\": surface_area_kurtosis,\n",
    "        \n",
    "        \"Diameter Skewness\": diameter_skewness,\n",
    "        \"Diameter Kurtosis\": diameter_kurtosis,\n",
    "        \n",
    "        \"Sphericity Skewness\": sphericity_skewness,\n",
    "        \"Sphericity Kurtosis\": sphericity_kurtosis,\n",
    "        \n",
    "        # Percentiles for all metrics\n",
    "        \"Volume 25th Percentile\": volume_percentiles[0],\n",
    "        \"Volume 50th Percentile (Median)\": volume_percentiles[1],\n",
    "        \"Volume 75th Percentile\": volume_percentiles[2],\n",
    "        \n",
    "        \"Surface Area 25th Percentile\": surface_area_percentiles[0],\n",
    "        \"Surface Area 50th Percentile (Median)\": surface_area_percentiles[1],\n",
    "        \"Surface Area 75th Percentile\": surface_area_percentiles[2],\n",
    "        \n",
    "        \"Diameter 25th Percentile\": diameter_percentiles[0],\n",
    "        \"Diameter 50th Percentile (Median)\": diameter_percentiles[1],\n",
    "        \"Diameter 75th Percentile\": diameter_percentiles[2],\n",
    "        \n",
    "        \"Sphericity 25th Percentile\": sphericity_percentiles[0],\n",
    "        \"Sphericity 50th Percentile (Median)\": sphericity_percentiles[1],\n",
    "        \"Sphericity 75th Percentile\": sphericity_percentiles[2]\n",
    "    }\n",
    "    \n",
    "    # Convert the summary dictionary to a DataFrame\n",
    "    summary_df = pd.DataFrame(summary, index=[0])\n",
    "\n",
    "    # Create the directory to save the summary file\n",
    "    summary_folder = os.path.join(save_dir, \"summary\", run_tag, name)\n",
    "    os.makedirs(summary_folder, exist_ok=True)\n",
    "\n",
    "    # Define the path to save the summary CSV file\n",
    "    summary_path = os.path.join(summary_folder, f\"{name}_{prefix}_summary.csv\")\n",
    "    \n",
    "    # Save the summary DataFrame to CSV\n",
    "    summary_df.to_csv(summary_path, index=False)\n",
    "    \n",
    "    print(f\"Saved summary metrics for {name} ({prefix}) to {summary_path}\")\n",
    "\n",
    "def psd(input_dir, run_tag, names, save_dir, save=True):\n",
    "    \"\"\"Analyze 3D instance segmentation and compute particle size distribution (PSD).\"\"\"\n",
    "    for name in names:\n",
    "        segmentation = load_data_from_dir(os.path.join(input_dir, name))\n",
    "        instance_labels, volumes, surface_areas, diameters, sphericities = compute_psd(segmentation)\n",
    "\n",
    "        if save:\n",
    "            table_folder = os.path.join(save_dir, \"table\", run_tag, name)\n",
    "            hist_folder = os.path.join(save_dir, \"histogram\", run_tag, name)\n",
    "            os.makedirs(table_folder, exist_ok=True)\n",
    "            os.makedirs(hist_folder, exist_ok=True)\n",
    "\n",
    "            # Save original CSV\n",
    "            orignal_csv_path = os.path.join(table_folder, f\"{name}_raw_psd.csv\")\n",
    "            save_psd_to_csv(instance_labels, volumes, surface_areas, diameters, sphericities, orignal_csv_path)\n",
    "\n",
    "            # Save IQR-filtered CSV\n",
    "            iqr_filt_instance_labels, iqr_filt_volumes, iqr_filt_surface_areas, iqr_filt_diameters, iqr_filt_sphericities = filter_by_iqr(instance_labels, volumes, surface_areas, diameters, sphericities)\n",
    "            iqr_filt_csv_path = os.path.join(table_folder, f\"{name}_iqr_filt_psd.csv\")\n",
    "            save_psd_to_csv(iqr_filt_instance_labels, iqr_filt_volumes, iqr_filt_surface_areas, iqr_filt_diameters, iqr_filt_sphericities, iqr_filt_csv_path)\n",
    "\n",
    "            # Save threshold-filtered CSV\n",
    "            thresh_filt_instance_labels, thresh_filt_volumes, thresh_filt_surface_areas, thresh_filt_diameters, thresh_filt_sphericities, threshold = filter_by_threshold(instance_labels, volumes, surface_areas, diameters, sphericities)\n",
    "            thresh_filt_csv_path = os.path.join(table_folder, f\"{name}_thresh_filt_psd.csv\")\n",
    "            save_psd_to_csv(thresh_filt_instance_labels, thresh_filt_volumes, thresh_filt_surface_areas, thresh_filt_diameters, thresh_filt_sphericities, thresh_filt_csv_path)\n",
    "\n",
    "            # Save binned PSD CSVs\n",
    "            raw_volume_bins, raw_surface_area_bins, raw_diameter_bins, raw_sphericity_bins = save_binned_psd(volumes, surface_areas, diameters, sphericities, os.path.join(table_folder, f\"{name}_raw_binned_psd.csv\"), num_bins=75)\n",
    "            iqr_filt_volume_bins, iqr_filt_surface_area_bins, iqr_filt_diameter_bins, iqr_filt_sphericity_bins = save_binned_psd(iqr_filt_volumes, iqr_filt_surface_areas, iqr_filt_diameters, iqr_filt_sphericities, os.path.join(table_folder, f\"{name}_iqr_filt_binned_psd.csv\"), num_bins=75)\n",
    "            thresh_filt_volume_bins, thresh_filt_surface_area_bins, thresh_filt_diameter_bins, thresh_filt_sphericity_bins = save_binned_psd(thresh_filt_volumes, thresh_filt_surface_areas, thresh_filt_diameters, thresh_filt_sphericities, os.path.join(table_folder, f\"{name}_thresh_filt_binned_psd.csv\"), num_bins=75, threshold=threshold)\n",
    "\n",
    "            # Save histograms\n",
    "            save_histogram(volumes, raw_volume_bins, \"Raw Particle Volume Distribution\", \"Volume (voxels)\", os.path.join(hist_folder, f\"{name}_raw_volume_hist.png\"))\n",
    "            save_histogram(surface_areas, raw_surface_area_bins, \"Raw Particle Surface Area Distribution\", \"Surface Area (voxels)\", os.path.join(hist_folder, f\"{name}_raw_surface_hist.png\"))\n",
    "            save_histogram(diameters, raw_diameter_bins, \"Raw Particle Diameter Distribution\", \"Diameter (voxels)\", os.path.join(hist_folder, f\"{name}_raw_diameter_hist.png\"))\n",
    "            save_histogram(sphericities, raw_sphericity_bins, \"Raw Particle Sphericity Distribution\", \"Sphericity\", os.path.join(hist_folder, f\"{name}_raw_sphericity_hist.png\"))\n",
    "\n",
    "            # Save filtered histograms\n",
    "            save_histogram(iqr_filt_volumes, iqr_filt_volume_bins, \"IQR-Filtered Particle Volume Distribution\", \"Volume (voxels)\", os.path.join(hist_folder, f\"{name}_iqr_filt_volume_hist.png\"))\n",
    "            save_histogram(iqr_filt_surface_areas, iqr_filt_surface_area_bins, \"IQR-Filtered Particle Surface Area Distribution\", \"Surface Area (voxels)\", os.path.join(hist_folder, f\"{name}_iqr_filt_surface_hist.png\"))\n",
    "            save_histogram(iqr_filt_diameters, iqr_filt_diameter_bins, \"IQR-Filtered Particle Diameter Distribution\", \"Diameter (voxels)\", os.path.join(hist_folder, f\"{name}_iqr_filt_diameter_hist.png\"))\n",
    "            save_histogram(iqr_filt_sphericities, iqr_filt_sphericity_bins, \"IQR-Filtered Particle Sphericity Distribution\", \"Sphericity\", os.path.join(hist_folder, f\"{name}_iqr_filt_sphericity_hist.png\"))\n",
    "            \n",
    "            save_histogram(thresh_filt_volumes, thresh_filt_volume_bins, \"Threshold-Filtered Particle Volume Distribution\", \"Volume (voxels)\", os.path.join(hist_folder, f\"{name}_thresh_filt_volume_hist.png\"))\n",
    "            save_histogram(thresh_filt_surface_areas, thresh_filt_surface_area_bins, \"Threshold-Filtered Particle Surface Area Distribution\", \"Surface Area (voxels)\", os.path.join(hist_folder, f\"{name}_thresh_filt_surface_hist.png\"))\n",
    "            save_histogram(thresh_filt_diameters, thresh_filt_diameter_bins, \"Threshold-Filtered Particle Diameter Distribution\", \"Diameter (voxels)\", os.path.join(hist_folder, f\"{name}_thresh_filt_diameter_hist.png\"))\n",
    "            save_histogram(thresh_filt_sphericities, thresh_filt_sphericity_bins, \"Threshold-Filtered Particle Sphericity Distribution\", \"Sphericity\", os.path.join(hist_folder, f\"{name}_thresh_filt_sphericity_hist.png\"))\n",
    "\n",
    "            # Save summary metrics\n",
    "            save_summary_metrics(volumes, surface_areas, diameters, sphericities, save_dir, run_tag, name, prefix=\"raw\")\n",
    "            save_summary_metrics(iqr_filt_volumes, iqr_filt_surface_areas, iqr_filt_diameters, iqr_filt_sphericities, save_dir, run_tag, name, prefix=\"iqr_filt\")\n",
    "            save_summary_metrics(thresh_filt_volumes, thresh_filt_surface_areas, thresh_filt_diameters, thresh_filt_sphericities, save_dir, run_tag, name, prefix=\"thresh_filt\")\n",
    "\n",
    "            print(f\"Saved results for {name}.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_paths(dir_location, run_tag, output_to_cloud=False):\n",
    "    if dir_location.lower() == 'internal':\n",
    "        base_path = r'C:\\Senior_Design'\n",
    "    elif dir_location.lower() == 'external':\n",
    "        base_path = r'D:\\Senior_Design'\n",
    "    elif dir_location.lower() == 'cloud':\n",
    "        base_path = r'C:\\Users\\dchen\\OneDrive - University of Connecticut\\Courses\\Year 4\\Fall 2024\\BME 4900 and 4910W (Kumavor)\\Python\\Files'\n",
    "    elif dir_location.lower() == 'refine':\n",
    "        base_path = r'D:\\Darren\\Files'\n",
    "    else:\n",
    "        raise ValueError('Invalid directory location type')\n",
    "\n",
    "    base_input_path = os.path.join(base_path, 'outputs', 'tiff')\n",
    "    psd_path = os.path.join(base_path, 'outputs', 'metrics', 'particle_size_dist_v2')\n",
    "    \n",
    "    if output_to_cloud:\n",
    "        psd_path = os.path.join(r'C:\\Users\\dchen\\OneDrive - University of Connecticut\\Courses\\Year 4\\Fall 2024\\BME 4900 and 4910W (Kumavor)\\Python\\Files', 'outputs', 'metrics', 'particle_size_dist')\n",
    "\n",
    "    input_tiff_path = os.path.join(base_input_path, run_tag)\n",
    "\n",
    "    print('Paths set')\n",
    "    print('Input:', input_tiff_path)\n",
    "    print('Output:', psd_path)\n",
    "    print()\n",
    "    return input_tiff_path, psd_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths set\n",
      "Input: D:\\Darren\\Files\\outputs\\tiff\\pretrained_tab40_gen35_clar35_fold4\n",
      "Output: D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v2\n",
      "\n",
      "Saved PSD as CSV to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v2\\table\\pretrained_tab40_gen35_clar35_fold4\\2_Tablet\\2_Tablet_raw_psd.csv\n",
      "Saved PSD as CSV to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v2\\table\\pretrained_tab40_gen35_clar35_fold4\\2_Tablet\\2_Tablet_iqr_filt_psd.csv\n",
      "Saved PSD as CSV to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v2\\table\\pretrained_tab40_gen35_clar35_fold4\\2_Tablet\\2_Tablet_thresh_filt_psd.csv\n",
      "Saved binned PSD results to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v2\\table\\pretrained_tab40_gen35_clar35_fold4\\2_Tablet\\2_Tablet_raw_binned_psd.csv\n",
      "Saved binned PSD results to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v2\\table\\pretrained_tab40_gen35_clar35_fold4\\2_Tablet\\2_Tablet_iqr_filt_binned_psd.csv\n",
      "Saved binned PSD results to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v2\\table\\pretrained_tab40_gen35_clar35_fold4\\2_Tablet\\2_Tablet_thresh_filt_binned_psd.csv\n",
      "Saved summary metrics for 2_Tablet (raw) to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v2\\summary\\pretrained_tab40_gen35_clar35_fold4\\2_Tablet\\2_Tablet_raw_summary.csv\n",
      "Saved summary metrics for 2_Tablet (iqr_filt) to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v2\\summary\\pretrained_tab40_gen35_clar35_fold4\\2_Tablet\\2_Tablet_iqr_filt_summary.csv\n",
      "Saved summary metrics for 2_Tablet (thresh_filt) to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v2\\summary\\pretrained_tab40_gen35_clar35_fold4\\2_Tablet\\2_Tablet_thresh_filt_summary.csv\n",
      "Saved results for 2_Tablet.\n",
      "\n",
      "Saved PSD as CSV to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v2\\table\\pretrained_tab40_gen35_clar35_fold4\\4_GenericD12\\4_GenericD12_raw_psd.csv\n",
      "Saved PSD as CSV to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v2\\table\\pretrained_tab40_gen35_clar35_fold4\\4_GenericD12\\4_GenericD12_iqr_filt_psd.csv\n",
      "Saved PSD as CSV to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v2\\table\\pretrained_tab40_gen35_clar35_fold4\\4_GenericD12\\4_GenericD12_thresh_filt_psd.csv\n",
      "Saved binned PSD results to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v2\\table\\pretrained_tab40_gen35_clar35_fold4\\4_GenericD12\\4_GenericD12_raw_binned_psd.csv\n",
      "Saved binned PSD results to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v2\\table\\pretrained_tab40_gen35_clar35_fold4\\4_GenericD12\\4_GenericD12_iqr_filt_binned_psd.csv\n",
      "Saved binned PSD results to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v2\\table\\pretrained_tab40_gen35_clar35_fold4\\4_GenericD12\\4_GenericD12_thresh_filt_binned_psd.csv\n",
      "Saved summary metrics for 4_GenericD12 (raw) to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v2\\summary\\pretrained_tab40_gen35_clar35_fold4\\4_GenericD12\\4_GenericD12_raw_summary.csv\n",
      "Saved summary metrics for 4_GenericD12 (iqr_filt) to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v2\\summary\\pretrained_tab40_gen35_clar35_fold4\\4_GenericD12\\4_GenericD12_iqr_filt_summary.csv\n",
      "Saved summary metrics for 4_GenericD12 (thresh_filt) to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v2\\summary\\pretrained_tab40_gen35_clar35_fold4\\4_GenericD12\\4_GenericD12_thresh_filt_summary.csv\n",
      "Saved results for 4_GenericD12.\n",
      "\n",
      "Saved PSD as CSV to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v2\\table\\pretrained_tab40_gen35_clar35_fold4\\5_ClaritinD12\\5_ClaritinD12_raw_psd.csv\n",
      "Saved PSD as CSV to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v2\\table\\pretrained_tab40_gen35_clar35_fold4\\5_ClaritinD12\\5_ClaritinD12_iqr_filt_psd.csv\n",
      "Saved PSD as CSV to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v2\\table\\pretrained_tab40_gen35_clar35_fold4\\5_ClaritinD12\\5_ClaritinD12_thresh_filt_psd.csv\n",
      "Saved binned PSD results to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v2\\table\\pretrained_tab40_gen35_clar35_fold4\\5_ClaritinD12\\5_ClaritinD12_raw_binned_psd.csv\n",
      "Saved binned PSD results to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v2\\table\\pretrained_tab40_gen35_clar35_fold4\\5_ClaritinD12\\5_ClaritinD12_iqr_filt_binned_psd.csv\n",
      "Saved binned PSD results to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v2\\table\\pretrained_tab40_gen35_clar35_fold4\\5_ClaritinD12\\5_ClaritinD12_thresh_filt_binned_psd.csv\n",
      "Saved summary metrics for 5_ClaritinD12 (raw) to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v2\\summary\\pretrained_tab40_gen35_clar35_fold4\\5_ClaritinD12\\5_ClaritinD12_raw_summary.csv\n",
      "Saved summary metrics for 5_ClaritinD12 (iqr_filt) to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v2\\summary\\pretrained_tab40_gen35_clar35_fold4\\5_ClaritinD12\\5_ClaritinD12_iqr_filt_summary.csv\n",
      "Saved summary metrics for 5_ClaritinD12 (thresh_filt) to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist_v2\\summary\\pretrained_tab40_gen35_clar35_fold4\\5_ClaritinD12\\5_ClaritinD12_thresh_filt_summary.csv\n",
      "Saved results for 5_ClaritinD12.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dir_location = 'refine'\n",
    "run_tag = 'pretrained_tab40_gen35_clar35_fold4'\n",
    "input_tiff_path, psd_path = setup_paths(dir_location, run_tag)\n",
    "save = True  # Set to True if you want to save both histograms and PSD data\n",
    "names = ['2_Tablet', '4_GenericD12', '5_ClaritinD12']\n",
    "\n",
    "# # For ground truth instance segmentation\n",
    "# # input_tiff_path = r'C:\\Users\\dchen\\OneDrive - University of Connecticut\\Courses\\Year 4\\Fall 2024\\BME 4900 and 4910W (Kumavor)\\Python\\Files\\database\\tablet_dataset\\instance\\tiff'\n",
    "# input_tiff_path = r'd:\\Darren\\Files\\database\\tablet_dataset\\instance\\tiff'\n",
    "# run_tag = 'ground_truth'\n",
    "\n",
    "psd(input_tiff_path, run_tag, names, psd_path, save)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Senior_Design_py310_source",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cc3d\n",
    "from skimage.measure import regionprops\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def load_data_from_dir(input_dir):\n",
    "    \"\"\"Load 3D instance segmentation from a directory of 2D TIFF slices.\"\"\"\n",
    "    file_list = sorted([f for f in os.listdir(input_dir) if f.endswith('.tiff')])\n",
    "    if not file_list:\n",
    "        raise ValueError(f\"No TIFF images found in {input_dir}\")\n",
    "    return np.stack([tiff.imread(os.path.join(input_dir, f)) for f in file_list])\n",
    "\n",
    "def compute_psd(segmentation):\n",
    "    \"\"\"Compute volume, surface area, and diameter for each particle in the 3D segmentation.\"\"\"\n",
    "    labels = cc3d.connected_components(segmentation)  # Fast 3D labeling\n",
    "    props = regionprops(labels)\n",
    "\n",
    "    def compute_metrics(prop):\n",
    "        if prop.label == 0:  # Exclude background\n",
    "            return None\n",
    "\n",
    "        instance_label = prop.label  # Instance ID\n",
    "        volume = prop.area  # Voxel count as volume\n",
    "        bbox = prop.bbox\n",
    "        min_x, min_y, min_z, max_x, max_y, max_z = bbox\n",
    "        surface_area = (\n",
    "            np.sum(segmentation[min_x+1:max_x, min_y:max_y, min_z:max_z] != \n",
    "                   segmentation[min_x:max_x-1, min_y:max_y, min_z:max_z]) +\n",
    "            np.sum(segmentation[min_x:max_x, min_y+1:max_y, min_z:max_z] != \n",
    "                   segmentation[min_x:max_x, min_y:max_y-1, min_z:max_z]) +\n",
    "            np.sum(segmentation[min_x:max_x, min_y:max_y, min_z+1:max_z] != \n",
    "                   segmentation[min_x:max_x, min_y:max_y, min_z:max_z-1])\n",
    "        )\n",
    "        diameter = (6 * volume / np.pi) ** (1/3)  # Spherical equivalent diameter\n",
    "        return instance_label, volume, surface_area, diameter\n",
    "\n",
    "    results = Parallel(n_jobs=-1)(delayed(compute_metrics)(prop) for prop in props)\n",
    "    results = [r for r in results if r is not None]  # Remove None values\n",
    "    instance_labels, volumes, surface_areas, diameters = zip(*results) if results else ([], [], [], [])\n",
    "\n",
    "    return np.array(instance_labels), np.array(volumes), np.array(surface_areas), np.array(diameters)\n",
    "\n",
    "def remove_outliers(data):\n",
    "    \"\"\"Remove outliers using the IQR method and return both filtered data and kept indices.\"\"\"\n",
    "    if len(data) == 0:\n",
    "        return data, np.arange(len(data))  # Return empty array and indices\n",
    "\n",
    "    Q1 = np.percentile(data, 25)\n",
    "    Q3 = np.percentile(data, 75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 5.0 * IQR\n",
    "    upper_bound = Q3 + 5.0 * IQR\n",
    "\n",
    "    mask = (data >= lower_bound) & (data <= upper_bound)  # Boolean mask for non-outliers\n",
    "    return data[mask], np.where(mask)[0]  # Return filtered data and valid indices\n",
    "\n",
    "def bin_data(data, bin_edges):\n",
    "    \"\"\"Bin the data according to the bin edges and return the bin counts.\"\"\"\n",
    "    counts, _ = np.histogram(data, bins=bin_edges)\n",
    "    return counts\n",
    "\n",
    "def save_histogram(data, bin_edges, title, xlabel, save_path):\n",
    "    \"\"\"Save histogram plot with scaled x-axis, excluding zero values.\"\"\"\n",
    "    data = data[data > 0]  # Exclude zero values\n",
    "    if len(data) == 0:\n",
    "        print(f\"Warning: No valid data for histogram {title}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # num_bins = min(100, max(10, len(np.unique(data)) // 5))  # Adaptive bin count\n",
    "    # bin_edges = np.linspace(data.min(), data.max(), num_bins)  # Scale x-axis\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.hist(data, bins=bin_edges, edgecolor='black', alpha=0.7)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(\"Particle Count\")\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def save_binned_psd(volumes, surface_areas, diameters, save_path, num_bins=50):\n",
    "    \"\"\"Save binned Particle Size Distribution (PSD) to CSV.\"\"\"\n",
    "    # Calculate the range for each dataset and round accordingly\n",
    "    volume_min = np.floor(min(volumes))  # Round down\n",
    "    volume_max = np.ceil(max(volumes))   # Round up\n",
    "    surface_area_min = np.floor(min(surface_areas))  # Round down\n",
    "    surface_area_max = np.ceil(max(surface_areas))   # Round up\n",
    "    diameter_min = np.floor(min(diameters))  # Round down\n",
    "    diameter_max = np.ceil(max(diameters))   # Round up\n",
    "\n",
    "    # Check if the range is less than the number of bins, if so use unique values\n",
    "    def create_bins(min_val, max_val, num_bins):\n",
    "        bin_range = max_val - min_val\n",
    "        if bin_range >= num_bins:\n",
    "            return np.linspace(min_val, max_val, num_bins + 1, dtype=int)\n",
    "        else:\n",
    "            # Create extra bins by adjusting the bin width based on the range\n",
    "            extra_bins = num_bins - bin_range  # Add extra bins if range is small\n",
    "            return np.linspace(min_val, max_val + extra_bins, num_bins + 1, dtype=int)\n",
    "\n",
    "    volume_bins = create_bins(volume_min, volume_max, num_bins)\n",
    "    surface_area_bins = create_bins(surface_area_min, surface_area_max, num_bins)\n",
    "    diameter_bins = create_bins(diameter_min, diameter_max, num_bins)\n",
    "\n",
    "    # # Check the length of each bin array\n",
    "    # print(f\"Number of volume bins: {len(volume_bins)}\")\n",
    "    # print(volume_bins)\n",
    "    # print(f\"Number of surface area bins: {len(surface_area_bins)}\")\n",
    "    # print(surface_area_bins)\n",
    "    # print(f\"Number of diameter bins: {len(diameter_bins)}\")\n",
    "    # print(diameter_bins)\n",
    "\n",
    "    # Bin the data\n",
    "    volume_counts = bin_data(volumes, volume_bins)\n",
    "    surface_area_counts = bin_data(surface_areas, surface_area_bins)\n",
    "    diameter_counts = bin_data(diameters, diameter_bins)\n",
    "\n",
    "    # Add \".0\" after each integer in the bin range\n",
    "    volume_bin_ranges = [f\"{v1}.0-{v2}.0\" for v1, v2 in zip(volume_bins[:-1], volume_bins[1:])]\n",
    "    surface_area_bin_ranges = [f\"{s1}.0-{s2}.0\" for s1, s2 in zip(surface_area_bins[:-1], surface_area_bins[1:])]\n",
    "    diameter_bin_ranges = [f\"{d1}.0-{d2}.0\" for d1, d2 in zip(diameter_bins[:-1], diameter_bins[1:])]\n",
    "\n",
    "    # Create the DataFrame with valid bins\n",
    "    binned_df = pd.DataFrame({\n",
    "        \"Volume Bin Range\": volume_bin_ranges,\n",
    "        \"Volume Count\": volume_counts,\n",
    "        \"Surface Area Bin Range\": surface_area_bin_ranges,\n",
    "        \"Surface Area Count\": surface_area_counts,\n",
    "        \"Diameter Bin Range\": diameter_bin_ranges,\n",
    "        \"Diameter Count\": diameter_counts\n",
    "    })\n",
    "\n",
    "    # Save to CSV\n",
    "    binned_df.to_csv(save_path, index=False)\n",
    "    print(f\"Saved binned PSD results to {save_path}\")\n",
    "\n",
    "    return volume_bins, surface_area_bins, diameter_bins\n",
    "\n",
    "def analyze_3d_instance_segmentation(input_dir, run_tag, name, save_dir, save):\n",
    "    \"\"\"Analyze 3D instance segmentation and compute particle size distribution (PSD).\"\"\"\n",
    "    segmentation = load_data_from_dir(input_dir)\n",
    "    instance_labels, volumes, surface_areas, diameters = compute_psd(segmentation)\n",
    "\n",
    "    if save:\n",
    "        csv_folder = os.path.join(save_dir, \"csv\", run_tag)\n",
    "        hist_folder = os.path.join(save_dir, \"hist\", run_tag, name)\n",
    "        os.makedirs(csv_folder, exist_ok=True)\n",
    "        os.makedirs(hist_folder, exist_ok=True)\n",
    "\n",
    "        # Save original CSV\n",
    "        csv_path = os.path.join(csv_folder, f\"{name}_raw_psd.csv\")\n",
    "        df = pd.DataFrame({\n",
    "            \"Instance\": instance_labels,\n",
    "            \"Volume\": volumes,\n",
    "            \"Surface Area\": surface_areas,\n",
    "            \"Diameter\": diameters\n",
    "        })\n",
    "        df = df[df[\"Volume\"] > 0]  # Ensure zero values are excluded\n",
    "        df.to_csv(csv_path, index=False)\n",
    "\n",
    "        # Save filtered CSV (outliers removed)\n",
    "        filtered_volumes, valid_indices = remove_outliers(volumes)\n",
    "        filtered_surface_areas = surface_areas[valid_indices]\n",
    "        filtered_diameters = diameters[valid_indices]\n",
    "        filtered_instance_labels = instance_labels[valid_indices]  # Ensure labels match filtered data\n",
    "\n",
    "        filtered_csv_path = os.path.join(csv_folder, f\"{name}_filtered_psd.csv\")\n",
    "        filtered_df = pd.DataFrame({\n",
    "            \"Instance\": filtered_instance_labels,\n",
    "            \"Volume\": filtered_volumes,\n",
    "            \"Surface Area\": filtered_surface_areas,\n",
    "            \"Diameter\": filtered_diameters\n",
    "        })\n",
    "        filtered_df.to_csv(filtered_csv_path, index=False)\n",
    "\n",
    "        # Save binned PSD CSVs\n",
    "        raw_volume_bins, raw_surface_area_bins, raw_diameter_bins = save_binned_psd(volumes, surface_areas, diameters, os.path.join(csv_folder, f\"{name}_raw_binned_psd.csv\"), num_bins=50)\n",
    "        filtered_volume_bins, filtered_surface_area_bins, filtered_diameter_bins = save_binned_psd(filtered_volumes, filtered_surface_areas, filtered_diameters, os.path.join(csv_folder, f\"{name}_filtered_binned_psd.csv\"), num_bins=25)\n",
    "\n",
    "        # Save histograms\n",
    "        save_histogram(volumes, raw_volume_bins, \"Particle Volume Distribution\", \"Volume (voxels)\", os.path.join(hist_folder, f\"{name}_raw_volume_hist.png\"))\n",
    "        save_histogram(surface_areas, raw_surface_area_bins, \"Particle Surface Area Distribution\", \"Surface Area (pixels)\", os.path.join(hist_folder, f\"{name}_raw_surface_hist.png\"))\n",
    "        save_histogram(diameters, raw_diameter_bins, \"Particle Diameter Distribution\", \"Diameter (voxels)\", os.path.join(hist_folder, f\"{name}_raw_diameter_hist.png\"))\n",
    "\n",
    "        # Save filtered histograms\n",
    "        save_histogram(filtered_volumes, filtered_volume_bins, \"Filtered Particle Volume Distribution\", \"Volume (voxels)\", os.path.join(hist_folder, f\"{name}_filtered_volume_hist.png\"))\n",
    "        save_histogram(filtered_surface_areas, filtered_surface_area_bins, \"Filtered Particle Surface Area Distribution\", \"Surface Area (pixels)\", os.path.join(hist_folder, f\"{name}_filtered_surface_hist.png\"))\n",
    "        save_histogram(filtered_diameters, filtered_diameter_bins, \"Filtered Particle Diameter Distribution\", \"Diameter (voxels)\", os.path.join(hist_folder, f\"{name}_filtered_diameter_hist.png\"))\n",
    "\n",
    "        print(f\"Saved results for {name} with outlier filtering.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_paths(dir_location, run_tag, output_to_cloud=False):\n",
    "    if dir_location.lower() == 'internal':\n",
    "        base_path = r'C:\\Senior_Design'\n",
    "    elif dir_location.lower() == 'external':\n",
    "        base_path = r'D:\\Senior_Design'\n",
    "    elif dir_location.lower() == 'cloud':\n",
    "        base_path = r'C:\\Users\\dchen\\OneDrive - University of Connecticut\\Courses\\Year 4\\Fall 2024\\BME 4900 and 4910W (Kumavor)\\Python\\Files'\n",
    "    elif dir_location.lower() == 'refine':\n",
    "        base_path = r'D:\\Darren\\Files'\n",
    "    else:\n",
    "        raise ValueError('Invalid directory location type')\n",
    "\n",
    "    base_input_path = os.path.join(base_path, 'outputs', 'tiff')\n",
    "    psd_path = os.path.join(base_path, 'outputs', 'metrics', 'particle_size_dist')\n",
    "    \n",
    "    if output_to_cloud:\n",
    "        psd_path = os.path.join(r'C:\\Users\\dchen\\OneDrive - University of Connecticut\\Courses\\Year 4\\Fall 2024\\BME 4900 and 4910W (Kumavor)\\Python\\Files', 'outputs', 'metrics', 'particle_size_dist')\n",
    "\n",
    "    input_tiff_path = os.path.join(base_input_path, run_tag)\n",
    "\n",
    "    print('Paths set')\n",
    "    print('Input:', input_tiff_path)\n",
    "    print('Output:', psd_path)\n",
    "    return input_tiff_path, psd_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths set\n",
      "Input: D:\\Darren\\Files\\outputs\\tiff\\pretrained_tab40_gen35_clar35_foldsALL\n",
      "Output: D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist\n",
      "Saved binned PSD results to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist\\csv\\pretrained_tab40_gen35_clar35_foldsALL\\2_Tablet_raw_binned_psd.csv\n",
      "Saved binned PSD results to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist\\csv\\pretrained_tab40_gen35_clar35_foldsALL\\2_Tablet_filtered_binned_psd.csv\n",
      "Saved results for 2_Tablet with outlier filtering.\n",
      "Saved binned PSD results to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist\\csv\\pretrained_tab40_gen35_clar35_foldsALL\\4_GenericD12_raw_binned_psd.csv\n",
      "Saved binned PSD results to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist\\csv\\pretrained_tab40_gen35_clar35_foldsALL\\4_GenericD12_filtered_binned_psd.csv\n",
      "Saved results for 4_GenericD12 with outlier filtering.\n",
      "Saved binned PSD results to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist\\csv\\pretrained_tab40_gen35_clar35_foldsALL\\5_ClaritinD12_raw_binned_psd.csv\n",
      "Saved binned PSD results to D:\\Darren\\Files\\outputs\\metrics\\particle_size_dist\\csv\\pretrained_tab40_gen35_clar35_foldsALL\\5_ClaritinD12_filtered_binned_psd.csv\n",
      "Saved results for 5_ClaritinD12 with outlier filtering.\n"
     ]
    }
   ],
   "source": [
    "dir_location = 'refine'\n",
    "run_tag = 'pretrained_tab40_gen35_clar35_foldsALL'\n",
    "input_tiff_path, psd_path = setup_paths(dir_location, run_tag)\n",
    "save = True  # Set to True if you want to save both histograms and PSD data\n",
    "names = ['2_Tablet', '4_GenericD12', '5_ClaritinD12']\n",
    "\n",
    "# # For ground truth instance segmentation\n",
    "# input_tiff_path = r'C:\\Users\\dchen\\OneDrive - University of Connecticut\\Courses\\Year 4\\Fall 2024\\BME 4900 and 4910W (Kumavor)\\Python\\Files\\database\\tablet_dataset\\instance\\tiff'\n",
    "# run_tag = 'ground_truth'\n",
    "\n",
    "for name in names:\n",
    "    analyze_3d_instance_segmentation(os.path.join(input_tiff_path, name), run_tag, name, psd_path, save)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Senior_Design_py310_source",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

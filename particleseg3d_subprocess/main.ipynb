{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configurables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values configured\n"
     ]
    }
   ],
   "source": [
    "# Configurable values that may or may not need to be changed per run\n",
    "dir_location = 'refine' # Location that this run is on: internal, external, cloud (i.e. OneDrive), REFINE\n",
    "output_to_cloud = False # Overrides the output path to always output to the cloud (i.e. OneDrive)\n",
    "is_original_data = False # Original data is the dataset used by the authors of ParticleSeg3D, False results in the DigiM tablet dataset\n",
    "weights_tag = 'original_particle_seg' # Name of the weights that will be used\n",
    "run_tag = 'pretrained_initial_tablet' # Name of the run, like what name will be used to label the outputs generated from this run\n",
    "conda_env = 'Senior_Design_py310' # Name of conda environment containing all necessary libraries, packages, and modules\n",
    "\n",
    "print('Values configured')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paths set\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set path to the base directory\n",
    "if dir_location.lower() == 'internal':\n",
    "    base_path = r'C:\\Senior_Design'\n",
    "elif dir_location.lower() == 'external':\n",
    "    base_path = r'D:\\Senior_Design'\n",
    "elif dir_location.lower() == 'cloud':\n",
    "    base_path = r'C:\\Users\\dchen\\OneDrive - University of Connecticut\\Courses\\Year 4\\Fall 2024\\BME 4900 and 4910W (Kumavor)\\Python\\Files'\n",
    "elif dir_location.lower() == 'refine':\n",
    "    base_path = r'D:\\Darren\\Files'\n",
    "else:\n",
    "    raise ValueError('Invalid directory location type')\n",
    "\n",
    "# Set base paths to input, output, and weights        \n",
    "base_input_path = os.path.join(base_path, 'database')\n",
    "base_output_path = os.path.join(base_path, 'outputs')\n",
    "if output_to_cloud:\n",
    "    base_output_path = os.path.join(r'C:\\Users\\dchen\\OneDrive - University of Connecticut\\Courses\\Year 4\\Fall 2024\\BME 4900 and 4910W (Kumavor)\\Python\\Files', 'outputs')\n",
    "base_weights_path = os.path.join(base_path, 'weights')\n",
    "\n",
    "# Set Zarr (model output) and TIFF (readable output) paths\n",
    "output_zarr_path = os.path.join(base_output_path, 'zarr', run_tag)\n",
    "output_tiff_path = os.path.join(base_output_path, 'tiff', run_tag)\n",
    "\n",
    "# Set dataset path\n",
    "if is_original_data:\n",
    "    input_path = os.path.join(base_input_path, 'orignal_dataset', 'grayscale', 'dataset')\n",
    "else:\n",
    "    input_path = os.path.join(base_input_path, 'tablet_dataset', 'grayscale', 'dataset')\n",
    "\n",
    "# Set weights path\n",
    "weights_path = os.path.join(base_weights_path, weights_tag)\n",
    "\n",
    "# Ensure paths with spaces or parentheses are quoted (for using the directory in OneDrive, does not matter if there are no spaces or parentheses)\n",
    "input_path = f'\"{input_path}\"'\n",
    "output_zarr_path = f'\"{output_zarr_path}\"'\n",
    "output_tiff_path = f'\"{output_tiff_path}\"'\n",
    "weights_path = f'\"{weights_path}\"'\n",
    "\n",
    "print('Paths set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check CUDA Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run ParticleSeg3D Using Subprocess Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run ParticleSeg3D on All Tablets Without Progress Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## No real time updates\n",
    "# import subprocess\n",
    "\n",
    "# # Define the commands to execute in Anaconda PowerShell Prompt\n",
    "# activate_env = 'conda activate ' + conda_env\n",
    "# inference = 'ps3d_inference -i ' + input_path + ' -o ' + output_zarr_path + ' -m ' + weights_path\n",
    "# command = activate_env + '; ' + inference\n",
    "\n",
    "# # Run the commands\n",
    "# process = subprocess.run(\n",
    "#     ['powershell', '-Command', command], \n",
    "#     stdout=subprocess.PIPE, \n",
    "#     stderr=subprocess.PIPE, \n",
    "#     text=True\n",
    "# )\n",
    "\n",
    "# # Output the results\n",
    "# print(\"STDOUT:\", process.stdout)\n",
    "# print(\"STDERR:\", process.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run ParticleSeg3D on All Tablets with Progress Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Runs inferences on all tablets\n",
    "\n",
    "# import subprocess\n",
    "# import sys\n",
    "\n",
    "# # Define the commands to execute in Anaconda PowerShell Prompt\n",
    "# activate_env = 'conda activate ' + conda_env\n",
    "# inference = 'ps3d_inference -i ' + input_path + ' -o ' + output_zarr_path + ' -m ' + weights_path\n",
    "# command = activate_env + '; ' + inference\n",
    "\n",
    "# # Run the command with unbuffered output\n",
    "# process = subprocess.Popen(\n",
    "#     ['powershell', '-Command', command], \n",
    "#     stdout=subprocess.PIPE, \n",
    "#     stderr=subprocess.PIPE, \n",
    "#     text=True,\n",
    "#     bufsize=1  # Line-buffered for real-time updates\n",
    "# )\n",
    "\n",
    "# print(\"Running inference...\\n\")\n",
    "\n",
    "# # Read output in real-time and ensure TQDM updates properly\n",
    "# for line in iter(process.stdout.readline, ''):\n",
    "#     sys.stdout.write(line)  # Ensures immediate output\n",
    "#     sys.stdout.flush()\n",
    "\n",
    "# # Capture any errors\n",
    "# process.stdout.close()\n",
    "# stderr_output = process.stderr.read()\n",
    "# process.wait()\n",
    "\n",
    "# if stderr_output:\n",
    "#     print(\"\\nSTDERR:\", stderr_output)\n",
    "\n",
    "# print(\"\\nInference Completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run ParticleSeg3D on Each Tablet in Different Cells With Progress Bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference...\n",
      "\n",
      "\n",
      "STDERR: ps3d_inference : The term 'ps3d_inference' is not recognized as the name of a cmdlet, function, script file, or \n",
      "operable program. Check the spelling of the name, or if a path was included, verify that the path is correct and try \n",
      "again.\n",
      "At line:1 char:37\n",
      "+ conda activate Senior_Design_py310; ps3d_inference -i \"D:\\Darren\\File ...\n",
      "+                                     ~~~~~~~~~~~~~~\n",
      "    + CategoryInfo          : ObjectNotFound: (ps3d_inference:String) [], CommandNotFoundException\n",
      "    + FullyQualifiedErrorId : CommandNotFoundException\n",
      " \n",
      "\n",
      "\n",
      "Inference Completed!\n"
     ]
    }
   ],
   "source": [
    "# Runs inferences on 1_Microsphere\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Define the commands to execute in Anaconda PowerShell Prompt\n",
    "input_path = os.path.join(os.path.dirname(input_path).strip('\"'), '1_Microsphere')\n",
    "input_path = f'\"{input_path}\"'\n",
    "activate_env = 'conda activate ' + conda_env\n",
    "inference = 'ps3d_inference -i ' + input_path + ' -o ' + output_zarr_path + ' -m ' + weights_path\n",
    "command = activate_env + '; ' + inference\n",
    "\n",
    "# Run the command with unbuffered output\n",
    "process = subprocess.Popen(\n",
    "    ['powershell', '-Command', command], \n",
    "    stdout=subprocess.PIPE, \n",
    "    stderr=subprocess.PIPE, \n",
    "    text=True,\n",
    "    bufsize=1  # Line-buffered for real-time updates\n",
    ")\n",
    "\n",
    "print(\"Running inference...\\n\")\n",
    "\n",
    "# Read output in real-time and ensure TQDM updates properly\n",
    "for line in iter(process.stdout.readline, ''):\n",
    "    sys.stdout.write(line)  # Ensures immediate output\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# Capture any errors\n",
    "process.stdout.close()\n",
    "stderr_output = process.stderr.read()\n",
    "process.wait()\n",
    "\n",
    "if stderr_output:\n",
    "    print(\"\\nSTDERR:\", stderr_output)\n",
    "\n",
    "print(\"\\nInference Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference...\n",
      "\n",
      "Samples:  ['2_Tablet']\n",
      "Starting inference of sample:  2_Tablet\n",
      "\n",
      "Predicting: 0it [00:00, ?it/s]\n",
      "Predicting:   0%|          | 0/9433 [00:00<?, ?it/s]\n",
      "Predicting DataLoader 0:   0%|          | 0/9433 [00:00<?, ?it/s]\n",
      "Predicting DataLoader 0:   0%|          | 1/9433 [00:36<94:57:06, 36.24s/it]\n"
     ]
    }
   ],
   "source": [
    "# Runs inferences on 2_Tablet\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Define the commands to execute in Anaconda PowerShell Prompt\n",
    "input_path = os.path.join(os.path.dirname(input_path).strip('\"'), '2_Tablet')\n",
    "input_path = f'\"{input_path}\"'\n",
    "activate_env = 'conda activate ' + conda_env\n",
    "inference = 'ps3d_inference -i ' + input_path + ' -o ' + output_zarr_path + ' -m ' + weights_path\n",
    "command = activate_env + '; ' + inference\n",
    "\n",
    "# Run the command with unbuffered output\n",
    "process = subprocess.Popen(\n",
    "    ['powershell', '-Command', command], \n",
    "    stdout=subprocess.PIPE, \n",
    "    stderr=subprocess.PIPE, \n",
    "    text=True,\n",
    "    bufsize=1  # Line-buffered for real-time updates\n",
    ")\n",
    "\n",
    "print(\"Running inference...\\n\")\n",
    "\n",
    "# Read output in real-time and ensure TQDM updates properly\n",
    "for line in iter(process.stdout.readline, ''):\n",
    "    sys.stdout.write(line)  # Ensures immediate output\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# Capture any errors\n",
    "process.stdout.close()\n",
    "stderr_output = process.stderr.read()\n",
    "process.wait()\n",
    "\n",
    "if stderr_output:\n",
    "    print(\"\\nSTDERR:\", stderr_output)\n",
    "\n",
    "print(\"\\nInference Completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference...\n",
      "\n",
      "Samples:  ['3_SprayDriedDispersion']\n",
      "Starting inference of sample:  3_SprayDriedDispersion\n",
      "\n",
      "Predicting: 0it [00:00, ?it/s]\n",
      "Predicting:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "Predicting DataLoader 0:   0%|          | 0/122 [00:00<?, ?it/s]\n",
      "Predicting DataLoader 0:   1%|          | 1/122 [00:37<1:14:48, 37.09s/it]\n",
      "Predicting DataLoader 0:   2%|▏         | 2/122 [01:19<1:19:34, 39.79s/it]\n",
      "Predicting DataLoader 0:   2%|▏         | 3/122 [02:01<1:20:36, 40.64s/it]\n",
      "Predicting DataLoader 0:   3%|▎         | 4/122 [02:44<1:20:48, 41.09s/it]\n",
      "Predicting DataLoader 0:   4%|▍         | 5/122 [03:26<1:20:42, 41.39s/it]\n",
      "Predicting DataLoader 0:   5%|▍         | 6/122 [04:09<1:20:23, 41.58s/it]\n",
      "Predicting DataLoader 0:   6%|▌         | 7/122 [04:51<1:19:48, 41.64s/it]\n",
      "Predicting DataLoader 0:   7%|▋         | 8/122 [05:32<1:18:57, 41.56s/it]\n",
      "Predicting DataLoader 0:   7%|▋         | 9/122 [06:13<1:18:06, 41.47s/it]\n",
      "Predicting DataLoader 0:   8%|▊         | 10/122 [06:54<1:17:18, 41.42s/it]\n",
      "Predicting DataLoader 0:   9%|▉         | 11/122 [07:35<1:16:32, 41.37s/it]\n",
      "Predicting DataLoader 0:  10%|▉         | 12/122 [08:16<1:15:50, 41.37s/it]\n",
      "Predicting DataLoader 0:  11%|█         | 13/122 [08:57<1:15:10, 41.38s/it]\n",
      "Predicting DataLoader 0:  11%|█▏        | 14/122 [09:40<1:14:40, 41.49s/it]\n",
      "Predicting DataLoader 0:  12%|█▏        | 15/122 [10:23<1:14:09, 41.58s/it]\n",
      "Predicting DataLoader 0:  13%|█▎        | 16/122 [11:06<1:13:32, 41.63s/it]\n",
      "Predicting DataLoader 0:  14%|█▍        | 17/122 [11:48<1:12:53, 41.65s/it]\n",
      "Predicting DataLoader 0:  15%|█▍        | 18/122 [12:29<1:12:13, 41.66s/it]\n",
      "Predicting DataLoader 0:  16%|█▌        | 19/122 [13:11<1:11:28, 41.64s/it]\n",
      "Predicting DataLoader 0:  16%|█▋        | 20/122 [13:52<1:10:43, 41.60s/it]\n",
      "Predicting DataLoader 0:  17%|█▋        | 21/122 [14:33<1:10:00, 41.59s/it]\n",
      "Predicting DataLoader 0:  18%|█▊        | 22/122 [15:14<1:09:16, 41.57s/it]\n",
      "Predicting DataLoader 0:  19%|█▉        | 23/122 [15:55<1:08:32, 41.54s/it]\n",
      "Predicting DataLoader 0:  20%|█▉        | 24/122 [16:38<1:07:56, 41.60s/it]\n",
      "Predicting DataLoader 0:  20%|██        | 25/122 [17:21<1:07:19, 41.64s/it]\n",
      "Predicting DataLoader 0:  21%|██▏       | 26/122 [18:03<1:06:42, 41.69s/it]\n",
      "Predicting DataLoader 0:  22%|██▏       | 27/122 [18:46<1:06:04, 41.73s/it]\n",
      "Predicting DataLoader 0:  23%|██▎       | 28/122 [19:29<1:05:27, 41.78s/it]\n",
      "Predicting DataLoader 0:  24%|██▍       | 29/122 [20:12<1:04:49, 41.83s/it]\n",
      "Predicting DataLoader 0:  25%|██▍       | 30/122 [20:56<1:04:12, 41.88s/it]\n",
      "Predicting DataLoader 0:  25%|██▌       | 31/122 [21:39<1:03:34, 41.92s/it]\n",
      "Predicting DataLoader 0:  26%|██▌       | 32/122 [22:21<1:02:54, 41.94s/it]\n",
      "Predicting DataLoader 0:  27%|██▋       | 33/122 [23:04<1:02:14, 41.96s/it]\n",
      "Predicting DataLoader 0:  28%|██▊       | 34/122 [23:48<1:01:36, 42.01s/it]\n",
      "Predicting DataLoader 0:  29%|██▊       | 35/122 [24:31<1:00:57, 42.04s/it]\n",
      "Predicting DataLoader 0:  30%|██▉       | 36/122 [25:14<1:00:18, 42.07s/it]\n",
      "Predicting DataLoader 0:  30%|███       | 37/122 [25:57<59:38, 42.10s/it]  \n",
      "Predicting DataLoader 0:  31%|███       | 38/122 [26:40<58:58, 42.12s/it]\n",
      "Predicting DataLoader 0:  32%|███▏      | 39/122 [27:23<58:16, 42.13s/it]\n",
      "Predicting DataLoader 0:  33%|███▎      | 40/122 [28:06<57:36, 42.15s/it]\n",
      "Predicting DataLoader 0:  34%|███▎      | 41/122 [28:48<56:54, 42.16s/it]\n",
      "Predicting DataLoader 0:  34%|███▍      | 42/122 [29:31<56:14, 42.18s/it]\n",
      "Predicting DataLoader 0:  35%|███▌      | 43/122 [30:14<55:32, 42.19s/it]\n",
      "Predicting DataLoader 0:  36%|███▌      | 44/122 [30:56<54:50, 42.19s/it]\n",
      "Predicting DataLoader 0:  37%|███▋      | 45/122 [31:38<54:08, 42.19s/it]\n",
      "Predicting DataLoader 0:  38%|███▊      | 46/122 [32:21<53:27, 42.20s/it]\n",
      "Predicting DataLoader 0:  39%|███▊      | 47/122 [33:03<52:44, 42.20s/it]\n",
      "Predicting DataLoader 0:  39%|███▉      | 48/122 [33:45<52:02, 42.20s/it]\n",
      "Predicting DataLoader 0:  40%|████      | 49/122 [34:27<51:20, 42.20s/it]\n",
      "Predicting DataLoader 0:  41%|████      | 50/122 [35:10<50:38, 42.20s/it]\n",
      "Predicting DataLoader 0:  42%|████▏     | 51/122 [35:52<49:56, 42.20s/it]\n",
      "Predicting DataLoader 0:  43%|████▎     | 52/122 [36:34<49:14, 42.20s/it]\n",
      "Predicting DataLoader 0:  43%|████▎     | 53/122 [37:16<48:31, 42.20s/it]\n",
      "Predicting DataLoader 0:  44%|████▍     | 54/122 [37:58<47:49, 42.19s/it]\n",
      "Predicting DataLoader 0:  45%|████▌     | 55/122 [38:41<47:07, 42.20s/it]\n",
      "Predicting DataLoader 0:  46%|████▌     | 56/122 [39:24<46:26, 42.22s/it]\n",
      "Predicting DataLoader 0:  47%|████▋     | 57/122 [40:06<45:44, 42.23s/it]\n",
      "Predicting DataLoader 0:  48%|████▊     | 58/122 [40:49<45:03, 42.24s/it]\n",
      "Predicting DataLoader 0:  48%|████▊     | 59/122 [41:32<44:21, 42.25s/it]\n",
      "Predicting DataLoader 0:  49%|████▉     | 60/122 [42:15<43:39, 42.25s/it]\n",
      "Predicting DataLoader 0:  50%|█████     | 61/122 [42:57<42:57, 42.26s/it]\n",
      "Predicting DataLoader 0:  51%|█████     | 62/122 [43:40<42:15, 42.26s/it]\n",
      "Predicting DataLoader 0:  52%|█████▏    | 63/122 [44:22<41:33, 42.26s/it]\n",
      "Predicting DataLoader 0:  52%|█████▏    | 64/122 [45:05<40:51, 42.27s/it]\n",
      "Predicting DataLoader 0:  53%|█████▎    | 65/122 [45:47<40:09, 42.27s/it]\n",
      "Predicting DataLoader 0:  54%|█████▍    | 66/122 [46:30<39:27, 42.28s/it]\n",
      "Predicting DataLoader 0:  55%|█████▍    | 67/122 [47:12<38:45, 42.28s/it]\n",
      "Predicting DataLoader 0:  56%|█████▌    | 68/122 [47:55<38:03, 42.29s/it]\n",
      "Predicting DataLoader 0:  57%|█████▋    | 69/122 [48:38<37:21, 42.29s/it]\n",
      "Predicting DataLoader 0:  57%|█████▋    | 70/122 [49:24<36:42, 42.35s/it]\n",
      "Predicting DataLoader 0:  58%|█████▊    | 71/122 [50:07<36:00, 42.37s/it]\n",
      "Predicting DataLoader 0:  59%|█████▉    | 72/122 [50:49<35:17, 42.36s/it]\n",
      "Predicting DataLoader 0:  60%|█████▉    | 73/122 [51:31<34:35, 42.35s/it]\n",
      "Predicting DataLoader 0:  61%|██████    | 74/122 [52:13<33:52, 42.35s/it]\n",
      "Predicting DataLoader 0:  61%|██████▏   | 75/122 [52:55<33:10, 42.34s/it]\n",
      "Predicting DataLoader 0:  62%|██████▏   | 76/122 [53:37<32:27, 42.34s/it]\n",
      "Predicting DataLoader 0:  63%|██████▎   | 77/122 [54:19<31:44, 42.33s/it]\n",
      "Predicting DataLoader 0:  64%|██████▍   | 78/122 [55:01<31:02, 42.33s/it]\n",
      "Predicting DataLoader 0:  65%|██████▍   | 79/122 [55:43<30:19, 42.32s/it]\n",
      "Predicting DataLoader 0:  66%|██████▌   | 80/122 [56:25<29:37, 42.32s/it]\n",
      "Predicting DataLoader 0:  66%|██████▋   | 81/122 [57:07<28:54, 42.31s/it]\n",
      "Predicting DataLoader 0:  67%|██████▋   | 82/122 [57:49<28:12, 42.31s/it]\n",
      "Predicting DataLoader 0:  68%|██████▊   | 83/122 [58:32<27:30, 42.31s/it]\n",
      "Predicting DataLoader 0:  69%|██████▉   | 84/122 [59:15<26:48, 42.32s/it]\n",
      "Predicting DataLoader 0:  70%|██████▉   | 85/122 [59:58<26:06, 42.33s/it]\n",
      "Predicting DataLoader 0:  70%|███████   | 86/122 [1:00:42<25:24, 42.35s/it]\n",
      "Predicting DataLoader 0:  71%|███████▏  | 87/122 [1:01:26<24:43, 42.37s/it]\n",
      "Predicting DataLoader 0:  72%|███████▏  | 88/122 [1:02:10<24:01, 42.39s/it]\n",
      "Predicting DataLoader 0:  73%|███████▎  | 89/122 [1:02:55<23:19, 42.42s/it]\n",
      "Predicting DataLoader 0:  74%|███████▍  | 90/122 [1:03:39<22:38, 42.44s/it]\n",
      "Predicting DataLoader 0:  75%|███████▍  | 91/122 [1:04:22<21:55, 42.45s/it]\n",
      "Predicting DataLoader 0:  75%|███████▌  | 92/122 [1:05:05<21:13, 42.45s/it]\n",
      "Predicting DataLoader 0:  76%|███████▌  | 93/122 [1:05:48<20:31, 42.45s/it]\n",
      "Predicting DataLoader 0:  77%|███████▋  | 94/122 [1:06:31<19:48, 42.46s/it]\n",
      "Predicting DataLoader 0:  78%|███████▊  | 95/122 [1:07:13<19:06, 42.46s/it]\n",
      "Predicting DataLoader 0:  79%|███████▊  | 96/122 [1:07:56<18:23, 42.46s/it]\n",
      "Predicting DataLoader 0:  80%|███████▉  | 97/122 [1:08:38<17:41, 42.46s/it]\n",
      "Predicting DataLoader 0:  80%|████████  | 98/122 [1:09:21<16:59, 42.46s/it]\n",
      "Predicting DataLoader 0:  81%|████████  | 99/122 [1:10:03<16:16, 42.46s/it]\n",
      "Predicting DataLoader 0:  82%|████████▏ | 100/122 [1:10:46<15:34, 42.46s/it]\n",
      "Predicting DataLoader 0:  83%|████████▎ | 101/122 [1:11:28<14:51, 42.47s/it]\n",
      "Predicting DataLoader 0:  84%|████████▎ | 102/122 [1:12:11<14:09, 42.47s/it]\n",
      "Predicting DataLoader 0:  84%|████████▍ | 103/122 [1:12:54<13:26, 42.47s/it]\n",
      "Predicting DataLoader 0:  85%|████████▌ | 104/122 [1:13:37<12:44, 42.47s/it]\n",
      "Predicting DataLoader 0:  86%|████████▌ | 105/122 [1:14:20<12:02, 42.48s/it]\n",
      "Predicting DataLoader 0:  87%|████████▋ | 106/122 [1:15:03<11:19, 42.49s/it]\n",
      "Predicting DataLoader 0:  88%|████████▊ | 107/122 [1:15:46<10:37, 42.49s/it]\n",
      "Predicting DataLoader 0:  89%|████████▊ | 108/122 [1:16:30<09:55, 42.50s/it]\n",
      "Predicting DataLoader 0:  89%|████████▉ | 109/122 [1:17:13<09:12, 42.51s/it]\n",
      "Predicting DataLoader 0:  90%|█████████ | 110/122 [1:17:56<08:30, 42.52s/it]\n",
      "Predicting DataLoader 0:  91%|█████████ | 111/122 [1:18:40<07:47, 42.53s/it]\n",
      "Predicting DataLoader 0:  92%|█████████▏| 112/122 [1:19:24<07:05, 42.54s/it]\n",
      "Predicting DataLoader 0:  93%|█████████▎| 113/122 [1:20:06<06:22, 42.54s/it]\n",
      "Predicting DataLoader 0:  93%|█████████▎| 114/122 [1:20:49<05:40, 42.54s/it]\n",
      "Predicting DataLoader 0:  94%|█████████▍| 115/122 [1:21:32<04:57, 42.54s/it]\n",
      "Predicting DataLoader 0:  95%|█████████▌| 116/122 [1:22:15<04:15, 42.54s/it]\n",
      "Predicting DataLoader 0:  96%|█████████▌| 117/122 [1:22:58<03:32, 42.55s/it]\n",
      "Predicting DataLoader 0:  97%|█████████▋| 118/122 [1:23:41<02:50, 42.55s/it]\n",
      "Predicting DataLoader 0:  98%|█████████▊| 119/122 [1:24:23<02:07, 42.55s/it]\n",
      "Predicting DataLoader 0:  98%|█████████▊| 120/122 [1:25:06<01:25, 42.56s/it]\n",
      "Predicting DataLoader 0:  99%|█████████▉| 121/122 [1:25:49<00:42, 42.56s/it]\n",
      "Predicting DataLoader 0: 100%|██████████| 122/122 [1:25:53<00:00, 42.24s/it]\n",
      "Predicting DataLoader 0: 100%|██████████| 122/122 [1:25:54<00:00, 42.25s/it]\n",
      "\n",
      "STDERR: C:\\Users\\dchen\\anaconda3\\envs\\Senior_Design_py310\\lib\\site-packages\\particleseg3d\\inference\\model_nnunet.py:63: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  network.load_state_dict(torch.load(checkpoint_path)[\"state_dict\"])\n",
      "C:\\Users\\dchen\\anaconda3\\envs\\Senior_Design_py310\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py:478: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  rank_zero_deprecation(\n",
      "Using 16bit None Automatic Mixed Precision (AMP)\n",
      "C:\\Users\\dchen\\anaconda3\\envs\\Senior_Design_py310\\lib\\site-packages\\pytorch_lightning\\plugins\\precision\\native_amp.py:47: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "Inference Query:   0%|          | 0/1 [00:00<?, ?it/s]You are using a CUDA device ('NVIDIA GeForce RTX 4070') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "C:\\Users\\dchen\\anaconda3\\envs\\Senior_Design_py310\\lib\\site-packages\\particleseg3d\\inference\\border_core2instance.py:142: FutureWarning: `cube` is deprecated since version 0.25 and will be removed in version 0.27. Use `skimage.morphology.footprint_rectangle` instead.\n",
      "  ball_here = cube(3)\n",
      "C:\\Users\\dchen\\anaconda3\\envs\\Senior_Design_py310\\lib\\site-packages\\particleseg3d\\inference\\border_core2instance.py:142: FutureWarning: `cube` is deprecated since version 0.25 and will be removed in version 0.27. Use `skimage.morphology.footprint_rectangle` instead.\n",
      "  ball_here = cube(3)\n",
      "\n",
      "\n",
      "  0%|          | 0/144 [00:00<?, ?it/s]\n",
      "100%|██████████| 144/144 [00:00<00:00, 18804.44it/s]\n",
      "\n",
      "Inference Query: 100%|██████████| 1/1 [1:26:31<00:00, 5191.27s/it]\n",
      "Inference Query: 100%|██████████| 1/1 [1:26:31<00:00, 5191.27s/it]\n",
      "\n",
      "\n",
      "Inference Completed!\n"
     ]
    }
   ],
   "source": [
    "# Runs inferences on 3_SprayDriedDispersion\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Define the commands to execute in Anaconda PowerShell Prompt\n",
    "input_path = os.path.join(os.path.dirname(input_path).strip('\"'), '3_SprayDriedDispersion')\n",
    "input_path = f'\"{input_path}\"'\n",
    "activate_env = 'conda activate ' + conda_env\n",
    "inference = 'ps3d_inference -i ' + input_path + ' -o ' + output_zarr_path + ' -m ' + weights_path\n",
    "command = activate_env + '; ' + inference\n",
    "\n",
    "# Run the command with unbuffered output\n",
    "process = subprocess.Popen(\n",
    "    ['powershell', '-Command', command], \n",
    "    stdout=subprocess.PIPE, \n",
    "    stderr=subprocess.PIPE, \n",
    "    text=True,\n",
    "    bufsize=1  # Line-buffered for real-time updates\n",
    ")\n",
    "\n",
    "print(\"Running inference...\\n\")\n",
    "\n",
    "# Read output in real-time and ensure TQDM updates properly\n",
    "for line in iter(process.stdout.readline, ''):\n",
    "    sys.stdout.write(line)  # Ensures immediate output\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# Capture any errors\n",
    "process.stdout.close()\n",
    "stderr_output = process.stderr.read()\n",
    "process.wait()\n",
    "\n",
    "if stderr_output:\n",
    "    print(\"\\nSTDERR:\", stderr_output)\n",
    "\n",
    "print(\"\\nInference Completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Zarr Output to TIFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import zarr\n",
    "import tifffile\n",
    "import subprocess\n",
    "\n",
    "def safe_makedirs(path):\n",
    "    \"\"\"\n",
    "    Safely create directories. If it fails due to invalid characters (e.g., quotes),\n",
    "    it strips invalid characters and retries.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "    except OSError as e:\n",
    "        print(f\"Error creating directory {path}: {e}\")\n",
    "        # Retry after stripping quotes\n",
    "        cleaned_path = path.strip('\"')\n",
    "        print(f\"Retrying with cleaned path: {cleaned_path}\")\n",
    "        try:\n",
    "            os.makedirs(cleaned_path, exist_ok=True)\n",
    "            path = cleaned_path\n",
    "        except OSError as e2:\n",
    "            print(f\"Failed again with cleaned path {cleaned_path}: {e2}\")\n",
    "            raise e2  # Reraise the error if it still fails\n",
    "        print()\n",
    "    return path\n",
    "\n",
    "\n",
    "def clean_path(path):\n",
    "    \"\"\"\n",
    "    Strips invalid characters (e.g., quotes) from the path.\n",
    "    \"\"\"\n",
    "    return path.strip('\"')\n",
    "\n",
    "\n",
    "def is_valid_zarr_directory(zarr_dir):\n",
    "    \"\"\"\n",
    "    Validates the Zarr directory to ensure it exists and contains the required structure.\n",
    "    Returns True if valid, otherwise False.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(zarr_dir):\n",
    "        print(f\"Error: Zarr directory {zarr_dir} does not exist.\")\n",
    "        print()\n",
    "        return False\n",
    "\n",
    "    if not os.path.isdir(zarr_dir):\n",
    "        print(f\"Error: {zarr_dir} is not a directory.\")\n",
    "        print()\n",
    "        return False\n",
    "\n",
    "    # Check if the directory contains valid subdirectories with `.zarr` files\n",
    "    for image_name in os.listdir(zarr_dir):\n",
    "        image_path = os.path.join(zarr_dir, image_name)\n",
    "        zarr_file = os.path.join(image_path, f\"{image_name}.zarr\")\n",
    "        if os.path.isdir(image_path) and os.path.exists(zarr_file):\n",
    "            continue  # Valid image directory with a .zarr file\n",
    "        else:\n",
    "            print(f\"Warning: {image_path} is missing a corresponding .zarr file.\")\n",
    "            print()\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def convert_zarr_to_tiff(zarr_dir, tiff_dir):\n",
    "    \"\"\"\n",
    "    Converts Zarr files to TIFF format, placing them directly in the `.tiff` folder.\n",
    "    \"\"\"\n",
    "    print(f\"Original Zarr Directory: {zarr_dir}\")\n",
    "    print(f\"Original TIFF Directory: {tiff_dir}\")\n",
    "    print()\n",
    "\n",
    "    # Try validating the Zarr directory\n",
    "    try:\n",
    "        # Attempt to list files in the Zarr directory\n",
    "        os.listdir(zarr_dir)\n",
    "    except OSError as e:\n",
    "        print(f\"Error accessing Zarr directory {zarr_dir}: {e}\")\n",
    "        # Clean path and retry\n",
    "        zarr_dir = clean_path(zarr_dir)  # Update zarr_dir with the cleaned path\n",
    "        print(f\"Retrying with cleaned Zarr Directory: {zarr_dir}\")\n",
    "        # Check again with the cleaned path\n",
    "        if not is_valid_zarr_directory(zarr_dir):\n",
    "            print(\"Invalid Zarr directory after cleaning. Aborting conversion.\")\n",
    "            print()\n",
    "            return\n",
    "        print()\n",
    "\n",
    "    # Ensure the output base directory exists for TIFF, and create the `.tiff` folder\n",
    "    tiff_dir = safe_makedirs(tiff_dir)\n",
    "\n",
    "    # Iterate through each folder in the Zarr directory\n",
    "    for image_name in os.listdir(zarr_dir):\n",
    "        image_path = os.path.join(zarr_dir, image_name)\n",
    "        if os.path.isdir(image_path):\n",
    "            zarr_input = os.path.join(image_path, f\"{image_name}.zarr\")\n",
    "\n",
    "            print(f\"Processing image: {image_name}\")\n",
    "            print(f\"Zarr Input: {zarr_input}\")\n",
    "            print(f\"TIFF Output Directory: {tiff_dir}\")\n",
    "            print()\n",
    "            \n",
    "            # Open Zarr dataset\n",
    "            image_zarr = zarr.open(zarr_input, mode='r')\n",
    "\n",
    "            # Convert Zarr data to uint8 (ensure it's within the valid range for uint8)\n",
    "            if image_zarr.dtype != np.uint8:\n",
    "                print(\"Converting data to float32...\")\n",
    "                for i in range(image_zarr.shape[0]):\n",
    "                    image_slice = image_zarr[i]\n",
    "\n",
    "                    # Normalize and scale the data to the uint8 range (0-255)\n",
    "                    image_slice = (image_slice / np.max(image_slice) * 255).astype(np.uint8) # Converts the segmentation labels into visualizable grayscale colors\n",
    "                    # image_slice = np.clip(image_slice, 0, 255)  # Clip values to 0-255\n",
    "                    # image_slice = image_slice.astype(np.uint8)   # Convert to uint8\n",
    "                    # image_slice = image_slice.astype(np.float32)   # Convert to float32\n",
    "\n",
    "                    # Save the slice as a TIFF image\n",
    "                    tiff_output_dir = os.path.join(tiff_dir, image_name)\n",
    "                    tiff_output_dir = safe_makedirs(tiff_output_dir)\n",
    "                    tifffile.imwrite(os.path.join(tiff_output_dir, f\"{image_name}_{i:04d}.tiff\"), image_slice)\n",
    "            else:\n",
    "                try:\n",
    "                    # Run the external command to convert Zarr to TIFF (does not seem to work, the generated TIFF images cannot be read...)\n",
    "                    command = [\"ps3d_zarr2tiff\", \"-i\", zarr_input, \"-o\", tiff_dir]\n",
    "                    result = subprocess.run(command, check=True, capture_output=True, text=True)\n",
    "                    print(f\"Converted {zarr_input} to {tiff_dir}\")\n",
    "                    print()\n",
    "                    print(\"Standard Output:\", result.stdout)\n",
    "                    print(\"Standard Error:\", result.stderr)\n",
    "                except subprocess.CalledProcessError as e:\n",
    "                    print(f\"Error converting {zarr_input} to TIFF: {e}\")\n",
    "                    print()\n",
    "                except Exception as e:\n",
    "                    print(f\"Unexpected error while processing {image_name}: {e}\")\n",
    "                    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Zarr Directory: \"C:\\Senior_Design\\outputs\\zarr\\pretrained_initial_tablet\"\n",
      "Original TIFF Directory: \"C:\\Senior_Design\\outputs\\tiff\\pretrained_initial_tablet\"\n",
      "\n",
      "Error accessing Zarr directory \"C:\\Senior_Design\\outputs\\zarr\\pretrained_initial_tablet\": [WinError 123] The filename, directory name, or volume label syntax is incorrect: '\"C:\\\\Senior_Design\\\\outputs\\\\zarr\\\\pretrained_initial_tablet\"'\n",
      "Retrying with cleaned Zarr Directory: C:\\Senior_Design\\outputs\\zarr\\pretrained_initial_tablet\n",
      "\n",
      "Error creating directory \"C:\\Senior_Design\\outputs\\tiff\\pretrained_initial_tablet\": [WinError 123] The filename, directory name, or volume label syntax is incorrect: '\"C:'\n",
      "Retrying with cleaned path: C:\\Senior_Design\\outputs\\tiff\\pretrained_initial_tablet\n",
      "\n",
      "Processing image: 3_SprayDriedDispersion\n",
      "Zarr Input: C:\\Senior_Design\\outputs\\zarr\\pretrained_initial_tablet\\3_SprayDriedDispersion\\3_SprayDriedDispersion.zarr\n",
      "TIFF Output Directory: C:\\Senior_Design\\outputs\\tiff\\pretrained_initial_tablet\n",
      "\n",
      "Converting data to float32...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dchen\\AppData\\Local\\Temp\\ipykernel_6164\\1999859547.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  image_slice = (image_slice / np.max(image_slice) * 255).astype(np.uint8) # Converts the segmentation labels into visualizable grayscale colors\n",
      "C:\\Users\\dchen\\AppData\\Local\\Temp\\ipykernel_6164\\1999859547.py:113: RuntimeWarning: invalid value encountered in cast\n",
      "  image_slice = (image_slice / np.max(image_slice) * 255).astype(np.uint8) # Converts the segmentation labels into visualizable grayscale colors\n"
     ]
    }
   ],
   "source": [
    "# Convert Zarr files to TIFF\n",
    "convert_zarr_to_tiff(output_zarr_path, output_tiff_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Senior_Design_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
